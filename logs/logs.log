2024-11-16 23:13:26,628 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-16 23:13:29,329 - INFO - EXTRACT ALL TABLE FROM SOURCE DATABASE - SUCCESS!
2024-11-16 23:13:29,335 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-16 23:13:29,335 - INFO - [pid 20451] Worker Worker(salt=9026128753, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=20451) done      Extract()
2024-11-16 23:13:29,337 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-16 23:13:29,352 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-16 23:13:29,353 - DEBUG - Asking scheduler for work...
2024-11-16 23:13:29,369 - DEBUG - Done
2024-11-16 23:13:29,369 - DEBUG - There are no more tasks to run at this time
2024-11-16 23:13:29,370 - INFO - Worker Worker(salt=9026128753, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=20451) was stopped. Shutting down Keep-Alive thread
2024-11-16 23:13:29,373 - INFO - 
===== Luigi Execution Summary =====

Scheduled 1 tasks of which:
* 1 ran successfully:
    - 1 Extract()

This progress looks :) because there were no failed tasks or missing dependencies

===== Luigi Execution Summary =====

2024-11-17 01:30:26,442 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-17 01:30:27,035 - INFO - EXTRACT ALL TABLE FROM SOURCE DATABASE - SUCCESS!
2024-11-17 01:30:27,036 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-17 01:30:27,036 - INFO - [pid 39018] Worker Worker(salt=3475374146, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=39018) done      Extract()
2024-11-17 01:30:27,038 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-17 01:30:27,041 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-17 01:30:27,041 - DEBUG - Asking scheduler for work...
2024-11-17 01:30:27,043 - DEBUG - Pending tasks: 1
2024-11-17 01:30:27,044 - INFO - [pid 39018] Worker Worker(salt=3475374146, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=39018) running   Load()
2024-11-17 01:30:27,044 - ERROR - [pid 39018] Worker Worker(salt=3475374146, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=39018) failed    Load()
Traceback (most recent call last):
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/luigi/worker.py", line 188, in run
    nonexistent_outputs = [output for output in dep.output() if not output.exists()]
TypeError: 'NoneType' object is not iterable
2024-11-17 01:30:27,047 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-17 01:30:27,052 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2024-11-17 01:30:27,052 - DEBUG - Asking scheduler for work...
2024-11-17 01:30:27,054 - DEBUG - Done
2024-11-17 01:30:27,054 - DEBUG - There are no more tasks to run at this time
2024-11-17 01:30:27,055 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-11-17 01:30:27,055 - DEBUG - There are 1 pending tasks unique to this worker
2024-11-17 01:30:27,055 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-11-17 01:30:27,055 - INFO - Worker Worker(salt=3475374146, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=39018) was stopped. Shutting down Keep-Alive thread
2024-11-17 01:30:27,056 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-17 01:32:42,759 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-17 01:32:43,225 - INFO - EXTRACT ALL TABLE FROM SOURCE DATABASE - SUCCESS!
2024-11-17 01:32:43,226 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-17 01:32:43,226 - INFO - [pid 39928] Worker Worker(salt=4389841095, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=39928) done      Extract()
2024-11-17 01:32:43,227 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-17 01:32:43,230 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-17 01:32:43,230 - DEBUG - Asking scheduler for work...
2024-11-17 01:32:43,232 - DEBUG - Pending tasks: 1
2024-11-17 01:32:43,232 - INFO - [pid 39928] Worker Worker(salt=4389841095, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=39928) running   Load()
2024-11-17 01:32:43,232 - ERROR - [pid 39928] Worker Worker(salt=4389841095, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=39928) failed    Load()
Traceback (most recent call last):
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/luigi/worker.py", line 188, in run
    nonexistent_outputs = [output for output in dep.output() if not output.exists()]
TypeError: 'NoneType' object is not iterable
2024-11-17 01:32:43,233 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-17 01:32:43,238 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2024-11-17 01:32:43,238 - DEBUG - Asking scheduler for work...
2024-11-17 01:32:43,242 - DEBUG - Done
2024-11-17 01:32:43,242 - DEBUG - There are no more tasks to run at this time
2024-11-17 01:32:43,243 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-11-17 01:32:43,243 - DEBUG - There are 1 pending tasks unique to this worker
2024-11-17 01:32:43,243 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-11-17 01:32:43,243 - INFO - Worker Worker(salt=4389841095, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=39928) was stopped. Shutting down Keep-Alive thread
2024-11-17 01:32:43,244 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-17 01:37:36,634 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-17 01:37:37,122 - INFO - EXTRACT ALL TABLE FROM SOURCE DATABASE - SUCCESS!
2024-11-17 01:37:37,123 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-17 01:37:37,123 - INFO - [pid 41792] Worker Worker(salt=9642369156, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=41792) done      Extract()
2024-11-17 01:37:37,124 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-17 01:37:37,127 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-17 01:37:37,127 - DEBUG - Asking scheduler for work...
2024-11-17 01:37:37,129 - DEBUG - Pending tasks: 1
2024-11-17 01:37:37,129 - INFO - [pid 41792] Worker Worker(salt=9642369156, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=41792) running   Load()
2024-11-17 01:37:37,129 - ERROR - [pid 41792] Worker Worker(salt=9642369156, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=41792) failed    Load()
Traceback (most recent call last):
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/luigi/worker.py", line 188, in run
    nonexistent_outputs = [output for output in dep.output() if not output.exists()]
TypeError: 'NoneType' object is not iterable
2024-11-17 01:37:37,130 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-17 01:37:37,136 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2024-11-17 01:37:37,136 - DEBUG - Asking scheduler for work...
2024-11-17 01:37:37,142 - DEBUG - Done
2024-11-17 01:37:37,142 - DEBUG - There are no more tasks to run at this time
2024-11-17 01:37:37,142 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-11-17 01:37:37,142 - DEBUG - There are 1 pending tasks unique to this worker
2024-11-17 01:37:37,142 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-11-17 01:37:37,142 - INFO - Worker Worker(salt=9642369156, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=41792) was stopped. Shutting down Keep-Alive thread
2024-11-17 01:37:37,143 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-17 01:40:26,451 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-17 01:40:26,892 - INFO - EXTRACT ALL TABLE FROM SOURCE DATABASE - SUCCESS!
2024-11-17 01:40:26,893 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-17 01:40:26,893 - INFO - [pid 42907] Worker Worker(salt=3013839832, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=42907) done      Extract()
2024-11-17 01:40:26,895 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-17 01:40:26,898 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-17 01:40:26,898 - DEBUG - Asking scheduler for work...
2024-11-17 01:40:26,900 - DEBUG - Pending tasks: 1
2024-11-17 01:40:26,900 - INFO - [pid 42907] Worker Worker(salt=3013839832, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=42907) running   Load()
2024-11-17 01:40:26,900 - ERROR - [pid 42907] Worker Worker(salt=3013839832, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=42907) failed    Load()
Traceback (most recent call last):
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/luigi/worker.py", line 188, in run
    nonexistent_outputs = [output for output in dep.output() if not output.exists()]
TypeError: 'NoneType' object is not iterable
2024-11-17 01:40:26,901 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-17 01:40:26,907 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2024-11-17 01:40:26,907 - DEBUG - Asking scheduler for work...
2024-11-17 01:40:26,910 - DEBUG - Done
2024-11-17 01:40:26,910 - DEBUG - There are no more tasks to run at this time
2024-11-17 01:40:26,910 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-11-17 01:40:26,910 - DEBUG - There are 1 pending tasks unique to this worker
2024-11-17 01:40:26,910 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-11-17 01:40:26,911 - INFO - Worker Worker(salt=3013839832, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=42907) was stopped. Shutting down Keep-Alive thread
2024-11-17 01:40:26,912 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-17 01:43:06,754 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-17 01:43:07,289 - INFO - EXTRACT ALL TABLE FROM SOURCE DATABASE - SUCCESS!
2024-11-17 01:43:07,290 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-17 01:43:07,290 - INFO - [pid 43958] Worker Worker(salt=6819546739, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=43958) done      Extract()
2024-11-17 01:43:07,290 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-17 01:43:07,293 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-17 01:43:07,293 - DEBUG - Asking scheduler for work...
2024-11-17 01:43:07,295 - DEBUG - Pending tasks: 1
2024-11-17 01:43:07,295 - INFO - [pid 43958] Worker Worker(salt=6819546739, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=43958) running   Load()
2024-11-17 01:43:07,295 - ERROR - [pid 43958] Worker Worker(salt=6819546739, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=43958) failed    Load()
Traceback (most recent call last):
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/luigi/worker.py", line 188, in run
    nonexistent_outputs = [output for output in dep.output() if not output.exists()]
TypeError: 'NoneType' object is not iterable
2024-11-17 01:43:07,296 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-17 01:43:07,300 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2024-11-17 01:43:07,300 - DEBUG - Asking scheduler for work...
2024-11-17 01:43:07,303 - DEBUG - Done
2024-11-17 01:43:07,303 - DEBUG - There are no more tasks to run at this time
2024-11-17 01:43:07,303 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-11-17 01:43:07,303 - DEBUG - There are 1 pending tasks unique to this worker
2024-11-17 01:43:07,303 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-11-17 01:43:07,303 - INFO - Worker Worker(salt=6819546739, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=43958) was stopped. Shutting down Keep-Alive thread
2024-11-17 01:43:07,304 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-17 01:46:30,087 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-17 01:46:30,755 - INFO - EXTRACT ALL TABLE FROM SOURCE DATABASE - SUCCESS!
2024-11-17 01:46:30,757 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-17 01:46:30,757 - INFO - [pid 45270] Worker Worker(salt=3536797902, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=45270) done      Extract()
2024-11-17 01:46:30,759 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-17 01:46:30,762 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-17 01:46:30,762 - DEBUG - Asking scheduler for work...
2024-11-17 01:46:30,763 - DEBUG - Pending tasks: 1
2024-11-17 01:46:30,764 - INFO - [pid 45270] Worker Worker(salt=3536797902, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=45270) running   Load()
2024-11-17 01:46:30,764 - ERROR - [pid 45270] Worker Worker(salt=3536797902, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=45270) failed    Load()
Traceback (most recent call last):
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/luigi/worker.py", line 188, in run
    nonexistent_outputs = [output for output in dep.output() if not output.exists()]
TypeError: 'NoneType' object is not iterable
2024-11-17 01:46:30,765 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-17 01:46:30,770 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2024-11-17 01:46:30,770 - DEBUG - Asking scheduler for work...
2024-11-17 01:46:30,775 - DEBUG - Done
2024-11-17 01:46:30,775 - DEBUG - There are no more tasks to run at this time
2024-11-17 01:46:30,775 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-11-17 01:46:30,775 - DEBUG - There are 1 pending tasks unique to this worker
2024-11-17 01:46:30,775 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-11-17 01:46:30,776 - INFO - Worker Worker(salt=3536797902, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=45270) was stopped. Shutting down Keep-Alive thread
2024-11-17 01:46:30,776 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-17 01:46:56,402 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-17 01:46:56,832 - INFO - EXTRACT ALL TABLE FROM SOURCE DATABASE - SUCCESS!
2024-11-17 01:46:56,833 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-17 01:46:56,833 - INFO - [pid 45509] Worker Worker(salt=7961647705, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=45509) done      Extract()
2024-11-17 01:46:56,835 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-17 01:46:56,838 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-17 01:46:56,838 - DEBUG - Asking scheduler for work...
2024-11-17 01:46:56,840 - DEBUG - Pending tasks: 1
2024-11-17 01:46:56,840 - INFO - [pid 45509] Worker Worker(salt=7961647705, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=45509) running   Load()
2024-11-17 01:46:56,841 - ERROR - [pid 45509] Worker Worker(salt=7961647705, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=45509) failed    Load()
Traceback (most recent call last):
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/luigi/worker.py", line 188, in run
    nonexistent_outputs = [output for output in dep.output() if not output.exists()]
TypeError: 'NoneType' object is not iterable
2024-11-17 01:46:56,841 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-17 01:46:56,846 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2024-11-17 01:46:56,846 - DEBUG - Asking scheduler for work...
2024-11-17 01:46:56,849 - DEBUG - Done
2024-11-17 01:46:56,849 - DEBUG - There are no more tasks to run at this time
2024-11-17 01:46:56,849 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-11-17 01:46:56,849 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-11-17 01:46:56,849 - INFO - Worker Worker(salt=7961647705, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=45509) was stopped. Shutting down Keep-Alive thread
2024-11-17 01:46:56,850 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-17 01:48:31,141 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-17 01:48:31,565 - INFO - EXTRACT ALL TABLE FROM SOURCE DATABASE - SUCCESS!
2024-11-17 01:48:31,566 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-17 01:48:31,567 - INFO - [pid 46166] Worker Worker(salt=5589620096, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=46166) done      Extract()
2024-11-17 01:48:31,568 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-17 01:48:31,571 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-17 01:48:31,571 - DEBUG - Asking scheduler for work...
2024-11-17 01:48:31,573 - DEBUG - Pending tasks: 1
2024-11-17 01:48:31,573 - INFO - [pid 46166] Worker Worker(salt=5589620096, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=46166) running   Load()
2024-11-17 01:48:31,573 - ERROR - [pid 46166] Worker Worker(salt=5589620096, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=46166) failed    Load()
Traceback (most recent call last):
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/luigi/worker.py", line 188, in run
    nonexistent_outputs = [output for output in dep.output() if not output.exists()]
TypeError: 'NoneType' object is not iterable
2024-11-17 01:48:31,574 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-17 01:48:31,579 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2024-11-17 01:48:31,579 - DEBUG - Asking scheduler for work...
2024-11-17 01:48:31,583 - DEBUG - Done
2024-11-17 01:48:31,583 - DEBUG - There are no more tasks to run at this time
2024-11-17 01:48:31,583 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-11-17 01:48:31,583 - DEBUG - There are 1 pending tasks unique to this worker
2024-11-17 01:48:31,583 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-11-17 01:48:31,584 - INFO - Worker Worker(salt=5589620096, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=46166) was stopped. Shutting down Keep-Alive thread
2024-11-17 01:48:31,584 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-17 01:48:53,106 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-17 01:48:53,525 - INFO - EXTRACT ALL TABLE FROM SOURCE DATABASE - SUCCESS!
2024-11-17 01:48:53,526 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-17 01:48:53,526 - INFO - [pid 46375] Worker Worker(salt=3249855685, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=46375) done      Extract()
2024-11-17 01:48:53,527 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-17 01:48:53,529 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-17 01:48:53,529 - DEBUG - Asking scheduler for work...
2024-11-17 01:48:53,531 - DEBUG - Pending tasks: 1
2024-11-17 01:48:53,531 - INFO - [pid 46375] Worker Worker(salt=3249855685, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=46375) running   Load()
2024-11-17 01:48:53,532 - ERROR - [pid 46375] Worker Worker(salt=3249855685, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=46375) failed    Load()
Traceback (most recent call last):
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/luigi/worker.py", line 188, in run
    nonexistent_outputs = [output for output in dep.output() if not output.exists()]
TypeError: 'NoneType' object is not iterable
2024-11-17 01:48:53,532 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-17 01:48:53,537 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2024-11-17 01:48:53,537 - DEBUG - Asking scheduler for work...
2024-11-17 01:48:53,540 - DEBUG - Done
2024-11-17 01:48:53,540 - DEBUG - There are no more tasks to run at this time
2024-11-17 01:48:53,540 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-11-17 01:48:53,540 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-11-17 01:48:53,541 - INFO - Worker Worker(salt=3249855685, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=46375) was stopped. Shutting down Keep-Alive thread
2024-11-17 01:48:53,542 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-17 01:49:53,447 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-17 01:49:53,878 - INFO - EXTRACT ALL TABLE FROM SOURCE DATABASE - SUCCESS!
2024-11-17 01:49:53,879 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-17 01:49:53,879 - INFO - [pid 46814] Worker Worker(salt=8659037336, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=46814) done      Extract()
2024-11-17 01:49:53,879 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-17 01:49:53,882 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-17 01:49:53,882 - DEBUG - Asking scheduler for work...
2024-11-17 01:49:53,885 - DEBUG - Pending tasks: 1
2024-11-17 01:49:53,885 - INFO - [pid 46814] Worker Worker(salt=8659037336, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=46814) running   Load()
2024-11-17 01:49:53,885 - ERROR - [pid 46814] Worker Worker(salt=8659037336, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=46814) failed    Load()
Traceback (most recent call last):
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/luigi/worker.py", line 188, in run
    nonexistent_outputs = [output for output in dep.output() if not output.exists()]
TypeError: 'NoneType' object is not iterable
2024-11-17 01:49:53,886 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-17 01:49:53,891 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2024-11-17 01:49:53,891 - DEBUG - Asking scheduler for work...
2024-11-17 01:49:53,893 - DEBUG - Done
2024-11-17 01:49:53,894 - DEBUG - There are no more tasks to run at this time
2024-11-17 01:49:53,894 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-11-17 01:49:53,894 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-11-17 01:49:53,894 - INFO - Worker Worker(salt=8659037336, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=46814) was stopped. Shutting down Keep-Alive thread
2024-11-17 01:49:53,895 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-17 01:50:20,478 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-17 01:50:20,915 - INFO - EXTRACT ALL TABLE FROM SOURCE DATABASE - SUCCESS!
2024-11-17 01:50:20,916 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-17 01:50:20,916 - INFO - [pid 47053] Worker Worker(salt=8272978800, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=47053) done      Extract()
2024-11-17 01:50:20,918 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-17 01:50:20,921 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-17 01:50:20,921 - DEBUG - Asking scheduler for work...
2024-11-17 01:50:20,922 - DEBUG - Pending tasks: 1
2024-11-17 01:50:20,922 - INFO - [pid 47053] Worker Worker(salt=8272978800, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=47053) running   Load()
2024-11-17 01:50:20,923 - ERROR - [pid 47053] Worker Worker(salt=8272978800, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=47053) failed    Load()
Traceback (most recent call last):
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/luigi/worker.py", line 188, in run
    nonexistent_outputs = [output for output in dep.output() if not output.exists()]
TypeError: 'NoneType' object is not iterable
2024-11-17 01:50:20,923 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-17 01:50:20,929 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2024-11-17 01:50:20,929 - DEBUG - Asking scheduler for work...
2024-11-17 01:50:20,932 - DEBUG - Done
2024-11-17 01:50:20,933 - DEBUG - There are no more tasks to run at this time
2024-11-17 01:50:20,933 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-11-17 01:50:20,933 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-11-17 01:50:20,933 - INFO - Worker Worker(salt=8272978800, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=47053) was stopped. Shutting down Keep-Alive thread
2024-11-17 01:50:20,934 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-17 01:52:52,158 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-17 01:52:52,848 - INFO - EXTRACT ALL TABLE FROM SOURCE DATABASE - SUCCESS!
2024-11-17 01:52:52,850 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-17 01:52:52,850 - INFO - [pid 48116] Worker Worker(salt=7566576590, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=48116) done      Extract()
2024-11-17 01:52:52,850 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-17 01:52:52,855 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-17 01:52:52,855 - DEBUG - Asking scheduler for work...
2024-11-17 01:52:52,857 - DEBUG - Pending tasks: 1
2024-11-17 01:52:52,857 - INFO - [pid 48116] Worker Worker(salt=7566576590, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=48116) running   Load()
2024-11-17 01:52:52,858 - ERROR - [pid 48116] Worker Worker(salt=7566576590, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=48116) failed    Load()
Traceback (most recent call last):
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/luigi/worker.py", line 188, in run
    nonexistent_outputs = [output for output in dep.output() if not output.exists()]
TypeError: 'NoneType' object is not iterable
2024-11-17 01:52:52,862 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-17 01:52:52,867 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2024-11-17 01:52:52,867 - DEBUG - Asking scheduler for work...
2024-11-17 01:52:52,870 - DEBUG - Done
2024-11-17 01:52:52,870 - DEBUG - There are no more tasks to run at this time
2024-11-17 01:52:52,870 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-11-17 01:52:52,870 - DEBUG - There are 1 pending tasks unique to this worker
2024-11-17 01:52:52,870 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-11-17 01:52:52,870 - INFO - Worker Worker(salt=7566576590, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=48116) was stopped. Shutting down Keep-Alive thread
2024-11-17 01:52:52,871 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-17 01:56:26,467 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-17 01:56:26,966 - INFO - EXTRACT ALL TABLE FROM SOURCE DATABASE - SUCCESS!
2024-11-17 01:56:26,967 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-17 01:56:26,967 - INFO - [pid 49508] Worker Worker(salt=3617884565, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=49508) done      Extract()
2024-11-17 01:56:26,969 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-17 01:56:26,973 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-17 01:56:26,973 - DEBUG - Asking scheduler for work...
2024-11-17 01:56:26,975 - DEBUG - Pending tasks: 1
2024-11-17 01:56:26,975 - INFO - [pid 49508] Worker Worker(salt=3617884565, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=49508) running   Load()
2024-11-17 01:56:26,975 - ERROR - [pid 49508] Worker Worker(salt=3617884565, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=49508) failed    Load()
Traceback (most recent call last):
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/luigi/worker.py", line 188, in run
    nonexistent_outputs = [output for output in dep.output() if not output.exists()]
TypeError: 'NoneType' object is not iterable
2024-11-17 01:56:26,977 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-17 01:56:26,983 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2024-11-17 01:56:26,983 - DEBUG - Asking scheduler for work...
2024-11-17 01:56:26,986 - DEBUG - Done
2024-11-17 01:56:26,986 - DEBUG - There are no more tasks to run at this time
2024-11-17 01:56:26,986 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-11-17 01:56:26,986 - DEBUG - There are 1 pending tasks unique to this worker
2024-11-17 01:56:26,986 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-11-17 01:56:26,986 - INFO - Worker Worker(salt=3617884565, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=49508) was stopped. Shutting down Keep-Alive thread
2024-11-17 01:56:26,987 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-17 02:04:01,923 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-17 02:04:01,963 - INFO - EXTRACT 'public.address' - SUCCESS.
2024-11-17 02:04:01,969 - INFO - EXTRACT 'public.address_status' - SUCCESS.
2024-11-17 02:04:01,990 - INFO - EXTRACT 'public.author' - SUCCESS.
2024-11-17 02:04:02,050 - INFO - EXTRACT 'public.book' - SUCCESS.
2024-11-17 02:04:02,084 - INFO - EXTRACT 'public.book_author' - SUCCESS.
2024-11-17 02:04:02,087 - INFO - EXTRACT 'public.book_language' - SUCCESS.
2024-11-17 02:04:02,091 - INFO - EXTRACT 'public.country' - SUCCESS.
2024-11-17 02:04:02,156 - INFO - EXTRACT 'public.cust_order' - SUCCESS.
2024-11-17 02:04:02,165 - INFO - EXTRACT 'public.customer' - SUCCESS.
2024-11-17 02:04:02,174 - INFO - EXTRACT 'public.customer_address' - SUCCESS.
2024-11-17 02:04:02,281 - INFO - EXTRACT 'public.order_history' - SUCCESS.
2024-11-17 02:04:02,372 - INFO - EXTRACT 'public.order_line' - SUCCESS.
2024-11-17 02:04:02,377 - INFO - EXTRACT 'public.order_status' - SUCCESS.
2024-11-17 02:04:02,384 - INFO - EXTRACT 'public.publisher' - SUCCESS.
2024-11-17 02:04:02,388 - INFO - EXTRACT 'public.shipping_method' - SUCCESS.
2024-11-17 02:04:02,388 - INFO - EXTRACT ALL TABLE FROM SOURCE DATABASE - SUCCESS!
2024-11-17 02:04:02,389 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-17 02:04:02,389 - INFO - [pid 52385] Worker Worker(salt=5547684674, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=52385) done      Extract()
2024-11-17 02:04:02,390 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-17 02:04:02,394 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-17 02:04:02,394 - DEBUG - Asking scheduler for work...
2024-11-17 02:04:02,395 - DEBUG - Pending tasks: 1
2024-11-17 02:04:02,396 - INFO - [pid 52385] Worker Worker(salt=5547684674, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=52385) running   Load()
2024-11-17 02:04:02,396 - ERROR - [pid 52385] Worker Worker(salt=5547684674, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=52385) failed    Load()
Traceback (most recent call last):
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/luigi/worker.py", line 188, in run
    nonexistent_outputs = [output for output in dep.output() if not output.exists()]
TypeError: 'NoneType' object is not iterable
2024-11-17 02:04:02,397 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-17 02:04:02,403 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2024-11-17 02:04:02,403 - DEBUG - Asking scheduler for work...
2024-11-17 02:04:02,406 - DEBUG - Done
2024-11-17 02:04:02,406 - DEBUG - There are no more tasks to run at this time
2024-11-17 02:04:02,406 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-11-17 02:04:02,406 - DEBUG - There are 1 pending tasks unique to this worker
2024-11-17 02:04:02,406 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-11-17 02:04:02,406 - INFO - Worker Worker(salt=5547684674, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=52385) was stopped. Shutting down Keep-Alive thread
2024-11-17 02:04:02,407 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-17 02:04:44,939 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-17 02:04:44,976 - INFO - EXTRACT 'public.address' - SUCCESS.
2024-11-17 02:04:44,980 - INFO - EXTRACT 'public.address_status' - SUCCESS.
2024-11-17 02:04:44,997 - INFO - EXTRACT 'public.author' - SUCCESS.
2024-11-17 02:04:45,087 - INFO - EXTRACT 'public.book' - SUCCESS.
2024-11-17 02:04:45,125 - INFO - EXTRACT 'public.book_author' - SUCCESS.
2024-11-17 02:04:45,131 - INFO - EXTRACT 'public.book_language' - SUCCESS.
2024-11-17 02:04:45,135 - INFO - EXTRACT 'public.country' - SUCCESS.
2024-11-17 02:04:45,203 - INFO - EXTRACT 'public.cust_order' - SUCCESS.
2024-11-17 02:04:45,211 - INFO - EXTRACT 'public.customer' - SUCCESS.
2024-11-17 02:04:45,220 - INFO - EXTRACT 'public.customer_address' - SUCCESS.
2024-11-17 02:04:45,332 - INFO - EXTRACT 'public.order_history' - SUCCESS.
2024-11-17 02:04:45,425 - INFO - EXTRACT 'public.order_line' - SUCCESS.
2024-11-17 02:04:45,429 - INFO - EXTRACT 'public.order_status' - SUCCESS.
2024-11-17 02:04:45,437 - INFO - EXTRACT 'public.publisher' - SUCCESS.
2024-11-17 02:04:45,441 - INFO - EXTRACT 'public.shipping_method' - SUCCESS.
2024-11-17 02:04:45,441 - INFO - EXTRACT ALL TABLE FROM SOURCE DATABASE - SUCCESS!
2024-11-17 02:04:45,442 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-17 02:04:45,442 - INFO - [pid 52791] Worker Worker(salt=332564099, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=52791) done      Extract()
2024-11-17 02:04:45,442 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-17 02:04:45,445 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-17 02:04:45,446 - DEBUG - Asking scheduler for work...
2024-11-17 02:04:45,449 - DEBUG - Pending tasks: 1
2024-11-17 02:04:45,449 - INFO - [pid 52791] Worker Worker(salt=332564099, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=52791) running   Load()
2024-11-17 02:04:45,450 - ERROR - [pid 52791] Worker Worker(salt=332564099, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=52791) failed    Load()
Traceback (most recent call last):
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/luigi/worker.py", line 188, in run
    nonexistent_outputs = [output for output in dep.output() if not output.exists()]
TypeError: 'NoneType' object is not iterable
2024-11-17 02:04:45,451 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-17 02:04:45,456 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2024-11-17 02:04:45,457 - DEBUG - Asking scheduler for work...
2024-11-17 02:04:45,459 - DEBUG - Done
2024-11-17 02:04:45,459 - DEBUG - There are no more tasks to run at this time
2024-11-17 02:04:45,459 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-11-17 02:04:45,459 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-11-17 02:04:45,460 - INFO - Worker Worker(salt=332564099, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=52791) was stopped. Shutting down Keep-Alive thread
2024-11-17 02:04:45,460 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-17 02:08:56,138 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-17 02:08:56,164 - INFO - EXTRACT 'public.address' - SUCCESS.
2024-11-17 02:08:56,168 - INFO - EXTRACT 'public.address_status' - SUCCESS.
2024-11-17 02:08:56,187 - INFO - EXTRACT 'public.author' - SUCCESS.
2024-11-17 02:08:56,249 - INFO - EXTRACT 'public.book' - SUCCESS.
2024-11-17 02:08:56,278 - INFO - EXTRACT 'public.book_author' - SUCCESS.
2024-11-17 02:08:56,282 - INFO - EXTRACT 'public.book_language' - SUCCESS.
2024-11-17 02:08:56,285 - INFO - EXTRACT 'public.country' - SUCCESS.
2024-11-17 02:08:56,349 - INFO - EXTRACT 'public.cust_order' - SUCCESS.
2024-11-17 02:08:56,358 - INFO - EXTRACT 'public.customer' - SUCCESS.
2024-11-17 02:08:56,367 - INFO - EXTRACT 'public.customer_address' - SUCCESS.
2024-11-17 02:08:56,473 - INFO - EXTRACT 'public.order_history' - SUCCESS.
2024-11-17 02:08:56,557 - INFO - EXTRACT 'public.order_line' - SUCCESS.
2024-11-17 02:08:56,561 - INFO - EXTRACT 'public.order_status' - SUCCESS.
2024-11-17 02:08:56,568 - INFO - EXTRACT 'public.publisher' - SUCCESS.
2024-11-17 02:08:56,572 - INFO - EXTRACT 'public.shipping_method' - SUCCESS.
2024-11-17 02:08:56,572 - INFO - EXTRACT ALL TABLE FROM SOURCE DATABASE - SUCCESS!
2024-11-17 02:08:56,573 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-17 02:08:56,573 - INFO - [pid 54415] Worker Worker(salt=9286198195, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=54415) done      Extract()
2024-11-17 02:08:56,581 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-17 02:08:56,584 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-17 02:08:56,585 - DEBUG - Asking scheduler for work...
2024-11-17 02:08:56,586 - DEBUG - Pending tasks: 1
2024-11-17 02:08:56,587 - INFO - [pid 54415] Worker Worker(salt=9286198195, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=54415) running   Load()
2024-11-17 02:08:56,651 - INFO - Read Extracted Data - SUCCESS!
2024-11-17 02:08:56,651 - INFO - Connect to DWH - SUCCESS!
2024-11-17 02:08:56,651 - INFO - ==================================STARTING LOAD DATA=======================================
2024-11-17 02:08:56,785 - ERROR - LOAD All Tables To Pacbook DWH Staging Schema - FAILED!
2024-11-17 02:08:56,787 - ERROR - LOAD All Tables to Pacbook DWH Staging Schema - FAILED
2024-11-17 02:08:56,787 - ERROR - [pid 54415] Worker Worker(salt=9286198195, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=54415) failed    Load()
Traceback (most recent call last):
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2119, in _exec_insertmany_context
    dialect.do_execute(
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.ForeignKeyViolation: insert or update on table "address" violates foreign key constraint "fk_addr_ctry"
DETAIL:  Key (country_id)=(95) is not present in table "country".


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pipeline/load.py", line 114, in run
    address.to_sql('address',
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/pandas/util/_decorators.py", line 333, in wrapper
    return func(*args, **kwargs)
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/pandas/core/generic.py", line 3084, in to_sql
    return sql.to_sql(
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/pandas/io/sql.py", line 842, in to_sql
    return pandas_sql.to_sql(
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/pandas/io/sql.py", line 2018, in to_sql
    total_inserted = sql_engine.insert_records(
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/pandas/io/sql.py", line 1567, in insert_records
    raise err
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/pandas/io/sql.py", line 1558, in insert_records
    return table.insert(chunksize=chunksize, method=method)
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/pandas/io/sql.py", line 1119, in insert
    num_inserted = exec_insert(conn, keys, chunk_iter)
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/pandas/io/sql.py", line 1010, in _execute_insert
    result = conn.execute(self.table.insert(), data)
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1847, in _execute_context
    return self._exec_insertmany_context(dialect, context)
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2127, in _exec_insertmany_context
    self._handle_dbapi_exception(
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2119, in _exec_insertmany_context
    dialect.do_execute(
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.ForeignKeyViolation) insert or update on table "address" violates foreign key constraint "fk_addr_ctry"
DETAIL:  Key (country_id)=(95) is not present in table "country".

[SQL: INSERT INTO stg.address (address_id, street_number, street_name, city, country_id) VALUES (%(address_id__0)s, %(street_number__0)s, %(street_name__0)s, %(city__0)s, %(country_id__0)s), (%(address_id__1)s, %(street_number__1)s, %(street_name__1)s, %(c ... 104188 characters truncated ... address_id__999)s, %(street_number__999)s, %(street_name__999)s, %(city__999)s, %(country_id__999)s)]
[parameters: {'country_id__0': 95, 'address_id__0': 1, 'street_number__0': 57, 'street_name__0': 'Glacier Hill Avenue', 'city__0': 'Torbat-e Jām', 'country_id__1': 37, 'address_id__1': 2, 'street_number__1': 86, 'street_name__1': 'Dottie Junction', 'city__1': 'Beaumont', 'country_id__2': 60, 'address_id__2': 3, 'street_number__2': 292, 'street_name__2': 'Ramsey Avenue', 'city__2': 'Cayambe', 'country_id__3': 47, 'address_id__3': 4, 'street_number__3': 5618, 'street_name__3': 'Thackeray Junction', 'city__3': 'Caldas', 'country_id__4': 153, 'address_id__4': 5, 'street_number__4': 4, 'street_name__4': '2nd Park', 'city__4': 'Ngunguru', 'country_id__5': 159, 'address_id__5': 6, 'street_number__5': 387, 'street_name__5': 'Nancy Junction', 'city__5': 'Burirao', 'country_id__6': 42, 'address_id__6': 7, 'street_number__6': 501, 'street_name__6': 'Atwood Point', 'city__6': 'Nirji', 'country_id__7': 164, 'address_id__7': 8, 'street_number__7': 42, 'street_name__7': 'North Pass', 'city__7': 'Tijão', 'country_id__8': 164, 'address_id__8': 9, 'street_number__8': 83, 'street_name__8': 'Graceland Pass', 'city__8': 'Castelo de Vide', 'country_id__9': 42, 'address_id__9': 10, 'street_number__9': 93, 'street_name__9': 'Clyde Gallagher Road', 'city__9': 'Shangde' ... 4900 parameters truncated ... 'country_id__990': 69, 'address_id__990': 991, 'street_number__990': 510, 'street_name__990': 'Heath Street', 'city__990': 'Parikkala', 'country_id__991': 200, 'address_id__991': 992, 'street_number__991': 71, 'street_name__991': 'Sheridan Park', 'city__991': 'Ongkharak', 'country_id__992': 70, 'address_id__992': 993, 'street_number__992': 5329, 'street_name__992': 'Carpenter Street', 'city__992': 'Paris 08', 'country_id__993': 194, 'address_id__993': 994, 'street_number__993': 61170, 'street_name__993': 'Arkansas Hill', 'city__993': 'Vellinge', 'country_id__994': 158, 'address_id__994': 995, 'street_number__994': 70837, 'street_name__994': 'Lindbergh Drive', 'city__994': 'Santa Rosa', 'country_id__995': 92, 'address_id__995': 996, 'street_number__995': 5, 'street_name__995': 'Leroy Alley', 'city__995': 'Mmaaf', 'country_id__996': 53, 'address_id__996': 997, 'street_number__996': 24, 'street_name__996': 'Morningstar Junction', 'city__996': 'Jobabo', 'country_id__997': 42, 'address_id__997': 998, 'street_number__997': 429, 'street_name__997': 'Autumn Leaf Parkway', 'city__997': 'Changxingbao', 'country_id__998': 92, 'address_id__998': 999, 'street_number__998': 2, 'street_name__998': 'Moose Crossing', 'city__998': 'Pasararba', 'country_id__999': 42, 'address_id__999': 1000, 'street_number__999': 503, 'street_name__999': 'Canary Crossing', 'city__999': 'Jiangfeng'}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pipeline/load.py", line 253, in run
    raise Exception('Failed Load Tables To Pacbook DWH Staging Schema!')
Exception: Failed Load Tables To Pacbook DWH Staging Schema!

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pipeline/load.py", line 293, in run
    raise Exception('Failed Load Tables To Pacbook DWH Staging Schema!')
Exception: Failed Load Tables To Pacbook DWH Staging Schema!
2024-11-17 02:08:56,799 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-17 02:08:56,808 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2024-11-17 02:08:56,808 - DEBUG - Asking scheduler for work...
2024-11-17 02:08:56,811 - DEBUG - Done
2024-11-17 02:08:56,811 - DEBUG - There are no more tasks to run at this time
2024-11-17 02:08:56,811 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-11-17 02:08:56,811 - DEBUG - There are 1 pending tasks unique to this worker
2024-11-17 02:08:56,811 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-11-17 02:08:56,811 - INFO - Worker Worker(salt=9286198195, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=54415) was stopped. Shutting down Keep-Alive thread
2024-11-17 02:08:56,812 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-17 02:33:53,694 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-17 02:33:53,779 - INFO - EXTRACT 'public.address' - SUCCESS.
2024-11-17 02:33:53,783 - INFO - EXTRACT 'public.address_status' - SUCCESS.
2024-11-17 02:33:53,815 - INFO - EXTRACT 'public.author' - SUCCESS.
2024-11-17 02:33:53,908 - INFO - EXTRACT 'public.book' - SUCCESS.
2024-11-17 02:33:53,949 - INFO - EXTRACT 'public.book_author' - SUCCESS.
2024-11-17 02:33:53,954 - INFO - EXTRACT 'public.book_language' - SUCCESS.
2024-11-17 02:33:53,958 - INFO - EXTRACT 'public.country' - SUCCESS.
2024-11-17 02:33:54,032 - INFO - EXTRACT 'public.cust_order' - SUCCESS.
2024-11-17 02:33:54,041 - INFO - EXTRACT 'public.customer' - SUCCESS.
2024-11-17 02:33:54,051 - INFO - EXTRACT 'public.customer_address' - SUCCESS.
2024-11-17 02:33:54,169 - INFO - EXTRACT 'public.order_history' - SUCCESS.
2024-11-17 02:33:54,258 - INFO - EXTRACT 'public.order_line' - SUCCESS.
2024-11-17 02:33:54,262 - INFO - EXTRACT 'public.order_status' - SUCCESS.
2024-11-17 02:33:54,269 - INFO - EXTRACT 'public.publisher' - SUCCESS.
2024-11-17 02:33:54,272 - INFO - EXTRACT 'public.shipping_method' - SUCCESS.
2024-11-17 02:33:54,273 - INFO - EXTRACT ALL TABLE FROM SOURCE DATABASE - SUCCESS!
2024-11-17 02:33:54,274 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-17 02:33:54,274 - INFO - [pid 63772] Worker Worker(salt=5401546570, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=63772) done      Extract()
2024-11-17 02:33:54,274 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-17 02:33:54,278 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-17 02:33:54,278 - DEBUG - Asking scheduler for work...
2024-11-17 02:33:54,280 - DEBUG - Pending tasks: 1
2024-11-17 02:33:54,280 - INFO - [pid 63772] Worker Worker(salt=5401546570, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=63772) running   Load()
2024-11-17 02:33:54,352 - INFO - Read Extracted Data - SUCCESS!
2024-11-17 02:33:54,353 - INFO - Connect to DWH - SUCCESS!
2024-11-17 02:33:54,353 - INFO - ==================================STARTING LOAD DATA=======================================
2024-11-17 02:33:54,396 - INFO - Load country table - SUCCESS!
2024-11-17 02:33:54,456 - INFO - Load address table - SUCCESS!
2024-11-17 02:33:54,463 - ERROR - LOAD All Tables To Pacbook DWH Staging Schema - FAILED!
2024-11-17 02:33:54,465 - ERROR - LOAD All Tables to Pacbook DWH Staging Schema - FAILED
2024-11-17 02:33:54,465 - ERROR - [pid 63772] Worker Worker(salt=5401546570, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=63772) failed    Load()
Traceback (most recent call last):
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2119, in _exec_insertmany_context
    dialect.do_execute(
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "status_id" of relation "address_status" does not exist
LINE 1: INSERT INTO stg.address_status (status_id, address_status) V...
                                        ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pipeline/load.py", line 132, in run
    address_status.to_sql('address_status',
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/pandas/util/_decorators.py", line 333, in wrapper
    return func(*args, **kwargs)
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/pandas/core/generic.py", line 3084, in to_sql
    return sql.to_sql(
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/pandas/io/sql.py", line 842, in to_sql
    return pandas_sql.to_sql(
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/pandas/io/sql.py", line 2018, in to_sql
    total_inserted = sql_engine.insert_records(
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/pandas/io/sql.py", line 1567, in insert_records
    raise err
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/pandas/io/sql.py", line 1558, in insert_records
    return table.insert(chunksize=chunksize, method=method)
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/pandas/io/sql.py", line 1119, in insert
    num_inserted = exec_insert(conn, keys, chunk_iter)
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/pandas/io/sql.py", line 1010, in _execute_insert
    result = conn.execute(self.table.insert(), data)
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1847, in _execute_context
    return self._exec_insertmany_context(dialect, context)
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2127, in _exec_insertmany_context
    self._handle_dbapi_exception(
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2119, in _exec_insertmany_context
    dialect.do_execute(
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "status_id" of relation "address_status" does not exist
LINE 1: INSERT INTO stg.address_status (status_id, address_status) V...
                                        ^

[SQL: INSERT INTO stg.address_status (status_id, address_status) VALUES (%(status_id__0)s, %(address_status__0)s), (%(status_id__1)s, %(address_status__1)s)]
[parameters: {'address_status__0': 'Active', 'status_id__0': 1, 'address_status__1': 'Inactive', 'status_id__1': 2}]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pipeline/load.py", line 253, in run
    raise Exception('Failed Load Tables To Pacbook DWH Staging Schema!')
Exception: Failed Load Tables To Pacbook DWH Staging Schema!

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pipeline/load.py", line 293, in run
    raise Exception('Failed Load Tables To Pacbook DWH Staging Schema!')
Exception: Failed Load Tables To Pacbook DWH Staging Schema!
2024-11-17 02:33:54,477 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-17 02:33:54,484 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2024-11-17 02:33:54,484 - DEBUG - Asking scheduler for work...
2024-11-17 02:33:54,486 - DEBUG - Done
2024-11-17 02:33:54,486 - DEBUG - There are no more tasks to run at this time
2024-11-17 02:33:54,486 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-11-17 02:33:54,487 - DEBUG - There are 1 pending tasks unique to this worker
2024-11-17 02:33:54,487 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-11-17 02:33:54,487 - INFO - Worker Worker(salt=5401546570, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=63772) was stopped. Shutting down Keep-Alive thread
2024-11-17 02:33:54,488 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-17 10:54:13,593 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-17 10:54:13,686 - INFO - EXTRACT 'public.address' - SUCCESS.
2024-11-17 10:54:13,697 - INFO - EXTRACT 'public.address_status' - SUCCESS.
2024-11-17 10:54:13,760 - INFO - EXTRACT 'public.author' - SUCCESS.
2024-11-17 10:54:13,911 - INFO - EXTRACT 'public.book' - SUCCESS.
2024-11-17 10:54:14,060 - INFO - EXTRACT 'public.book_author' - SUCCESS.
2024-11-17 10:54:14,080 - INFO - EXTRACT 'public.book_language' - SUCCESS.
2024-11-17 10:54:14,100 - INFO - EXTRACT 'public.country' - SUCCESS.
2024-11-17 10:54:14,417 - INFO - EXTRACT 'public.cust_order' - SUCCESS.
2024-11-17 10:54:14,447 - INFO - EXTRACT 'public.customer' - SUCCESS.
2024-11-17 10:54:14,482 - INFO - EXTRACT 'public.customer_address' - SUCCESS.
2024-11-17 10:54:14,836 - INFO - EXTRACT 'public.order_history' - SUCCESS.
2024-11-17 10:54:15,124 - INFO - EXTRACT 'public.order_line' - SUCCESS.
2024-11-17 10:54:15,149 - INFO - EXTRACT 'public.order_status' - SUCCESS.
2024-11-17 10:54:15,181 - INFO - EXTRACT 'public.publisher' - SUCCESS.
2024-11-17 10:54:15,200 - INFO - EXTRACT 'public.shipping_method' - SUCCESS.
2024-11-17 10:54:15,200 - INFO - EXTRACT ALL TABLE FROM SOURCE DATABASE - SUCCESS!
2024-11-17 10:54:15,208 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-17 10:54:15,209 - INFO - [pid 7268] Worker Worker(salt=5456719372, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=7268) done      Extract()
2024-11-17 10:54:15,211 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-17 10:54:15,224 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-17 10:54:15,225 - DEBUG - Asking scheduler for work...
2024-11-17 10:54:15,236 - DEBUG - Pending tasks: 1
2024-11-17 10:54:15,237 - INFO - [pid 7268] Worker Worker(salt=5456719372, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=7268) running   Load()
2024-11-17 10:54:15,457 - INFO - Read Extracted Data - SUCCESS!
2024-11-17 10:54:15,458 - INFO - Connect to DWH - SUCCESS!
2024-11-17 10:54:15,459 - INFO - ==================================STARTING LOAD DATA=======================================
2024-11-17 10:54:15,531 - INFO - Load country table - SUCCESS!
2024-11-17 10:54:15,661 - INFO - Load address table - SUCCESS!
2024-11-17 10:54:15,676 - ERROR - LOAD All Tables To Pacbook DWH Staging Schema - FAILED!
2024-11-17 10:54:15,680 - ERROR - LOAD All Tables to Pacbook DWH Staging Schema - FAILED
2024-11-17 10:54:15,680 - ERROR - [pid 7268] Worker Worker(salt=5456719372, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=7268) failed    Load()
Traceback (most recent call last):
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2119, in _exec_insertmany_context
    dialect.do_execute(
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "address_status" of relation "address_status" does not exist
LINE 1: INSERT INTO stg.address_status (status_id, address_status) V...
                                                   ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pipeline/load.py", line 132, in run
    address_status.to_sql('address_status',
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/pandas/util/_decorators.py", line 333, in wrapper
    return func(*args, **kwargs)
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/pandas/core/generic.py", line 3084, in to_sql
    return sql.to_sql(
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/pandas/io/sql.py", line 842, in to_sql
    return pandas_sql.to_sql(
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/pandas/io/sql.py", line 2018, in to_sql
    total_inserted = sql_engine.insert_records(
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/pandas/io/sql.py", line 1567, in insert_records
    raise err
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/pandas/io/sql.py", line 1558, in insert_records
    return table.insert(chunksize=chunksize, method=method)
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/pandas/io/sql.py", line 1119, in insert
    num_inserted = exec_insert(conn, keys, chunk_iter)
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/pandas/io/sql.py", line 1010, in _execute_insert
    result = conn.execute(self.table.insert(), data)
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1847, in _execute_context
    return self._exec_insertmany_context(dialect, context)
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2127, in _exec_insertmany_context
    self._handle_dbapi_exception(
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2119, in _exec_insertmany_context
    dialect.do_execute(
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "address_status" of relation "address_status" does not exist
LINE 1: INSERT INTO stg.address_status (status_id, address_status) V...
                                                   ^

[SQL: INSERT INTO stg.address_status (status_id, address_status) VALUES (%(status_id__0)s, %(address_status__0)s), (%(status_id__1)s, %(address_status__1)s)]
[parameters: {'status_id__0': 1, 'address_status__0': 'Active', 'status_id__1': 2, 'address_status__1': 'Inactive'}]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pipeline/load.py", line 253, in run
    raise Exception('Failed Load Tables To Pacbook DWH Staging Schema!')
Exception: Failed Load Tables To Pacbook DWH Staging Schema!

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pipeline/load.py", line 293, in run
    raise Exception('Failed Load Tables To Pacbook DWH Staging Schema!')
Exception: Failed Load Tables To Pacbook DWH Staging Schema!
2024-11-17 10:54:15,734 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-17 10:54:15,759 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2024-11-17 10:54:15,760 - DEBUG - Asking scheduler for work...
2024-11-17 10:54:15,771 - DEBUG - Done
2024-11-17 10:54:15,772 - DEBUG - There are no more tasks to run at this time
2024-11-17 10:54:15,773 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-11-17 10:54:15,773 - DEBUG - There are 1 pending tasks unique to this worker
2024-11-17 10:54:15,774 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-11-17 10:54:15,775 - INFO - Worker Worker(salt=5456719372, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=7268) was stopped. Shutting down Keep-Alive thread
2024-11-17 10:54:15,779 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-17 10:57:18,394 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-17 10:57:18,616 - INFO - EXTRACT 'public.address' - SUCCESS.
2024-11-17 10:57:18,636 - INFO - EXTRACT 'public.address_status' - SUCCESS.
2024-11-17 10:57:18,825 - INFO - EXTRACT 'public.author' - SUCCESS.
2024-11-17 10:57:19,152 - INFO - EXTRACT 'public.book' - SUCCESS.
2024-11-17 10:57:19,321 - INFO - EXTRACT 'public.book_author' - SUCCESS.
2024-11-17 10:57:19,341 - INFO - EXTRACT 'public.book_language' - SUCCESS.
2024-11-17 10:57:19,362 - INFO - EXTRACT 'public.country' - SUCCESS.
2024-11-17 10:57:19,677 - INFO - EXTRACT 'public.cust_order' - SUCCESS.
2024-11-17 10:57:19,720 - INFO - EXTRACT 'public.customer' - SUCCESS.
2024-11-17 10:57:19,782 - INFO - EXTRACT 'public.customer_address' - SUCCESS.
2024-11-17 10:57:20,321 - INFO - EXTRACT 'public.order_history' - SUCCESS.
2024-11-17 10:57:20,614 - INFO - EXTRACT 'public.order_line' - SUCCESS.
2024-11-17 10:57:20,623 - INFO - EXTRACT 'public.order_status' - SUCCESS.
2024-11-17 10:57:20,644 - INFO - EXTRACT 'public.publisher' - SUCCESS.
2024-11-17 10:57:20,652 - INFO - EXTRACT 'public.shipping_method' - SUCCESS.
2024-11-17 10:57:20,652 - INFO - EXTRACT ALL TABLE FROM SOURCE DATABASE - SUCCESS!
2024-11-17 10:57:20,654 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-17 10:57:20,655 - INFO - [pid 8704] Worker Worker(salt=8572889042, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=8704) done      Extract()
2024-11-17 10:57:20,656 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-17 10:57:20,662 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-17 10:57:20,663 - DEBUG - Asking scheduler for work...
2024-11-17 10:57:20,669 - DEBUG - Pending tasks: 1
2024-11-17 10:57:20,670 - INFO - [pid 8704] Worker Worker(salt=8572889042, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=8704) running   Load()
2024-11-17 10:57:20,855 - INFO - Read Extracted Data - SUCCESS!
2024-11-17 10:57:20,857 - INFO - Connect to DWH - SUCCESS!
2024-11-17 10:57:20,857 - INFO - ==================================STARTING LOAD DATA=======================================
2024-11-17 10:57:20,986 - INFO - Load country table - SUCCESS!
2024-11-17 10:57:21,114 - INFO - Load address table - SUCCESS!
2024-11-17 10:57:21,126 - INFO - Load address_status table - SUCCESS!
2024-11-17 10:57:21,138 - INFO - Load book_language table - SUCCESS!
2024-11-17 10:57:21,261 - INFO - Load customer table - SUCCESS!
2024-11-17 10:57:21,336 - INFO - Load publisher table - SUCCESS!
2024-11-17 10:57:21,363 - INFO - Load shipping_method table - SUCCESS!
2024-11-17 10:57:22,020 - INFO - Load author table - SUCCESS!
2024-11-17 10:57:22,602 - ERROR - LOAD All Tables To Pacbook DWH Staging Schema - FAILED!
2024-11-17 10:57:22,608 - ERROR - LOAD All Tables to Pacbook DWH Staging Schema - FAILED
2024-11-17 10:57:22,609 - ERROR - [pid 8704] Worker Worker(salt=8572889042, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=8704) failed    Load()
Traceback (most recent call last):
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2119, in _exec_insertmany_context
    dialect.do_execute(
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "publication_date" of relation "book" does not exist
LINE 1: ... (book_id, title, isbn13, language_id, num_pages, publicatio...
                                                             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pipeline/load.py", line 186, in run
    book.to_sql('book',
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/pandas/util/_decorators.py", line 333, in wrapper
    return func(*args, **kwargs)
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/pandas/core/generic.py", line 3084, in to_sql
    return sql.to_sql(
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/pandas/io/sql.py", line 842, in to_sql
    return pandas_sql.to_sql(
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/pandas/io/sql.py", line 2018, in to_sql
    total_inserted = sql_engine.insert_records(
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/pandas/io/sql.py", line 1567, in insert_records
    raise err
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/pandas/io/sql.py", line 1558, in insert_records
    return table.insert(chunksize=chunksize, method=method)
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/pandas/io/sql.py", line 1119, in insert
    num_inserted = exec_insert(conn, keys, chunk_iter)
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/pandas/io/sql.py", line 1010, in _execute_insert
    result = conn.execute(self.table.insert(), data)
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1847, in _execute_context
    return self._exec_insertmany_context(dialect, context)
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2127, in _exec_insertmany_context
    self._handle_dbapi_exception(
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2119, in _exec_insertmany_context
    dialect.do_execute(
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "publication_date" of relation "book" does not exist
LINE 1: ... (book_id, title, isbn13, language_id, num_pages, publicatio...
                                                             ^

[SQL: INSERT INTO stg.book (book_id, title, isbn13, language_id, num_pages, publication_date, publisher_id) VALUES (%(book_id__0)s, %(title__0)s, %(isbn13__0)s, %(language_id__0)s, %(num_pages__0)s, %(publication_date__0)s, %(publisher_id__0)s), (%(book_id ... 143987 characters truncated ... __999)s, %(language_id__999)s, %(num_pages__999)s, %(publication_date__999)s, %(publisher_id__999)s)]
[parameters: {'isbn13__0': 8987059752, 'num_pages__0': 276, 'publisher_id__0': 1010, 'book_id__0': 1, 'publication_date__0': '1996-09-01', 'title__0': "The World's First Love: Mary  Mother of God", 'language_id__0': 2, 'isbn13__1': 20049130001, 'num_pages__1': 352, 'publisher_id__1': 1967, 'book_id__1': 2, 'publication_date__1': '2004-10-04', 'title__1': 'The Illuminati', 'language_id__1': 1, 'isbn13__2': 23755004321, 'num_pages__2': 128, 'publisher_id__2': 1967, 'book_id__2': 3, 'publication_date__2': '2003-03-11', 'title__2': 'The Servant Leader', 'language_id__2': 1, 'isbn13__3': 34406054602, 'num_pages__3': 168, 'publisher_id__3': 1978, 'book_id__3': 4, 'publication_date__3': '1999-09-01', 'title__3': 'What Life Was Like in the Jewel in the Crown: British India  AD 1600-1905', 'language_id__3': 1, 'isbn13__4': 49086007763, 'num_pages__4': 80, 'publisher_id__4': 416, 'book_id__4': 5, 'publication_date__4': '1983-12-29', 'title__4': "Cliffs Notes on Aristophanes' Lysistrata  The Birds  The Clouds  The Frogs", 'language_id__4': 1, 'isbn13__5': 73999140774, 'num_pages__5': 298, 'publisher_id__5': 96, 'book_id__5': 6, 'publication_date__5': '2000-04-01', 'title__5': "Life Is a Dream and Other Spanish Classics (Eric Bentley's Dramatic Repertoire) - Volume II", 'language_id__5': 1, 'isbn13__6': 73999254907, 'num_pages__6': 504, 'publisher_id__6': 95, 'book_id__6': 7, 'publication_date__6': '2000-05-01', 'title__6': 'William Goldman: Four Screenplays', 'language_id__6': 2, 'isbn13__7': 73999768442 ... 6900 parameters truncated ... 'language_id__992': 1, 'isbn13__993': 9780140119503, 'num_pages__993': 240, 'publisher_id__993': 1476, 'book_id__993': 991, 'publication_date__993': '1990-05-01', 'title__993': 'If the River Was Whiskey', 'language_id__993': 1, 'isbn13__994': 9780140127225, 'num_pages__994': 107, 'publisher_id__994': 1476, 'book_id__994': 992, 'publication_date__994': '1992-01-01', 'title__994': 'On Directing Film', 'language_id__994': 1, 'isbn13__995': 9780140128468, 'num_pages__995': 270, 'publisher_id__995': 1476, 'book_id__995': 993, 'publication_date__995': '1995-01-31', 'title__995': "Love's Executioner  And Other Tales Of Psychotherapy", 'language_id__995': 1, 'isbn13__996': 9780140131673, 'num_pages__996': 384, 'publisher_id__996': 1476, 'book_id__996': 994, 'publication_date__996': '1991-08-01', 'title__996': 'East Is East', 'language_id__996': 1, 'isbn13__997': 9780140131963, 'num_pages__997': 415, 'publisher_id__997': 1476, 'book_id__997': 995, 'publication_date__997': '1993-08-01', 'title__997': 'The Ice-Shirt (Seven Dreams #1)', 'language_id__997': 1, 'isbn13__998': 9780140137002, 'num_pages__998': 400, 'publisher_id__998': 1470, 'book_id__998': 996, 'publication_date__998': '2002-12-05', 'title__998': 'Montaillou: Cathars and Catholics in a French Village 1294-1324', 'language_id__998': 1, 'isbn13__999': 9780140137347, 'num_pages__999': 304, 'publisher_id__999': 1470, 'book_id__999': 997, 'publication_date__999': '1998-07-30', 'title__999': 'The History of Sexuality  Volume 2: The Use of Pleasure', 'language_id__999': 1}]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pipeline/load.py", line 253, in run
    raise Exception('Failed Load Tables To Pacbook DWH Staging Schema!')
Exception: Failed Load Tables To Pacbook DWH Staging Schema!

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pipeline/load.py", line 293, in run
    raise Exception('Failed Load Tables To Pacbook DWH Staging Schema!')
Exception: Failed Load Tables To Pacbook DWH Staging Schema!
2024-11-17 10:57:22,773 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-17 10:57:22,808 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2024-11-17 10:57:22,809 - DEBUG - Asking scheduler for work...
2024-11-17 10:57:22,822 - DEBUG - Done
2024-11-17 10:57:22,822 - DEBUG - There are no more tasks to run at this time
2024-11-17 10:57:22,823 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-11-17 10:57:22,823 - DEBUG - There are 1 pending tasks unique to this worker
2024-11-17 10:57:22,824 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-11-17 10:57:22,825 - INFO - Worker Worker(salt=8572889042, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=8704) was stopped. Shutting down Keep-Alive thread
2024-11-17 10:57:22,830 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-17 10:59:50,527 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-17 10:59:50,605 - INFO - EXTRACT 'public.address' - SUCCESS.
2024-11-17 10:59:50,615 - INFO - EXTRACT 'public.address_status' - SUCCESS.
2024-11-17 10:59:50,730 - INFO - EXTRACT 'public.author' - SUCCESS.
2024-11-17 10:59:50,957 - INFO - EXTRACT 'public.book' - SUCCESS.
2024-11-17 10:59:51,044 - INFO - EXTRACT 'public.book_author' - SUCCESS.
2024-11-17 10:59:51,052 - INFO - EXTRACT 'public.book_language' - SUCCESS.
2024-11-17 10:59:51,064 - INFO - EXTRACT 'public.country' - SUCCESS.
2024-11-17 10:59:51,399 - INFO - EXTRACT 'public.cust_order' - SUCCESS.
2024-11-17 10:59:51,447 - INFO - EXTRACT 'public.customer' - SUCCESS.
2024-11-17 10:59:51,492 - INFO - EXTRACT 'public.customer_address' - SUCCESS.
2024-11-17 10:59:51,962 - INFO - EXTRACT 'public.order_history' - SUCCESS.
2024-11-17 10:59:52,311 - INFO - EXTRACT 'public.order_line' - SUCCESS.
2024-11-17 10:59:52,327 - INFO - EXTRACT 'public.order_status' - SUCCESS.
2024-11-17 10:59:52,364 - INFO - EXTRACT 'public.publisher' - SUCCESS.
2024-11-17 10:59:52,379 - INFO - EXTRACT 'public.shipping_method' - SUCCESS.
2024-11-17 10:59:52,379 - INFO - EXTRACT ALL TABLE FROM SOURCE DATABASE - SUCCESS!
2024-11-17 10:59:52,384 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-17 10:59:52,384 - INFO - [pid 9748] Worker Worker(salt=4126316793, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=9748) done      Extract()
2024-11-17 10:59:52,391 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-17 10:59:52,402 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-17 10:59:52,403 - DEBUG - Asking scheduler for work...
2024-11-17 10:59:52,413 - DEBUG - Pending tasks: 1
2024-11-17 10:59:52,413 - INFO - [pid 9748] Worker Worker(salt=4126316793, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=9748) running   Load()
2024-11-17 10:59:52,820 - INFO - Read Extracted Data - SUCCESS!
2024-11-17 10:59:52,821 - INFO - Connect to DWH - SUCCESS!
2024-11-17 10:59:52,821 - INFO - ==================================STARTING LOAD DATA=======================================
2024-11-17 10:59:52,923 - INFO - Load country table - SUCCESS!
2024-11-17 10:59:53,189 - INFO - Load address table - SUCCESS!
2024-11-17 10:59:53,209 - INFO - Load address_status table - SUCCESS!
2024-11-17 10:59:53,226 - INFO - Load book_language table - SUCCESS!
2024-11-17 10:59:53,301 - INFO - Load customer table - SUCCESS!
2024-11-17 10:59:53,403 - INFO - Load publisher table - SUCCESS!
2024-11-17 10:59:53,428 - INFO - Load shipping_method table - SUCCESS!
2024-11-17 10:59:53,930 - INFO - Load author table - SUCCESS!
2024-11-17 10:59:55,375 - INFO - Load book table - SUCCESS!
2024-11-17 10:59:56,207 - INFO - Load cust_order table - SUCCESS!
2024-11-17 10:59:56,707 - INFO - Load customer_address table - SUCCESS!
2024-11-17 10:59:56,742 - INFO - Load order_status table - SUCCESS!
2024-11-17 10:59:57,745 - INFO - Load book_author table - SUCCESS!
2024-11-17 10:59:59,613 - INFO - Load order_history table - SUCCESS!
2024-11-17 11:00:00,932 - INFO - Load order_line table - SUCCESS!
2024-11-17 11:00:00,933 - INFO - LOAD All Tables To Pacbook DWH Staging Schema - SUCCESS!
2024-11-17 11:00:00,938 - INFO - ==================================ENDING LOAD DATA=======================================
2024-11-17 11:00:00,941 - INFO - [pid 9748] Worker Worker(salt=4126316793, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=9748) done      Load()
2024-11-17 11:00:00,942 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-17 11:00:00,951 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-11-17 11:00:00,951 - DEBUG - Asking scheduler for work...
2024-11-17 11:00:00,959 - DEBUG - Done
2024-11-17 11:00:00,959 - DEBUG - There are no more tasks to run at this time
2024-11-17 11:00:00,960 - INFO - Worker Worker(salt=4126316793, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=9748) was stopped. Shutting down Keep-Alive thread
2024-11-17 11:00:00,963 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()

This progress looks :) because there were no failed tasks or missing dependencies

===== Luigi Execution Summary =====

2024-11-19 14:58:01,656 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-19 14:58:01,923 - INFO - EXTRACT 'public.address' - SUCCESS.
2024-11-19 14:58:01,940 - INFO - EXTRACT 'public.address_status' - SUCCESS.
2024-11-19 14:58:02,066 - INFO - EXTRACT 'public.author' - SUCCESS.
2024-11-19 14:58:02,416 - INFO - EXTRACT 'public.book' - SUCCESS.
2024-11-19 14:58:02,622 - INFO - EXTRACT 'public.book_author' - SUCCESS.
2024-11-19 14:58:02,645 - INFO - EXTRACT 'public.book_language' - SUCCESS.
2024-11-19 14:58:02,671 - INFO - EXTRACT 'public.country' - SUCCESS.
2024-11-19 14:58:02,823 - INFO - EXTRACT 'public.cust_order' - SUCCESS.
2024-11-19 14:58:02,847 - INFO - EXTRACT 'public.customer' - SUCCESS.
2024-11-19 14:58:02,874 - INFO - EXTRACT 'public.customer_address' - SUCCESS.
2024-11-19 14:58:03,398 - INFO - EXTRACT 'public.order_history' - SUCCESS.
2024-11-19 14:58:03,746 - INFO - EXTRACT 'public.order_line' - SUCCESS.
2024-11-19 14:58:03,764 - INFO - EXTRACT 'public.order_status' - SUCCESS.
2024-11-19 14:58:03,805 - INFO - EXTRACT 'public.publisher' - SUCCESS.
2024-11-19 14:58:03,825 - INFO - EXTRACT 'public.shipping_method' - SUCCESS.
2024-11-19 14:58:03,825 - INFO - EXTRACT ALL TABLE FROM SOURCE DATABASE - SUCCESS!
2024-11-19 14:58:03,832 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-19 14:58:03,833 - INFO - [pid 6347] Worker Worker(salt=7530064830, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=6347) done      Extract()
2024-11-19 14:58:03,835 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-19 14:58:03,848 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-19 14:58:03,849 - DEBUG - Asking scheduler for work...
2024-11-19 14:58:03,860 - DEBUG - Pending tasks: 1
2024-11-19 14:58:03,860 - INFO - [pid 6347] Worker Worker(salt=7530064830, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=6347) running   Load()
2024-11-19 14:58:04,311 - INFO - Read Extracted Data - SUCCESS!
2024-11-19 14:58:04,313 - INFO - Connect to DWH - SUCCESS!
2024-11-19 14:58:04,314 - INFO - ==================================STARTING LOAD DATA=======================================
2024-11-19 14:58:04,521 - INFO - Load country table - SUCCESS!
2024-11-19 14:58:04,835 - INFO - Load address table - SUCCESS!
2024-11-19 14:58:04,860 - INFO - Load address_status table - SUCCESS!
2024-11-19 14:58:04,891 - INFO - Load book_language table - SUCCESS!
2024-11-19 14:58:05,190 - INFO - Load customer table - SUCCESS!
2024-11-19 14:58:05,339 - INFO - Load publisher table - SUCCESS!
2024-11-19 14:58:05,368 - INFO - Load shipping_method table - SUCCESS!
2024-11-19 14:58:05,875 - INFO - Load author table - SUCCESS!
2024-11-19 14:58:07,811 - INFO - Load book table - SUCCESS!
2024-11-19 14:58:08,531 - INFO - Load cust_order table - SUCCESS!
2024-11-19 14:58:08,770 - INFO - Load customer_address table - SUCCESS!
2024-11-19 14:58:08,782 - INFO - Load order_status table - SUCCESS!
2024-11-19 14:58:10,115 - INFO - Load book_author table - SUCCESS!
2024-11-19 14:58:11,890 - INFO - Load order_history table - SUCCESS!
2024-11-19 14:58:13,316 - INFO - Load order_line table - SUCCESS!
2024-11-19 14:58:13,316 - INFO - LOAD All Tables To Pacbook DWH Staging Schema - SUCCESS!
2024-11-19 14:58:13,324 - INFO - ==================================ENDING LOAD DATA=======================================
2024-11-19 14:58:13,327 - INFO - [pid 6347] Worker Worker(salt=7530064830, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=6347) done      Load()
2024-11-19 14:58:13,328 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-19 14:58:13,337 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-11-19 14:58:13,337 - DEBUG - Asking scheduler for work...
2024-11-19 14:58:13,346 - DEBUG - Done
2024-11-19 14:58:13,347 - DEBUG - There are no more tasks to run at this time
2024-11-19 14:58:13,347 - INFO - Worker Worker(salt=7530064830, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=6347) was stopped. Shutting down Keep-Alive thread
2024-11-19 14:58:13,351 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()

This progress looks :) because there were no failed tasks or missing dependencies

===== Luigi Execution Summary =====

2024-11-19 15:08:59,570 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-19 15:08:59,715 - INFO - EXTRACT 'public.address' - SUCCESS.
2024-11-19 15:08:59,728 - INFO - EXTRACT 'public.address_status' - SUCCESS.
2024-11-19 15:08:59,817 - INFO - EXTRACT 'public.author' - SUCCESS.
2024-11-19 15:09:00,138 - INFO - EXTRACT 'public.book' - SUCCESS.
2024-11-19 15:09:00,293 - INFO - EXTRACT 'public.book_author' - SUCCESS.
2024-11-19 15:09:00,309 - INFO - EXTRACT 'public.book_language' - SUCCESS.
2024-11-19 15:09:00,326 - INFO - EXTRACT 'public.country' - SUCCESS.
2024-11-19 15:09:00,636 - INFO - EXTRACT 'public.cust_order' - SUCCESS.
2024-11-19 15:09:00,674 - INFO - EXTRACT 'public.customer' - SUCCESS.
2024-11-19 15:09:00,721 - INFO - EXTRACT 'public.customer_address' - SUCCESS.
2024-11-19 15:09:01,135 - INFO - EXTRACT 'public.order_history' - SUCCESS.
2024-11-19 15:09:01,295 - INFO - EXTRACT 'public.order_line' - SUCCESS.
2024-11-19 15:09:01,305 - INFO - EXTRACT 'public.order_status' - SUCCESS.
2024-11-19 15:09:01,325 - INFO - EXTRACT 'public.publisher' - SUCCESS.
2024-11-19 15:09:01,333 - INFO - EXTRACT 'public.shipping_method' - SUCCESS.
2024-11-19 15:09:01,333 - INFO - EXTRACT ALL TABLE FROM SOURCE DATABASE - SUCCESS!
2024-11-19 15:09:01,336 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-19 15:09:01,336 - INFO - [pid 10309] Worker Worker(salt=866252530, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=10309) done      Extract()
2024-11-19 15:09:01,337 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-19 15:09:01,344 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-19 15:09:01,345 - DEBUG - Asking scheduler for work...
2024-11-19 15:09:01,350 - DEBUG - Pending tasks: 1
2024-11-19 15:09:01,350 - INFO - [pid 10309] Worker Worker(salt=866252530, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=10309) running   Load()
2024-11-19 15:09:01,678 - INFO - Read Extracted Data - SUCCESS!
2024-11-19 15:09:01,680 - INFO - Connect to DWH - SUCCESS!
2024-11-19 15:09:01,680 - INFO - ==================================STARTING LOAD DATA=======================================
2024-11-19 15:09:01,763 - ERROR - LOAD All Tables To Pacbook DWH Staging Schema - FAILED!
2024-11-19 15:09:01,767 - ERROR - LOAD All Tables to Pacbook DWH Staging Schema - FAILED
2024-11-19 15:09:01,767 - ERROR - [pid 10309] Worker Worker(salt=866252530, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=10309) failed    Load()
Traceback (most recent call last):
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2119, in _exec_insertmany_context
    dialect.do_execute(
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "pk_country"
DETAIL:  Key (country_id)=(1) already exists.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pipeline/load.py", line 114, in run
    country.to_sql('country',
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/pandas/util/_decorators.py", line 333, in wrapper
    return func(*args, **kwargs)
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/pandas/core/generic.py", line 3084, in to_sql
    return sql.to_sql(
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/pandas/io/sql.py", line 842, in to_sql
    return pandas_sql.to_sql(
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/pandas/io/sql.py", line 2018, in to_sql
    total_inserted = sql_engine.insert_records(
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/pandas/io/sql.py", line 1567, in insert_records
    raise err
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/pandas/io/sql.py", line 1558, in insert_records
    return table.insert(chunksize=chunksize, method=method)
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/pandas/io/sql.py", line 1119, in insert
    num_inserted = exec_insert(conn, keys, chunk_iter)
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/pandas/io/sql.py", line 1010, in _execute_insert
    result = conn.execute(self.table.insert(), data)
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1421, in execute
    return meth(
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 514, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1643, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1847, in _execute_context
    return self._exec_insertmany_context(dialect, context)
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2127, in _exec_insertmany_context
    self._handle_dbapi_exception(
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2356, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2119, in _exec_insertmany_context
    dialect.do_execute(
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 924, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "pk_country"
DETAIL:  Key (country_id)=(1) already exists.

[SQL: INSERT INTO stg.country (country_id, country_name) VALUES (%(country_id__0)s, %(country_name__0)s), (%(country_id__1)s, %(country_name__1)s), (%(country_id__2)s, %(country_name__2)s), (%(country_id__3)s, %(country_name__3)s), (%(country_id__4)s, %(co ... 10158 characters truncated ... __229)s), (%(country_id__230)s, %(country_name__230)s), (%(country_id__231)s, %(country_name__231)s)]
[parameters: {'country_id__0': 1, 'country_name__0': 'Afghanistan', 'country_id__1': 2, 'country_name__1': 'Netherlands Antilles', 'country_id__2': 3, 'country_name__2': 'Albania', 'country_id__3': 4, 'country_name__3': 'Algeria', 'country_id__4': 5, 'country_name__4': 'Andorra', 'country_id__5': 6, 'country_name__5': 'Angola', 'country_id__6': 7, 'country_name__6': 'Antigua and Barbuda', 'country_id__7': 8, 'country_name__7': 'Australasia', 'country_id__8': 9, 'country_name__8': 'Argentina', 'country_id__9': 10, 'country_name__9': 'Armenia', 'country_id__10': 11, 'country_name__10': 'Aruba', 'country_id__11': 12, 'country_name__11': 'American Samoa', 'country_id__12': 13, 'country_name__12': 'Australia', 'country_id__13': 14, 'country_name__13': 'Austria', 'country_id__14': 15, 'country_name__14': 'Azerbaijan', 'country_id__15': 16, 'country_name__15': 'Bahamas', 'country_id__16': 17, 'country_name__16': 'Bangladesh', 'country_id__17': 18, 'country_name__17': 'Barbados', 'country_id__18': 19, 'country_name__18': 'Burundi', 'country_id__19': 20, 'country_name__19': 'Belgium', 'country_id__20': 21, 'country_name__20': 'Benin', 'country_id__21': 22, 'country_name__21': 'Bermuda', 'country_id__22': 23, 'country_name__22': 'Bhutan', 'country_id__23': 24, 'country_name__23': 'Bosnia and Herzegovina', 'country_id__24': 25, 'country_name__24': 'Belize' ... 364 parameters truncated ... 'country_id__207': 208, 'country_name__207': 'Turkey', 'country_id__208': 209, 'country_name__208': 'Tuvalu', 'country_id__209': 210, 'country_name__209': 'United Arab Emirates', 'country_id__210': 211, 'country_name__210': 'United Arab Republic', 'country_id__211': 212, 'country_name__211': 'Uganda', 'country_id__212': 213, 'country_name__212': 'Ukraine', 'country_id__213': 214, 'country_name__213': 'Unknown', 'country_id__214': 215, 'country_name__214': 'Soviet Union', 'country_id__215': 216, 'country_name__215': 'Uruguay', 'country_id__216': 217, 'country_name__216': 'United States of America', 'country_id__217': 218, 'country_name__217': 'Uzbekistan', 'country_id__218': 219, 'country_name__218': 'Vanuatu', 'country_id__219': 220, 'country_name__219': 'Venezuela', 'country_id__220': 221, 'country_name__220': 'Vietnam', 'country_id__221': 222, 'country_name__221': 'Saint Vincent', 'country_id__222': 223, 'country_name__222': 'Vietnam (pre)', 'country_id__223': 224, 'country_name__223': 'West Indies Federation', 'country_id__224': 225, 'country_name__224': 'North Yemen', 'country_id__225': 226, 'country_name__225': 'Yemen', 'country_id__226': 227, 'country_name__226': 'South Yemen', 'country_id__227': 228, 'country_name__227': 'Yugoslavia', 'country_id__228': 229, 'country_name__228': 'Zambia', 'country_id__229': 230, 'country_name__229': 'Zimbabwe', 'country_id__230': 231, 'country_name__230': 'Singapore', 'country_id__231': 232, 'country_name__231': 'French Polynesia'}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pipeline/load.py", line 253, in run
    raise Exception('Failed Load Tables To Pacbook DWH Staging Schema!')
Exception: Failed Load Tables To Pacbook DWH Staging Schema!

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pipeline/load.py", line 294, in run
    raise Exception('Failed Load Tables To Pacbook DWH Staging Schema!')
Exception: Failed Load Tables To Pacbook DWH Staging Schema!
2024-11-19 15:09:01,789 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-19 15:09:01,807 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2024-11-19 15:09:01,808 - DEBUG - Asking scheduler for work...
2024-11-19 15:09:01,825 - DEBUG - Done
2024-11-19 15:09:01,826 - DEBUG - There are no more tasks to run at this time
2024-11-19 15:09:01,826 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-11-19 15:09:01,826 - DEBUG - There are 1 pending tasks unique to this worker
2024-11-19 15:09:01,827 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-11-19 15:09:01,827 - INFO - Worker Worker(salt=866252530, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=10309) was stopped. Shutting down Keep-Alive thread
2024-11-19 15:09:01,831 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-19 15:21:45,736 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-19 15:21:45,775 - INFO - EXTRACT 'public.address' - SUCCESS.
2024-11-19 15:21:45,778 - INFO - EXTRACT 'public.address_status' - SUCCESS.
2024-11-19 15:21:45,800 - INFO - EXTRACT 'public.author' - SUCCESS.
2024-11-19 15:21:45,870 - INFO - EXTRACT 'public.book' - SUCCESS.
2024-11-19 15:21:45,903 - INFO - EXTRACT 'public.book_author' - SUCCESS.
2024-11-19 15:21:45,908 - INFO - EXTRACT 'public.book_language' - SUCCESS.
2024-11-19 15:21:45,912 - INFO - EXTRACT 'public.country' - SUCCESS.
2024-11-19 15:21:45,989 - INFO - EXTRACT 'public.cust_order' - SUCCESS.
2024-11-19 15:21:45,997 - INFO - EXTRACT 'public.customer' - SUCCESS.
2024-11-19 15:21:46,007 - INFO - EXTRACT 'public.customer_address' - SUCCESS.
2024-11-19 15:21:46,123 - INFO - EXTRACT 'public.order_history' - SUCCESS.
2024-11-19 15:21:46,219 - INFO - EXTRACT 'public.order_line' - SUCCESS.
2024-11-19 15:21:46,224 - INFO - EXTRACT 'public.order_status' - SUCCESS.
2024-11-19 15:21:46,231 - INFO - EXTRACT 'public.publisher' - SUCCESS.
2024-11-19 15:21:46,235 - INFO - EXTRACT 'public.shipping_method' - SUCCESS.
2024-11-19 15:21:46,236 - INFO - EXTRACT ALL TABLE FROM SOURCE DATABASE - SUCCESS!
2024-11-19 15:21:46,237 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-19 15:21:46,237 - INFO - [pid 14468] Worker Worker(salt=5750355571, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=14468) done      Extract()
2024-11-19 15:21:46,239 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-19 15:21:46,242 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-19 15:21:46,242 - DEBUG - Asking scheduler for work...
2024-11-19 15:21:46,244 - DEBUG - Pending tasks: 1
2024-11-19 15:21:46,244 - INFO - [pid 14468] Worker Worker(salt=5750355571, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=14468) running   Load()
2024-11-19 15:21:46,313 - INFO - Read Extracted Data - SUCCESS!
2024-11-19 15:21:46,314 - INFO - Connect to DWH - SUCCESS!
2024-11-19 15:21:46,315 - ERROR - Truncate Staging Schema in DWH - FAILED!
2024-11-19 15:21:46,315 - ERROR - [pid 14468] Worker Worker(salt=5750355571, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=14468) failed    Load()
Traceback (most recent call last):
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pipeline/load.py", line 127, in run
    query = sqlalchemy.text(query)
NameError: name 'sqlalchemy' is not defined

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pipeline/load.py", line 140, in run
    raise Exception("Failed to Truncate Staging Schema in DWH!")
Exception: Failed to Truncate Staging Schema in DWH!
2024-11-19 15:21:46,320 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-19 15:21:46,325 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2024-11-19 15:21:46,325 - DEBUG - Asking scheduler for work...
2024-11-19 15:21:46,328 - DEBUG - Done
2024-11-19 15:21:46,328 - DEBUG - There are no more tasks to run at this time
2024-11-19 15:21:46,328 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-11-19 15:21:46,328 - DEBUG - There are 1 pending tasks unique to this worker
2024-11-19 15:21:46,329 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-11-19 15:21:46,329 - INFO - Worker Worker(salt=5750355571, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=14468) was stopped. Shutting down Keep-Alive thread
2024-11-19 15:21:46,330 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-19 15:22:26,712 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-19 15:22:26,741 - INFO - EXTRACT 'public.address' - SUCCESS.
2024-11-19 15:22:26,745 - INFO - EXTRACT 'public.address_status' - SUCCESS.
2024-11-19 15:22:26,762 - INFO - EXTRACT 'public.author' - SUCCESS.
2024-11-19 15:22:26,825 - INFO - EXTRACT 'public.book' - SUCCESS.
2024-11-19 15:22:26,855 - INFO - EXTRACT 'public.book_author' - SUCCESS.
2024-11-19 15:22:26,859 - INFO - EXTRACT 'public.book_language' - SUCCESS.
2024-11-19 15:22:26,862 - INFO - EXTRACT 'public.country' - SUCCESS.
2024-11-19 15:22:26,939 - INFO - EXTRACT 'public.cust_order' - SUCCESS.
2024-11-19 15:22:26,948 - INFO - EXTRACT 'public.customer' - SUCCESS.
2024-11-19 15:22:26,959 - INFO - EXTRACT 'public.customer_address' - SUCCESS.
2024-11-19 15:22:27,074 - INFO - EXTRACT 'public.order_history' - SUCCESS.
2024-11-19 15:22:27,171 - INFO - EXTRACT 'public.order_line' - SUCCESS.
2024-11-19 15:22:27,177 - INFO - EXTRACT 'public.order_status' - SUCCESS.
2024-11-19 15:22:27,191 - INFO - EXTRACT 'public.publisher' - SUCCESS.
2024-11-19 15:22:27,197 - INFO - EXTRACT 'public.shipping_method' - SUCCESS.
2024-11-19 15:22:27,197 - INFO - EXTRACT ALL TABLE FROM SOURCE DATABASE - SUCCESS!
2024-11-19 15:22:27,202 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-19 15:22:27,202 - INFO - [pid 14783] Worker Worker(salt=3670295278, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=14783) done      Extract()
2024-11-19 15:22:27,203 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-19 15:22:27,207 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-19 15:22:27,208 - DEBUG - Asking scheduler for work...
2024-11-19 15:22:27,212 - DEBUG - Pending tasks: 1
2024-11-19 15:22:27,212 - INFO - [pid 14783] Worker Worker(salt=3670295278, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=14783) running   Load()
2024-11-19 15:22:27,288 - INFO - Read Extracted Data - SUCCESS!
2024-11-19 15:22:27,289 - INFO - Connect to DWH - SUCCESS!
2024-11-19 15:22:27,575 - INFO - Truncate Staging Schema in DWH - SUCCESS!
2024-11-19 15:22:27,575 - INFO - ==================================STARTING LOAD DATA=======================================
2024-11-19 15:22:27,597 - INFO - Load country table - SUCCESS!
2024-11-19 15:22:27,658 - INFO - Load address table - SUCCESS!
2024-11-19 15:22:27,668 - INFO - Load address_status table - SUCCESS!
2024-11-19 15:22:27,676 - INFO - Load book_language table - SUCCESS!
2024-11-19 15:22:27,728 - INFO - Load customer table - SUCCESS!
2024-11-19 15:22:27,766 - INFO - Load publisher table - SUCCESS!
2024-11-19 15:22:27,775 - INFO - Load shipping_method table - SUCCESS!
2024-11-19 15:22:27,902 - INFO - Load author table - SUCCESS!
2024-11-19 15:22:28,373 - INFO - Load book table - SUCCESS!
2024-11-19 15:22:28,688 - INFO - Load cust_order table - SUCCESS!
2024-11-19 15:22:28,794 - INFO - Load customer_address table - SUCCESS!
2024-11-19 15:22:28,801 - INFO - Load order_status table - SUCCESS!
2024-11-19 15:22:29,189 - INFO - Load book_author table - SUCCESS!
2024-11-19 15:22:29,826 - INFO - Load order_history table - SUCCESS!
2024-11-19 15:22:30,420 - INFO - Load order_line table - SUCCESS!
2024-11-19 15:22:30,420 - INFO - LOAD All Tables To Pacbook DWH Staging Schema - SUCCESS!
2024-11-19 15:22:30,422 - INFO - ==================================ENDING LOAD DATA=======================================
2024-11-19 15:22:30,426 - INFO - [pid 14783] Worker Worker(salt=3670295278, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=14783) done      Load()
2024-11-19 15:22:30,427 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-19 15:22:30,430 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-11-19 15:22:30,431 - DEBUG - Asking scheduler for work...
2024-11-19 15:22:30,434 - DEBUG - Done
2024-11-19 15:22:30,434 - DEBUG - There are no more tasks to run at this time
2024-11-19 15:22:30,434 - INFO - Worker Worker(salt=3670295278, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=14783) was stopped. Shutting down Keep-Alive thread
2024-11-19 15:22:30,435 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()

This progress looks :) because there were no failed tasks or missing dependencies

===== Luigi Execution Summary =====

2024-11-19 16:15:12,790 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-19 16:15:12,859 - INFO - EXTRACT 'public.address' - SUCCESS.
2024-11-19 16:15:12,863 - INFO - EXTRACT 'public.address_status' - SUCCESS.
2024-11-19 16:15:12,890 - INFO - EXTRACT 'public.author' - SUCCESS.
2024-11-19 16:15:12,964 - INFO - EXTRACT 'public.book' - SUCCESS.
2024-11-19 16:15:13,005 - INFO - EXTRACT 'public.book_author' - SUCCESS.
2024-11-19 16:15:13,008 - INFO - EXTRACT 'public.book_language' - SUCCESS.
2024-11-19 16:15:13,013 - INFO - EXTRACT 'public.country' - SUCCESS.
2024-11-19 16:15:13,121 - INFO - EXTRACT 'public.cust_order' - SUCCESS.
2024-11-19 16:15:13,134 - INFO - EXTRACT 'public.customer' - SUCCESS.
2024-11-19 16:15:13,148 - INFO - EXTRACT 'public.customer_address' - SUCCESS.
2024-11-19 16:15:13,281 - INFO - EXTRACT 'public.order_history' - SUCCESS.
2024-11-19 16:15:13,377 - INFO - EXTRACT 'public.order_line' - SUCCESS.
2024-11-19 16:15:13,383 - INFO - EXTRACT 'public.order_status' - SUCCESS.
2024-11-19 16:15:13,393 - INFO - EXTRACT 'public.publisher' - SUCCESS.
2024-11-19 16:15:13,398 - INFO - EXTRACT 'public.shipping_method' - SUCCESS.
2024-11-19 16:15:13,398 - INFO - EXTRACT ALL TABLE FROM SOURCE DATABASE - SUCCESS!
2024-11-19 16:15:13,400 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-19 16:15:13,400 - INFO - [pid 34745] Worker Worker(salt=092417438, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=34745) done      Extract()
2024-11-19 16:15:13,402 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-19 16:15:13,407 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-19 16:15:13,407 - DEBUG - Asking scheduler for work...
2024-11-19 16:15:13,410 - DEBUG - Pending tasks: 1
2024-11-19 16:15:13,410 - INFO - [pid 34745] Worker Worker(salt=092417438, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=34745) running   Load()
2024-11-19 16:15:13,485 - INFO - Read Extracted Data - SUCCESS!
2024-11-19 16:15:13,486 - INFO - Connect to DWH - SUCCESS!
2024-11-19 16:15:13,776 - INFO - Truncate Staging Schema in DWH - SUCCESS!
2024-11-19 16:15:13,776 - INFO - ==================================STARTING LOAD DATA=======================================
2024-11-19 16:15:13,795 - INFO - Load country table - SUCCESS!
2024-11-19 16:15:13,835 - INFO - Load address table - SUCCESS!
2024-11-19 16:15:13,844 - INFO - Load address_status table - SUCCESS!
2024-11-19 16:15:13,852 - INFO - Load book_language table - SUCCESS!
2024-11-19 16:15:13,896 - INFO - Load customer table - SUCCESS!
2024-11-19 16:15:13,937 - INFO - Load publisher table - SUCCESS!
2024-11-19 16:15:13,946 - INFO - Load shipping_method table - SUCCESS!
2024-11-19 16:15:14,083 - INFO - Load author table - SUCCESS!
2024-11-19 16:15:14,581 - INFO - Load book table - SUCCESS!
2024-11-19 16:15:14,899 - INFO - Load cust_order table - SUCCESS!
2024-11-19 16:15:15,017 - INFO - Load customer_address table - SUCCESS!
2024-11-19 16:15:15,024 - INFO - Load order_status table - SUCCESS!
2024-11-19 16:15:15,460 - INFO - Load book_author table - SUCCESS!
2024-11-19 16:15:16,098 - INFO - Load order_history table - SUCCESS!
2024-11-19 16:15:16,613 - INFO - Load order_line table - SUCCESS!
2024-11-19 16:15:16,614 - INFO - LOAD All Tables To Pacbook DWH Staging Schema - SUCCESS!
2024-11-19 16:15:16,616 - INFO - ==================================ENDING LOAD DATA=======================================
2024-11-19 16:15:16,617 - INFO - [pid 34745] Worker Worker(salt=092417438, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=34745) done      Load()
2024-11-19 16:15:16,617 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-19 16:15:16,620 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-11-19 16:15:16,620 - DEBUG - Asking scheduler for work...
2024-11-19 16:15:16,622 - DEBUG - Done
2024-11-19 16:15:16,622 - DEBUG - There are no more tasks to run at this time
2024-11-19 16:15:16,622 - INFO - Worker Worker(salt=092417438, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=34745) was stopped. Shutting down Keep-Alive thread
2024-11-19 16:15:16,623 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()

This progress looks :) because there were no failed tasks or missing dependencies

===== Luigi Execution Summary =====

2024-11-19 16:33:47,153 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-19 16:33:47,212 - INFO - EXTRACT 'public.address' - SUCCESS.
2024-11-19 16:33:47,217 - INFO - EXTRACT 'public.address_status' - SUCCESS.
2024-11-19 16:33:47,242 - INFO - EXTRACT 'public.author' - SUCCESS.
2024-11-19 16:33:47,311 - INFO - EXTRACT 'public.book' - SUCCESS.
2024-11-19 16:33:47,371 - INFO - EXTRACT 'public.book_author' - SUCCESS.
2024-11-19 16:33:47,375 - INFO - EXTRACT 'public.book_language' - SUCCESS.
2024-11-19 16:33:47,380 - INFO - EXTRACT 'public.country' - SUCCESS.
2024-11-19 16:33:47,426 - INFO - EXTRACT 'public.cust_order' - SUCCESS.
2024-11-19 16:33:47,435 - INFO - EXTRACT 'public.customer' - SUCCESS.
2024-11-19 16:33:47,446 - INFO - EXTRACT 'public.customer_address' - SUCCESS.
2024-11-19 16:33:47,557 - INFO - EXTRACT 'public.order_history' - SUCCESS.
2024-11-19 16:33:47,638 - INFO - EXTRACT 'public.order_line' - SUCCESS.
2024-11-19 16:33:47,642 - INFO - EXTRACT 'public.order_status' - SUCCESS.
2024-11-19 16:33:47,650 - INFO - EXTRACT 'public.publisher' - SUCCESS.
2024-11-19 16:33:47,654 - INFO - EXTRACT 'public.shipping_method' - SUCCESS.
2024-11-19 16:33:47,654 - INFO - EXTRACT ALL TABLE FROM SOURCE DATABASE - SUCCESS!
2024-11-19 16:33:47,655 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-19 16:33:47,655 - INFO - [pid 43601] Worker Worker(salt=8441061434, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=43601) done      Extract()
2024-11-19 16:33:47,656 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-19 16:33:47,659 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-19 16:33:47,659 - DEBUG - Asking scheduler for work...
2024-11-19 16:33:47,661 - DEBUG - Pending tasks: 2
2024-11-19 16:33:47,662 - INFO - [pid 43601] Worker Worker(salt=8441061434, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=43601) running   Load()
2024-11-19 16:33:47,731 - INFO - Read Extracted Data - SUCCESS!
2024-11-19 16:33:47,732 - INFO - Connect to DWH - SUCCESS!
2024-11-19 16:33:48,016 - INFO - Truncate Staging Schema in DWH - SUCCESS!
2024-11-19 16:33:48,016 - INFO - ==================================STARTING LOAD DATA=======================================
2024-11-19 16:33:48,036 - INFO - Load country table - SUCCESS!
2024-11-19 16:33:48,105 - INFO - Load address table - SUCCESS!
2024-11-19 16:33:48,113 - INFO - Load address_status table - SUCCESS!
2024-11-19 16:33:48,120 - INFO - Load book_language table - SUCCESS!
2024-11-19 16:33:48,170 - INFO - Load customer table - SUCCESS!
2024-11-19 16:33:48,205 - INFO - Load publisher table - SUCCESS!
2024-11-19 16:33:48,214 - INFO - Load shipping_method table - SUCCESS!
2024-11-19 16:33:48,345 - INFO - Load author table - SUCCESS!
2024-11-19 16:33:48,847 - INFO - Load book table - SUCCESS!
2024-11-19 16:33:49,122 - INFO - Load cust_order table - SUCCESS!
2024-11-19 16:33:49,222 - INFO - Load customer_address table - SUCCESS!
2024-11-19 16:33:49,231 - INFO - Load order_status table - SUCCESS!
2024-11-19 16:33:49,604 - INFO - Load book_author table - SUCCESS!
2024-11-19 16:33:50,208 - INFO - Load order_history table - SUCCESS!
2024-11-19 16:33:50,645 - INFO - Load order_line table - SUCCESS!
2024-11-19 16:33:50,646 - INFO - LOAD All Tables To Pacbook DWH Staging Schema - SUCCESS!
2024-11-19 16:33:50,647 - INFO - ==================================ENDING LOAD DATA=======================================
2024-11-19 16:33:50,648 - INFO - [pid 43601] Worker Worker(salt=8441061434, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=43601) done      Load()
2024-11-19 16:33:50,649 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-19 16:33:50,651 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-11-19 16:33:50,651 - DEBUG - Asking scheduler for work...
2024-11-19 16:33:50,653 - DEBUG - Pending tasks: 1
2024-11-19 16:33:50,653 - INFO - [pid 43601] Worker Worker(salt=8441061434, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=43601) running   Transform()
2024-11-19 16:33:50,654 - ERROR - [pid 43601] Worker Worker(salt=8441061434, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=43601) failed    Transform()
Traceback (most recent call last):
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/luigi/worker.py", line 195, in run
    raise RuntimeError('Unfulfilled %s at run time: %s' % (deps, ', '.join(missing)))
RuntimeError: Unfulfilled dependency at run time: Load__99914b932b (/home/ricofebrian/data-warehouse-labs/project/pacbook_store/temp/data/load-summary.csv)
2024-11-19 16:33:50,726 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-19 16:33:50,732 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-11-19 16:33:50,732 - DEBUG - Checking if Transform() is complete
2024-11-19 16:33:50,732 - DEBUG - Checking if Load() is complete
2024-11-19 16:33:50,735 - INFO - Informed scheduler that task   Transform__99914b932b   has status   PENDING
2024-11-19 16:33:50,735 - DEBUG - Checking if Extract() is complete
2024-11-19 16:33:50,738 - INFO - Informed scheduler that task   Load__99914b932b   has status   PENDING
2024-11-19 16:33:50,742 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-19 16:33:50,742 - DEBUG - Asking scheduler for work...
2024-11-19 16:33:50,746 - DEBUG - Pending tasks: 1
2024-11-19 16:33:50,747 - INFO - [pid 43601] Worker Worker(salt=8441061434, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=43601) running   Transform()
2024-11-19 16:33:50,747 - ERROR - [pid 43601] Worker Worker(salt=8441061434, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=43601) failed    Transform()
Traceback (most recent call last):
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/luigi/worker.py", line 195, in run
    raise RuntimeError('Unfulfilled %s at run time: %s' % (deps, ', '.join(missing)))
RuntimeError: Unfulfilled dependency at run time: Load__99914b932b (/home/ricofebrian/data-warehouse-labs/project/pacbook_store/temp/data/load-summary.csv)
2024-11-19 16:33:50,756 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-19 16:33:50,761 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-11-19 16:33:50,761 - DEBUG - Asking scheduler for work...
2024-11-19 16:33:50,763 - DEBUG - Done
2024-11-19 16:33:50,764 - DEBUG - There are no more tasks to run at this time
2024-11-19 16:33:50,764 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-11-19 16:33:50,764 - DEBUG - There are 1 pending tasks unique to this worker
2024-11-19 16:33:50,764 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-11-19 16:33:50,764 - INFO - Worker Worker(salt=8441061434, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=43601) was stopped. Shutting down Keep-Alive thread
2024-11-19 16:33:50,766 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-19 16:36:44,486 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-19 16:36:44,535 - INFO - EXTRACT 'public.address' - SUCCESS.
2024-11-19 16:36:44,539 - INFO - EXTRACT 'public.address_status' - SUCCESS.
2024-11-19 16:36:44,562 - INFO - EXTRACT 'public.author' - SUCCESS.
2024-11-19 16:36:44,626 - INFO - EXTRACT 'public.book' - SUCCESS.
2024-11-19 16:36:44,688 - INFO - EXTRACT 'public.book_author' - SUCCESS.
2024-11-19 16:36:44,691 - INFO - EXTRACT 'public.book_language' - SUCCESS.
2024-11-19 16:36:44,695 - INFO - EXTRACT 'public.country' - SUCCESS.
2024-11-19 16:36:44,737 - INFO - EXTRACT 'public.cust_order' - SUCCESS.
2024-11-19 16:36:44,746 - INFO - EXTRACT 'public.customer' - SUCCESS.
2024-11-19 16:36:44,756 - INFO - EXTRACT 'public.customer_address' - SUCCESS.
2024-11-19 16:36:44,875 - INFO - EXTRACT 'public.order_history' - SUCCESS.
2024-11-19 16:36:44,972 - INFO - EXTRACT 'public.order_line' - SUCCESS.
2024-11-19 16:36:44,976 - INFO - EXTRACT 'public.order_status' - SUCCESS.
2024-11-19 16:36:44,984 - INFO - EXTRACT 'public.publisher' - SUCCESS.
2024-11-19 16:36:44,989 - INFO - EXTRACT 'public.shipping_method' - SUCCESS.
2024-11-19 16:36:44,989 - INFO - EXTRACT ALL TABLE FROM SOURCE DATABASE - SUCCESS!
2024-11-19 16:36:44,990 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-19 16:36:44,990 - INFO - [pid 44958] Worker Worker(salt=3181077139, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=44958) done      Extract()
2024-11-19 16:36:44,993 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-19 16:36:44,996 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-19 16:36:44,997 - DEBUG - Asking scheduler for work...
2024-11-19 16:36:44,999 - DEBUG - Pending tasks: 2
2024-11-19 16:36:44,999 - INFO - [pid 44958] Worker Worker(salt=3181077139, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=44958) running   Load()
2024-11-19 16:36:45,066 - INFO - Read Extracted Data - SUCCESS!
2024-11-19 16:36:45,067 - INFO - Connect to DWH - SUCCESS!
2024-11-19 16:36:45,317 - INFO - Truncate Staging Schema in DWH - SUCCESS!
2024-11-19 16:36:45,317 - INFO - ==================================STARTING LOAD DATA=======================================
2024-11-19 16:36:45,332 - INFO - Load country table - SUCCESS!
2024-11-19 16:36:45,371 - INFO - Load address table - SUCCESS!
2024-11-19 16:36:45,379 - INFO - Load address_status table - SUCCESS!
2024-11-19 16:36:45,387 - INFO - Load book_language table - SUCCESS!
2024-11-19 16:36:45,435 - INFO - Load customer table - SUCCESS!
2024-11-19 16:36:45,471 - INFO - Load publisher table - SUCCESS!
2024-11-19 16:36:45,480 - INFO - Load shipping_method table - SUCCESS!
2024-11-19 16:36:45,601 - INFO - Load author table - SUCCESS!
2024-11-19 16:36:46,088 - INFO - Load book table - SUCCESS!
2024-11-19 16:36:46,369 - INFO - Load cust_order table - SUCCESS!
2024-11-19 16:36:46,476 - INFO - Load customer_address table - SUCCESS!
2024-11-19 16:36:46,483 - INFO - Load order_status table - SUCCESS!
2024-11-19 16:36:46,914 - INFO - Load book_author table - SUCCESS!
2024-11-19 16:36:47,632 - INFO - Load order_history table - SUCCESS!
2024-11-19 16:36:48,099 - INFO - Load order_line table - SUCCESS!
2024-11-19 16:36:48,099 - INFO - LOAD All Tables To Pacbook DWH Staging Schema - SUCCESS!
2024-11-19 16:36:48,100 - INFO - ==================================ENDING LOAD DATA=======================================
2024-11-19 16:36:48,102 - INFO - [pid 44958] Worker Worker(salt=3181077139, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=44958) done      Load()
2024-11-19 16:36:48,102 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-19 16:36:48,106 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-11-19 16:36:48,106 - DEBUG - Asking scheduler for work...
2024-11-19 16:36:48,109 - DEBUG - Pending tasks: 1
2024-11-19 16:36:48,109 - INFO - [pid 44958] Worker Worker(salt=3181077139, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=44958) running   Transform()
2024-11-19 16:36:48,110 - ERROR - [pid 44958] Worker Worker(salt=3181077139, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=44958) failed    Transform()
Traceback (most recent call last):
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/luigi/worker.py", line 195, in run
    raise RuntimeError('Unfulfilled %s at run time: %s' % (deps, ', '.join(missing)))
RuntimeError: Unfulfilled dependency at run time: Load__99914b932b (/home/ricofebrian/data-warehouse-labs/project/pacbook_store/temp/data/load-summary.csv)
2024-11-19 16:36:48,192 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-19 16:36:48,199 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-11-19 16:36:48,199 - DEBUG - Checking if Transform() is complete
2024-11-19 16:36:48,200 - DEBUG - Checking if Load() is complete
2024-11-19 16:36:48,203 - INFO - Informed scheduler that task   Transform__99914b932b   has status   PENDING
2024-11-19 16:36:48,203 - DEBUG - Checking if Extract() is complete
2024-11-19 16:36:48,206 - INFO - Informed scheduler that task   Load__99914b932b   has status   PENDING
2024-11-19 16:36:48,209 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-19 16:36:48,209 - DEBUG - Asking scheduler for work...
2024-11-19 16:36:48,212 - DEBUG - Pending tasks: 1
2024-11-19 16:36:48,213 - INFO - [pid 44958] Worker Worker(salt=3181077139, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=44958) running   Transform()
2024-11-19 16:36:48,214 - ERROR - [pid 44958] Worker Worker(salt=3181077139, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=44958) failed    Transform()
Traceback (most recent call last):
  File "/home/ricofebrian/data-warehouse-labs/project/pacbook_store/pacbook_venv/lib/python3.10/site-packages/luigi/worker.py", line 195, in run
    raise RuntimeError('Unfulfilled %s at run time: %s' % (deps, ', '.join(missing)))
RuntimeError: Unfulfilled dependency at run time: Load__99914b932b (/home/ricofebrian/data-warehouse-labs/project/pacbook_store/temp/data/load-summary.csv)
2024-11-19 16:36:48,219 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-19 16:36:48,225 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-11-19 16:36:48,225 - DEBUG - Asking scheduler for work...
2024-11-19 16:36:48,228 - DEBUG - Done
2024-11-19 16:36:48,228 - DEBUG - There are no more tasks to run at this time
2024-11-19 16:36:48,229 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-11-19 16:36:48,229 - DEBUG - There are 1 pending tasks unique to this worker
2024-11-19 16:36:48,229 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-11-19 16:36:48,229 - INFO - Worker Worker(salt=3181077139, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=44958) was stopped. Shutting down Keep-Alive thread
2024-11-19 16:36:48,231 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-19 16:38:46,170 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-19 16:38:46,200 - INFO - EXTRACT 'public.address' - SUCCESS.
2024-11-19 16:38:46,203 - INFO - EXTRACT 'public.address_status' - SUCCESS.
2024-11-19 16:38:46,221 - INFO - EXTRACT 'public.author' - SUCCESS.
2024-11-19 16:38:46,284 - INFO - EXTRACT 'public.book' - SUCCESS.
2024-11-19 16:38:46,355 - INFO - EXTRACT 'public.book_author' - SUCCESS.
2024-11-19 16:38:46,359 - INFO - EXTRACT 'public.book_language' - SUCCESS.
2024-11-19 16:38:46,363 - INFO - EXTRACT 'public.country' - SUCCESS.
2024-11-19 16:38:46,413 - INFO - EXTRACT 'public.cust_order' - SUCCESS.
2024-11-19 16:38:46,423 - INFO - EXTRACT 'public.customer' - SUCCESS.
2024-11-19 16:38:46,433 - INFO - EXTRACT 'public.customer_address' - SUCCESS.
2024-11-19 16:38:46,541 - INFO - EXTRACT 'public.order_history' - SUCCESS.
2024-11-19 16:38:46,645 - INFO - EXTRACT 'public.order_line' - SUCCESS.
2024-11-19 16:38:46,652 - INFO - EXTRACT 'public.order_status' - SUCCESS.
2024-11-19 16:38:46,660 - INFO - EXTRACT 'public.publisher' - SUCCESS.
2024-11-19 16:38:46,665 - INFO - EXTRACT 'public.shipping_method' - SUCCESS.
2024-11-19 16:38:46,665 - INFO - EXTRACT ALL TABLE FROM SOURCE DATABASE - SUCCESS!
2024-11-19 16:38:46,667 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-19 16:38:46,667 - INFO - [pid 45958] Worker Worker(salt=8240874147, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=45958) done      Extract()
2024-11-19 16:38:46,669 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-19 16:38:46,673 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-19 16:38:46,673 - DEBUG - Asking scheduler for work...
2024-11-19 16:38:46,676 - DEBUG - Pending tasks: 2
2024-11-19 16:38:46,676 - INFO - [pid 45958] Worker Worker(salt=8240874147, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=45958) running   Load()
2024-11-19 16:38:46,749 - INFO - Read Extracted Data - SUCCESS!
2024-11-19 16:38:46,750 - INFO - Connect to DWH - SUCCESS!
2024-11-19 16:38:46,995 - INFO - Truncate Staging Schema in DWH - SUCCESS!
2024-11-19 16:38:46,996 - INFO - ==================================STARTING LOAD DATA=======================================
2024-11-19 16:38:47,011 - INFO - Load country table - SUCCESS!
2024-11-19 16:38:47,056 - INFO - Load address table - SUCCESS!
2024-11-19 16:38:47,063 - INFO - Load address_status table - SUCCESS!
2024-11-19 16:38:47,073 - INFO - Load book_language table - SUCCESS!
2024-11-19 16:38:47,122 - INFO - Load customer table - SUCCESS!
2024-11-19 16:38:47,157 - INFO - Load publisher table - SUCCESS!
2024-11-19 16:38:47,165 - INFO - Load shipping_method table - SUCCESS!
2024-11-19 16:38:47,285 - INFO - Load author table - SUCCESS!
2024-11-19 16:38:47,773 - INFO - Load book table - SUCCESS!
2024-11-19 16:38:48,034 - INFO - Load cust_order table - SUCCESS!
2024-11-19 16:38:48,135 - INFO - Load customer_address table - SUCCESS!
2024-11-19 16:38:48,142 - INFO - Load order_status table - SUCCESS!
2024-11-19 16:38:48,526 - INFO - Load book_author table - SUCCESS!
2024-11-19 16:38:49,162 - INFO - Load order_history table - SUCCESS!
2024-11-19 16:38:49,698 - INFO - Load order_line table - SUCCESS!
2024-11-19 16:38:49,699 - INFO - LOAD All Tables To Pacbook DWH Staging Schema - SUCCESS!
2024-11-19 16:38:49,700 - INFO - ==================================ENDING LOAD DATA=======================================
2024-11-19 16:38:49,702 - INFO - [pid 45958] Worker Worker(salt=8240874147, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=45958) done      Load()
2024-11-19 16:38:49,702 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-19 16:38:49,705 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-11-19 16:38:49,705 - DEBUG - Asking scheduler for work...
2024-11-19 16:38:49,707 - DEBUG - Pending tasks: 1
2024-11-19 16:38:49,707 - INFO - [pid 45958] Worker Worker(salt=8240874147, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=45958) running   Transform()
2024-11-19 16:38:49,708 - INFO - ==================================STARTING TRANSFROM DATA=======================================
[0m09:38:51  Running with dbt=1.9.0-b4
[0m09:38:52  Installing dbt-labs/dbt_utils
[0m09:38:52  Installed from version 1.1.1
[0m09:38:52  Updated version available: 1.3.0
[0m09:38:52  Installing calogica/dbt_date
[0m09:38:53  Installed from version 0.10.0
[0m09:38:53  Updated version available: 0.10.1
[0m09:38:53  Installing Snowflake-Labs/dbt_constraints
[0m09:38:53  Installed from version 0.6.3
[0m09:38:53  Updated version available: 1.0.4
[0m09:38:53  
[0m09:38:53  Updates available for packages: ['dbt-labs/dbt_utils', 'calogica/dbt_date', 'Snowflake-Labs/dbt_constraints']                 
Update your versions in packages.yml, then run dbt deps
[0m09:38:56  Running with dbt=1.9.0-b4
[0m09:38:56  Registered adapter: postgres=1.8.2
[0m09:38:57  Found 19 models, 2 snapshots, 1 seed, 1 operation, 21 data tests, 15 sources, 751 macros
[0m09:38:57  
[0m09:38:57  Concurrency: 1 threads (target='dev')
[0m09:38:57  
[0m09:38:57  1 of 1 START seed file final.dim_date .......................................... [RUN]
[0m09:41:11  1 of 1 OK loaded seed file final.dim_date ...................................... [[32mINSERT 29220[0m in 134.22s]
[0m09:41:11  
[0m09:41:11  Running dbt Constraints
[0m09:41:11  Finished dbt Constraints
[0m09:41:11  1 of 1 START hook: dbt_constraints.on-run-end.0 ................................ [RUN]
[0m09:41:11  1 of 1 OK hook: dbt_constraints.on-run-end.0 ................................... [[32mOK[0m in 0.05s]
[0m09:41:11  
[0m09:41:11  Finished running 1 project hook, 1 seed in 0 hours 2 minutes and 14.54 seconds (134.54s).
[0m09:41:11  
[0m09:41:11  [32mCompleted successfully[0m
[0m09:41:11  
[0m09:41:11  Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m09:41:14  Running with dbt=1.9.0-b4
[0m09:41:14  Registered adapter: postgres=1.8.2
[0m09:41:15  Found 19 models, 2 snapshots, 1 seed, 1 operation, 21 data tests, 15 sources, 751 macros
[0m09:41:15  
[0m09:41:15  Concurrency: 1 threads (target='dev')
[0m09:41:15  
[0m09:41:15  1 of 19 START sql view model final.stg_pacbook__address ........................ [RUN]
[0m09:41:15  1 of 19 OK created sql view model final.stg_pacbook__address ................... [[32mCREATE VIEW[0m in 0.13s]
[0m09:41:15  2 of 19 START sql view model final.stg_pacbook__address_status ................. [RUN]
[0m09:41:15  2 of 19 OK created sql view model final.stg_pacbook__address_status ............ [[32mCREATE VIEW[0m in 0.07s]
[0m09:41:15  3 of 19 START sql view model final.stg_pacbook__author ......................... [RUN]
[0m09:41:15  3 of 19 OK created sql view model final.stg_pacbook__author .................... [[32mCREATE VIEW[0m in 0.06s]
[0m09:41:15  4 of 19 START sql view model final.stg_pacbook__book ........................... [RUN]
[0m09:41:15  4 of 19 OK created sql view model final.stg_pacbook__book ...................... [[32mCREATE VIEW[0m in 0.06s]
[0m09:41:15  5 of 19 START sql view model final.stg_pacbook__book_author .................... [RUN]
[0m09:41:15  5 of 19 OK created sql view model final.stg_pacbook__book_author ............... [[32mCREATE VIEW[0m in 0.06s]
[0m09:41:15  6 of 19 START sql view model final.stg_pacbook__book_language .................. [RUN]
[0m09:41:16  6 of 19 OK created sql view model final.stg_pacbook__book_language ............. [[32mCREATE VIEW[0m in 0.06s]
[0m09:41:16  7 of 19 START sql view model final.stg_pacbook__country ........................ [RUN]
[0m09:41:16  7 of 19 OK created sql view model final.stg_pacbook__country ................... [[32mCREATE VIEW[0m in 0.06s]
[0m09:41:16  8 of 19 START sql view model final.stg_pacbook__cust_order ..................... [RUN]
[0m09:41:16  8 of 19 OK created sql view model final.stg_pacbook__cust_order ................ [[32mCREATE VIEW[0m in 0.06s]
[0m09:41:16  9 of 19 START sql view model final.stg_pacbook__customer ....................... [RUN]
[0m09:41:16  9 of 19 OK created sql view model final.stg_pacbook__customer .................. [[32mCREATE VIEW[0m in 0.06s]
[0m09:41:16  10 of 19 START sql view model final.stg_pacbook__customer_address .............. [RUN]
[0m09:41:16  10 of 19 OK created sql view model final.stg_pacbook__customer_address ......... [[32mCREATE VIEW[0m in 0.07s]
[0m09:41:16  11 of 19 START sql view model final.stg_pacbook__order_history ................. [RUN]
[0m09:41:16  11 of 19 OK created sql view model final.stg_pacbook__order_history ............ [[32mCREATE VIEW[0m in 0.13s]
[0m09:41:16  12 of 19 START sql view model final.stg_pacbook__order_line .................... [RUN]
[0m09:41:16  12 of 19 OK created sql view model final.stg_pacbook__order_line ............... [[32mCREATE VIEW[0m in 0.07s]
[0m09:41:16  13 of 19 START sql view model final.stg_pacbook__order_status .................. [RUN]
[0m09:41:16  13 of 19 OK created sql view model final.stg_pacbook__order_status ............. [[32mCREATE VIEW[0m in 0.06s]
[0m09:41:16  14 of 19 START sql view model final.stg_pacbook__publisher ..................... [RUN]
[0m09:41:16  14 of 19 OK created sql view model final.stg_pacbook__publisher ................ [[32mCREATE VIEW[0m in 0.06s]
[0m09:41:16  15 of 19 START sql view model final.stg_pacbook__shipping_method ............... [RUN]
[0m09:41:16  15 of 19 OK created sql view model final.stg_pacbook__shipping_method .......... [[32mCREATE VIEW[0m in 0.06s]
[0m09:41:16  16 of 19 START sql table model final.dim_customers ............................. [RUN]
[0m09:41:16  16 of 19 OK created sql table model final.dim_customers ........................ [[32mSELECT 3350[0m in 0.14s]
[0m09:41:16  17 of 19 START sql table model final.dim_books ................................. [RUN]
[0m09:41:17  17 of 19 OK created sql table model final.dim_books ............................ [[32mSELECT 11128[0m in 0.19s]
[0m09:41:17  18 of 19 START sql table model final.fct_book_sales ............................ [RUN]
[0m09:41:17  18 of 19 OK created sql table model final.fct_book_sales ....................... [[32mSELECT 15399[0m in 0.16s]
[0m09:41:17  19 of 19 START sql table model final.fct_orders ................................ [RUN]
[0m09:41:17  19 of 19 OK created sql table model final.fct_orders ........................... [[32mSELECT 7550[0m in 0.19s]
[0m09:41:17  
[0m09:41:17  Running dbt Constraints
[0m09:41:17  Finished dbt Constraints
[0m09:41:17  1 of 1 START hook: dbt_constraints.on-run-end.0 ................................ [RUN]
[0m09:41:17  1 of 1 OK hook: dbt_constraints.on-run-end.0 ................................... [[32mOK[0m in 0.05s]
[0m09:41:17  
[0m09:41:17  Finished running 1 project hook, 4 table models, 15 view models in 0 hours 0 minutes and 2.08 seconds (2.08s).
[0m09:41:17  
[0m09:41:17  [32mCompleted successfully[0m
[0m09:41:17  
[0m09:41:17  Done. PASS=20 WARN=0 ERROR=0 SKIP=0 TOTAL=20
[0m09:41:20  Running with dbt=1.9.0-b4
[0m09:41:20  Registered adapter: postgres=1.8.2
[0m09:41:21  Found 19 models, 2 snapshots, 1 seed, 1 operation, 21 data tests, 15 sources, 751 macros
[0m09:41:21  
[0m09:41:21  Concurrency: 1 threads (target='dev')
[0m09:41:21  
[0m09:41:21  1 of 2 START snapshot snapshots.dim_books_snapshot ............................. [RUN]
[0m09:41:21  1 of 2 OK snapshotted snapshots.dim_books_snapshot ............................. [[32mINSERT 0 11128[0m in 0.55s]
[0m09:41:21  2 of 2 START snapshot snapshots.dim_customers_snapshot ......................... [RUN]
[0m09:41:22  2 of 2 OK snapshotted snapshots.dim_customers_snapshot ......................... [[32mINSERT 0 3350[0m in 0.18s]
[0m09:41:22  
[0m09:41:22  Running dbt Constraints
[0m09:41:22  Finished dbt Constraints
[0m09:41:22  1 of 1 START hook: dbt_constraints.on-run-end.0 ................................ [RUN]
[0m09:41:22  1 of 1 OK hook: dbt_constraints.on-run-end.0 ................................... [[32mOK[0m in 0.05s]
[0m09:41:22  
[0m09:41:22  Finished running 1 project hook, 2 snapshots in 0 hours 0 minutes and 1.05 seconds (1.05s).
[0m09:41:22  
[0m09:41:22  [32mCompleted successfully[0m
[0m09:41:22  
[0m09:41:22  Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m09:41:24  Running with dbt=1.9.0-b4
[0m09:41:24  Registered adapter: postgres=1.8.2
[0m09:41:25  Found 19 models, 2 snapshots, 1 seed, 1 operation, 21 data tests, 15 sources, 751 macros
[0m09:41:25  
[0m09:41:25  Concurrency: 1 threads (target='dev')
[0m09:41:25  
[0m09:41:25  1 of 21 START test dbt_constraints_foreign_key_fct_book_sales_nk_book_id__nk_book_id__ref_dim_books_  [RUN]
[0m09:41:25  1 of 21 PASS dbt_constraints_foreign_key_fct_book_sales_nk_book_id__nk_book_id__ref_dim_books_  [[32mPASS[0m in 0.07s]
[0m09:41:25  2 of 21 START test dbt_constraints_foreign_key_fct_book_sales_order_date__date_actual__ref_dim_date_  [RUN]
[0m09:41:25  2 of 21 PASS dbt_constraints_foreign_key_fct_book_sales_order_date__date_actual__ref_dim_date_  [[32mPASS[0m in 0.04s]
[0m09:41:25  3 of 21 START test dbt_constraints_foreign_key_fct_orders_nk_customer_id__nk_customer_id__ref_dim_customers_  [RUN]
[0m09:41:25  3 of 21 PASS dbt_constraints_foreign_key_fct_orders_nk_customer_id__nk_customer_id__ref_dim_customers_  [[32mPASS[0m in 0.03s]
[0m09:41:25  4 of 21 START test dbt_constraints_primary_key_dim_books_sk_book_id ............ [RUN]
[0m09:41:25  4 of 21 PASS dbt_constraints_primary_key_dim_books_sk_book_id .................. [[32mPASS[0m in 0.04s]
[0m09:41:25  5 of 21 START test dbt_constraints_primary_key_dim_customers_sk_customer_id .... [RUN]
[0m09:41:25  5 of 21 PASS dbt_constraints_primary_key_dim_customers_sk_customer_id .......... [[32mPASS[0m in 0.03s]
[0m09:41:25  6 of 21 START test dbt_constraints_primary_key_dim_date_date_id ................ [RUN]
[0m09:41:25  6 of 21 PASS dbt_constraints_primary_key_dim_date_date_id ...................... [[32mPASS[0m in 0.04s]
[0m09:41:25  7 of 21 START test dbt_constraints_primary_key_fct_orders_sk_order_id .......... [RUN]
[0m09:41:25  7 of 21 PASS dbt_constraints_primary_key_fct_orders_sk_order_id ................ [[32mPASS[0m in 0.03s]
[0m09:41:25  8 of 21 START test not_null_dim_books_nk_book_id ............................... [RUN]
[0m09:41:25  8 of 21 PASS not_null_dim_books_nk_book_id ..................................... [[32mPASS[0m in 0.03s]
[0m09:41:25  9 of 21 START test not_null_dim_books_sk_book_id ............................... [RUN]
[0m09:41:25  9 of 21 PASS not_null_dim_books_sk_book_id ..................................... [[32mPASS[0m in 0.03s]
[0m09:41:25  10 of 21 START test not_null_dim_customers_nk_customer_id ...................... [RUN]
[0m09:41:25  10 of 21 PASS not_null_dim_customers_nk_customer_id ............................ [[32mPASS[0m in 0.03s]
[0m09:41:25  11 of 21 START test not_null_dim_customers_sk_customer_id ...................... [RUN]
[0m09:41:25  11 of 21 PASS not_null_dim_customers_sk_customer_id ............................ [[32mPASS[0m in 0.03s]
[0m09:41:25  12 of 21 START test not_null_dim_date_date_id .................................. [RUN]
[0m09:41:25  12 of 21 PASS not_null_dim_date_date_id ........................................ [[32mPASS[0m in 0.03s]
[0m09:41:25  13 of 21 START test not_null_fct_book_sales_dd_order_id ........................ [RUN]
[0m09:41:26  13 of 21 PASS not_null_fct_book_sales_dd_order_id .............................. [[32mPASS[0m in 0.03s]
[0m09:41:26  14 of 21 START test not_null_fct_book_sales_nk_book_id ......................... [RUN]
[0m09:41:26  14 of 21 PASS not_null_fct_book_sales_nk_book_id ............................... [[32mPASS[0m in 0.03s]
[0m09:41:26  15 of 21 START test not_null_fct_book_sales_order_date ......................... [RUN]
[0m09:41:26  15 of 21 PASS not_null_fct_book_sales_order_date ............................... [[32mPASS[0m in 0.03s]
[0m09:41:26  16 of 21 START test not_null_fct_orders_dd_order_id ............................ [RUN]
[0m09:41:26  16 of 21 PASS not_null_fct_orders_dd_order_id .................................. [[32mPASS[0m in 0.03s]
[0m09:41:26  17 of 21 START test not_null_fct_orders_nk_customer_id ......................... [RUN]
[0m09:41:26  17 of 21 PASS not_null_fct_orders_nk_customer_id ............................... [[32mPASS[0m in 0.03s]
[0m09:41:26  18 of 21 START test not_null_fct_orders_sk_order_id ............................ [RUN]
[0m09:41:26  18 of 21 PASS not_null_fct_orders_sk_order_id .................................. [[32mPASS[0m in 0.03s]
[0m09:41:26  19 of 21 START test unique_dim_books_sk_book_id ................................ [RUN]
[0m09:41:26  19 of 21 PASS unique_dim_books_sk_book_id ...................................... [[32mPASS[0m in 0.03s]
[0m09:41:26  20 of 21 START test unique_dim_customers_sk_customer_id ........................ [RUN]
[0m09:41:26  20 of 21 PASS unique_dim_customers_sk_customer_id .............................. [[32mPASS[0m in 0.03s]
[0m09:41:26  21 of 21 START test unique_fct_orders_sk_order_id .............................. [RUN]
[0m09:41:26  21 of 21 PASS unique_fct_orders_sk_order_id .................................... [[32mPASS[0m in 0.03s]
[0m09:41:26  
[0m09:41:26  Running dbt Constraints
[0m09:41:26  Creating not null constraint for: nk_book_id in "pacbook-dwh"."final"."dim_books"
[0m09:41:26  Creating not null constraint for: sk_book_id in "pacbook-dwh"."final"."dim_books"
[0m09:41:26  Creating not null constraint for: nk_customer_id in "pacbook-dwh"."final"."dim_customers"
[0m09:41:26  Creating not null constraint for: sk_customer_id in "pacbook-dwh"."final"."dim_customers"
[0m09:41:26  Creating not null constraint for: date_id in "pacbook-dwh"."final"."dim_date"
[0m09:41:26  Creating not null constraint for: dd_order_id in "pacbook-dwh"."final"."fct_book_sales"
[0m09:41:26  Creating not null constraint for: nk_book_id in "pacbook-dwh"."final"."fct_book_sales"
[0m09:41:26  Creating not null constraint for: order_date in "pacbook-dwh"."final"."fct_book_sales"
[0m09:41:26  Creating not null constraint for: dd_order_id in "pacbook-dwh"."final"."fct_orders"
[0m09:41:26  Creating not null constraint for: nk_customer_id in "pacbook-dwh"."final"."fct_orders"
[0m09:41:26  Creating not null constraint for: sk_order_id in "pacbook-dwh"."final"."fct_orders"
[0m09:41:26  Creating not null constraint for: sk_book_id in "pacbook-dwh"."final"."dim_books"
[0m09:41:26  Creating primary key: DIM_BOOKS_SK_BOOK_ID_PK
[0m09:41:26  Creating not null constraint for: sk_customer_id in "pacbook-dwh"."final"."dim_customers"
[0m09:41:26  Creating primary key: DIM_CUSTOMERS_SK_CUSTOMER_ID_PK
[0m09:41:26  Creating not null constraint for: date_id in "pacbook-dwh"."final"."dim_date"
[0m09:41:26  Creating primary key: DIM_DATE_DATE_ID_PK
[0m09:41:26  Creating not null constraint for: sk_order_id in "pacbook-dwh"."final"."fct_orders"
[0m09:41:26  Creating primary key: FCT_ORDERS_SK_ORDER_ID_PK
[0m09:41:26  Skipping FCT_BOOK_SALES_NK_BOOK_ID_FK because a PK/UK was not found on the PK table: "pacbook-dwh"."final"."dim_books" ['nk_book_id']
[0m09:41:26  Skipping FCT_BOOK_SALES_ORDER_DATE_FK because a PK/UK was not found on the PK table: "pacbook-dwh"."final"."dim_date" ['date_actual']
[0m09:41:26  Skipping FCT_ORDERS_NK_CUSTOMER_ID_FK because a PK/UK was not found on the PK table: "pacbook-dwh"."final"."dim_customers" ['nk_customer_id']
[0m09:41:26  Finished dbt Constraints
[0m09:41:26  1 of 1 START hook: dbt_constraints.on-run-end.0 ................................ [RUN]
[0m09:41:26  1 of 1 OK hook: dbt_constraints.on-run-end.0 ................................... [[32mOK[0m in 0.59s]
[0m09:41:26  
[0m09:41:26  Finished running 1 project hook, 21 data tests in 0 hours 0 minutes and 1.50 seconds (1.50s).
[0m09:41:27  
[0m09:41:27  [32mCompleted successfully[0m
[0m09:41:27  
[0m09:41:27  Done. PASS=22 WARN=0 ERROR=0 SKIP=0 TOTAL=22
2024-11-19 16:41:28,705 - INFO - Transform to All Dimensions and Fact Tables - SUCCESS!
2024-11-19 16:41:28,705 - INFO - ==================================ENDING TRANSFROM DATA=======================================
2024-11-19 16:41:28,706 - INFO - [pid 45958] Worker Worker(salt=8240874147, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=45958) done      Transform()
2024-11-19 16:41:28,706 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-19 16:41:28,709 - INFO - Informed scheduler that task   Transform__99914b932b   has status   DONE
2024-11-19 16:41:28,709 - DEBUG - Asking scheduler for work...
2024-11-19 16:41:28,712 - DEBUG - Done
2024-11-19 16:41:28,712 - DEBUG - There are no more tasks to run at this time
2024-11-19 16:41:28,712 - INFO - Worker Worker(salt=8240874147, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=45958) was stopped. Shutting down Keep-Alive thread
2024-11-19 16:41:28,714 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 3 ran successfully:
    - 1 Extract()
    - 1 Load()
    - 1 Transform()

This progress looks :) because there were no failed tasks or missing dependencies

===== Luigi Execution Summary =====

2024-11-19 17:57:53,381 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-19 17:57:53,572 - INFO - EXTRACT 'public.address' - SUCCESS.
2024-11-19 17:57:53,588 - INFO - EXTRACT 'public.address_status' - SUCCESS.
2024-11-19 17:57:53,698 - INFO - EXTRACT 'public.author' - SUCCESS.
2024-11-19 17:57:54,041 - INFO - EXTRACT 'public.book' - SUCCESS.
2024-11-19 17:57:54,216 - INFO - EXTRACT 'public.book_author' - SUCCESS.
2024-11-19 17:57:54,227 - INFO - EXTRACT 'public.book_language' - SUCCESS.
2024-11-19 17:57:54,251 - INFO - EXTRACT 'public.country' - SUCCESS.
2024-11-19 17:57:54,430 - INFO - EXTRACT 'public.cust_order' - SUCCESS.
2024-11-19 17:57:54,477 - INFO - EXTRACT 'public.customer' - SUCCESS.
2024-11-19 17:57:54,523 - INFO - EXTRACT 'public.customer_address' - SUCCESS.
2024-11-19 17:57:54,852 - INFO - EXTRACT 'public.order_history' - SUCCESS.
2024-11-19 17:57:55,159 - INFO - EXTRACT 'public.order_line' - SUCCESS.
2024-11-19 17:57:55,172 - INFO - EXTRACT 'public.order_status' - SUCCESS.
2024-11-19 17:57:55,200 - INFO - EXTRACT 'public.publisher' - SUCCESS.
2024-11-19 17:57:55,214 - INFO - EXTRACT 'public.shipping_method' - SUCCESS.
2024-11-19 17:57:55,214 - INFO - EXTRACT ALL TABLE FROM SOURCE DATABASE - SUCCESS!
2024-11-19 17:57:55,219 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-19 17:57:55,219 - INFO - [pid 74316] Worker Worker(salt=816750656, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=74316) done      Extract()
2024-11-19 17:57:55,230 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-19 17:57:55,244 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-19 17:57:55,244 - DEBUG - Asking scheduler for work...
2024-11-19 17:57:55,256 - DEBUG - Pending tasks: 2
2024-11-19 17:57:55,257 - INFO - [pid 74316] Worker Worker(salt=816750656, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=74316) running   Load()
2024-11-19 17:57:55,441 - INFO - Read Extracted Data - SUCCESS!
2024-11-19 17:57:55,442 - INFO - Connect to DWH - SUCCESS!
2024-11-19 17:57:56,021 - INFO - Truncate Staging Schema in DWH - SUCCESS!
2024-11-19 17:57:56,022 - INFO - ==================================STARTING LOAD DATA=======================================
2024-11-19 17:57:56,081 - INFO - Load country table - SUCCESS!
2024-11-19 17:57:56,235 - INFO - Load address table - SUCCESS!
2024-11-19 17:57:56,258 - INFO - Load address_status table - SUCCESS!
2024-11-19 17:57:56,284 - INFO - Load book_language table - SUCCESS!
2024-11-19 17:57:56,461 - INFO - Load customer table - SUCCESS!
2024-11-19 17:57:56,606 - INFO - Load publisher table - SUCCESS!
2024-11-19 17:57:56,634 - INFO - Load shipping_method table - SUCCESS!
2024-11-19 17:57:57,222 - INFO - Load author table - SUCCESS!
2024-11-19 17:57:58,949 - INFO - Load book table - SUCCESS!
2024-11-19 17:58:00,100 - INFO - Load cust_order table - SUCCESS!
2024-11-19 17:58:00,620 - INFO - Load customer_address table - SUCCESS!
2024-11-19 17:58:00,646 - INFO - Load order_status table - SUCCESS!
2024-11-19 17:58:02,196 - INFO - Load book_author table - SUCCESS!
2024-11-19 17:58:04,313 - INFO - Load order_history table - SUCCESS!
2024-11-19 17:58:05,710 - INFO - Load order_line table - SUCCESS!
2024-11-19 17:58:05,710 - INFO - LOAD All Tables To Pacbook DWH Staging Schema - SUCCESS!
2024-11-19 17:58:05,714 - INFO - ==================================ENDING LOAD DATA=======================================
2024-11-19 17:58:05,717 - INFO - [pid 74316] Worker Worker(salt=816750656, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=74316) done      Load()
2024-11-19 17:58:05,718 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-19 17:58:05,727 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-11-19 17:58:05,728 - DEBUG - Asking scheduler for work...
2024-11-19 17:58:05,736 - DEBUG - Pending tasks: 1
2024-11-19 17:58:05,736 - INFO - [pid 74316] Worker Worker(salt=816750656, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=74316) running   Transform()
2024-11-19 17:58:05,738 - INFO - ==================================STARTING TRANSFROM DATA=======================================
[0m10:58:11  Running with dbt=1.9.0-b4
[0m10:58:12  Installing dbt-labs/dbt_utils
[0m10:58:13  Installed from version 1.1.1
[0m10:58:13  Updated version available: 1.3.0
[0m10:58:13  Installing calogica/dbt_date
[0m10:58:13  Installed from version 0.10.0
[0m10:58:13  Updated version available: 0.10.1
[0m10:58:13  Installing Snowflake-Labs/dbt_constraints
[0m10:58:14  Installed from version 0.6.3
[0m10:58:14  Updated version available: 1.0.4
[0m10:58:14  
[0m10:58:14  Updates available for packages: ['dbt-labs/dbt_utils', 'calogica/dbt_date', 'Snowflake-Labs/dbt_constraints']                 
Update your versions in packages.yml, then run dbt deps
[0m10:58:19  Running with dbt=1.9.0-b4
[0m10:58:19  Registered adapter: postgres=1.8.2
[0m10:58:22  Found 19 models, 1 seed, 1 operation, 21 data tests, 2 snapshots, 15 sources, 751 macros
[0m10:58:22  
[0m10:58:22  Concurrency: 1 threads (target='dev')
[0m10:58:22  
[0m10:58:22  1 of 1 START seed file final.dim_date .......................................... [RUN]
[0m11:03:11  1 of 1 OK loaded seed file final.dim_date ...................................... [[32mINSERT 29220[0m in 288.46s]
[0m11:03:11  
[0m11:03:11  Running dbt Constraints
[0m11:03:11  Finished dbt Constraints
[0m11:03:11  1 of 1 START hook: dbt_constraints.on-run-end.0 ................................ [RUN]
[0m11:03:11  1 of 1 OK hook: dbt_constraints.on-run-end.0 ................................... [[32mOK[0m in 0.12s]
[0m11:03:11  
[0m11:03:11  Finished running 1 project hook, 1 seed in 0 hours 4 minutes and 49.22 seconds (289.22s).
[0m11:03:11  
[0m11:03:11  [32mCompleted successfully[0m
[0m11:03:11  
[0m11:03:11  Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m11:03:16  Running with dbt=1.9.0-b4
[0m11:03:16  Registered adapter: postgres=1.8.2
[0m11:03:18  Found 19 models, 1 seed, 1 operation, 21 data tests, 2 snapshots, 15 sources, 751 macros
[0m11:03:18  
[0m11:03:18  Concurrency: 1 threads (target='dev')
[0m11:03:18  
[0m11:03:18  1 of 19 START sql view model final.stg_pacbook__address ........................ [RUN]
[0m11:03:18  1 of 19 OK created sql view model final.stg_pacbook__address ................... [[32mCREATE VIEW[0m in 0.37s]
[0m11:03:18  2 of 19 START sql view model final.stg_pacbook__address_status ................. [RUN]
[0m11:03:19  2 of 19 OK created sql view model final.stg_pacbook__address_status ............ [[32mCREATE VIEW[0m in 0.15s]
[0m11:03:19  3 of 19 START sql view model final.stg_pacbook__author ......................... [RUN]
[0m11:03:19  3 of 19 OK created sql view model final.stg_pacbook__author .................... [[32mCREATE VIEW[0m in 0.17s]
[0m11:03:19  4 of 19 START sql view model final.stg_pacbook__book ........................... [RUN]
[0m11:03:19  4 of 19 OK created sql view model final.stg_pacbook__book ...................... [[32mCREATE VIEW[0m in 0.21s]
[0m11:03:19  5 of 19 START sql view model final.stg_pacbook__book_author .................... [RUN]
[0m11:03:19  5 of 19 OK created sql view model final.stg_pacbook__book_author ............... [[32mCREATE VIEW[0m in 0.20s]
[0m11:03:19  6 of 19 START sql view model final.stg_pacbook__book_language .................. [RUN]
[0m11:03:19  6 of 19 OK created sql view model final.stg_pacbook__book_language ............. [[32mCREATE VIEW[0m in 0.23s]
[0m11:03:19  7 of 19 START sql view model final.stg_pacbook__country ........................ [RUN]
[0m11:03:20  7 of 19 OK created sql view model final.stg_pacbook__country ................... [[32mCREATE VIEW[0m in 0.16s]
[0m11:03:20  8 of 19 START sql view model final.stg_pacbook__cust_order ..................... [RUN]
[0m11:03:20  8 of 19 OK created sql view model final.stg_pacbook__cust_order ................ [[32mCREATE VIEW[0m in 0.15s]
[0m11:03:20  9 of 19 START sql view model final.stg_pacbook__customer ....................... [RUN]
[0m11:03:20  9 of 19 OK created sql view model final.stg_pacbook__customer .................. [[32mCREATE VIEW[0m in 0.18s]
[0m11:03:20  10 of 19 START sql view model final.stg_pacbook__customer_address .............. [RUN]
[0m11:03:20  10 of 19 OK created sql view model final.stg_pacbook__customer_address ......... [[32mCREATE VIEW[0m in 0.16s]
[0m11:03:20  11 of 19 START sql view model final.stg_pacbook__order_history ................. [RUN]
[0m11:03:20  11 of 19 OK created sql view model final.stg_pacbook__order_history ............ [[32mCREATE VIEW[0m in 0.20s]
[0m11:03:20  12 of 19 START sql view model final.stg_pacbook__order_line .................... [RUN]
[0m11:03:21  12 of 19 OK created sql view model final.stg_pacbook__order_line ............... [[32mCREATE VIEW[0m in 0.14s]
[0m11:03:21  13 of 19 START sql view model final.stg_pacbook__order_status .................. [RUN]
[0m11:03:21  13 of 19 OK created sql view model final.stg_pacbook__order_status ............. [[32mCREATE VIEW[0m in 0.14s]
[0m11:03:21  14 of 19 START sql view model final.stg_pacbook__publisher ..................... [RUN]
[0m11:03:21  14 of 19 OK created sql view model final.stg_pacbook__publisher ................ [[32mCREATE VIEW[0m in 0.33s]
[0m11:03:21  15 of 19 START sql view model final.stg_pacbook__shipping_method ............... [RUN]
[0m11:03:21  15 of 19 OK created sql view model final.stg_pacbook__shipping_method .......... [[32mCREATE VIEW[0m in 0.16s]
[0m11:03:21  16 of 19 START sql table model final.dim_customers ............................. [RUN]
[0m11:03:22  16 of 19 OK created sql table model final.dim_customers ........................ [[32mSELECT 3350[0m in 0.38s]
[0m11:03:22  17 of 19 START sql table model final.dim_books ................................. [RUN]
[0m11:03:22  17 of 19 OK created sql table model final.dim_books ............................ [[32mSELECT 11127[0m in 0.42s]
[0m11:03:22  18 of 19 START sql table model final.fct_book_sales ............................ [RUN]
[0m11:03:23  18 of 19 OK created sql table model final.fct_book_sales ....................... [[32mSELECT 15399[0m in 1.39s]
[0m11:03:23  19 of 19 START sql table model final.fct_orders ................................ [RUN]
[0m11:03:26  19 of 19 OK created sql table model final.fct_orders ........................... [[32mSELECT 7550[0m in 2.10s]
[0m11:03:26  
[0m11:03:26  Running dbt Constraints
[0m11:03:26  Finished dbt Constraints
[0m11:03:26  1 of 1 START hook: dbt_constraints.on-run-end.0 ................................ [RUN]
[0m11:03:26  1 of 1 OK hook: dbt_constraints.on-run-end.0 ................................... [[32mOK[0m in 0.13s]
[0m11:03:26  
[0m11:03:26  Finished running 1 project hook, 4 table models, 15 view models in 0 hours 0 minutes and 8.25 seconds (8.25s).
[0m11:03:26  
[0m11:03:26  [32mCompleted successfully[0m
[0m11:03:26  
[0m11:03:26  Done. PASS=20 WARN=0 ERROR=0 SKIP=0 TOTAL=20
[0m11:03:30  Running with dbt=1.9.0-b4
[0m11:03:31  Registered adapter: postgres=1.8.2
[0m11:03:32  Found 19 models, 1 seed, 1 operation, 21 data tests, 2 snapshots, 15 sources, 751 macros
[0m11:03:32  
[0m11:03:32  Concurrency: 1 threads (target='dev')
[0m11:03:32  
[0m11:03:32  1 of 2 START snapshot snapshots.dim_books_snapshot ............................. [RUN]
[0m11:03:33  1 of 2 OK snapshotted snapshots.dim_books_snapshot ............................. [[32mSELECT 11127[0m in 0.53s]
[0m11:03:33  2 of 2 START snapshot snapshots.dim_customers_snapshot ......................... [RUN]
[0m11:03:33  2 of 2 OK snapshotted snapshots.dim_customers_snapshot ......................... [[32mSELECT 3350[0m in 0.23s]
[0m11:03:33  
[0m11:03:33  Running dbt Constraints
[0m11:03:33  Finished dbt Constraints
[0m11:03:33  1 of 1 START hook: dbt_constraints.on-run-end.0 ................................ [RUN]
[0m11:03:33  1 of 1 OK hook: dbt_constraints.on-run-end.0 ................................... [[32mOK[0m in 0.19s]
[0m11:03:33  
[0m11:03:33  Finished running 1 project hook, 2 snapshots in 0 hours 0 minutes and 1.49 seconds (1.49s).
[0m11:03:34  
[0m11:03:34  [32mCompleted successfully[0m
[0m11:03:34  
[0m11:03:34  Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m11:03:38  Running with dbt=1.9.0-b4
[0m11:03:38  Registered adapter: postgres=1.8.2
[0m11:03:40  Found 19 models, 1 seed, 1 operation, 21 data tests, 2 snapshots, 15 sources, 751 macros
[0m11:03:40  
[0m11:03:40  Concurrency: 1 threads (target='dev')
[0m11:03:40  
[0m11:03:40  1 of 21 START test dbt_constraints_foreign_key_fct_book_sales_nk_book_id__nk_book_id__ref_dim_books_  [RUN]
[0m11:03:40  1 of 21 PASS dbt_constraints_foreign_key_fct_book_sales_nk_book_id__nk_book_id__ref_dim_books_  [[32mPASS[0m in 0.30s]
[0m11:03:40  2 of 21 START test dbt_constraints_foreign_key_fct_book_sales_order_date__date_actual__ref_dim_date_  [RUN]
[0m11:03:41  2 of 21 PASS dbt_constraints_foreign_key_fct_book_sales_order_date__date_actual__ref_dim_date_  [[32mPASS[0m in 0.15s]
[0m11:03:41  3 of 21 START test dbt_constraints_foreign_key_fct_orders_nk_customer_id__nk_customer_id__ref_dim_customers_  [RUN]
[0m11:03:41  3 of 21 PASS dbt_constraints_foreign_key_fct_orders_nk_customer_id__nk_customer_id__ref_dim_customers_  [[32mPASS[0m in 0.12s]
[0m11:03:41  4 of 21 START test dbt_constraints_primary_key_dim_books_sk_book_id ............ [RUN]
[0m11:03:41  4 of 21 PASS dbt_constraints_primary_key_dim_books_sk_book_id .................. [[32mPASS[0m in 0.16s]
[0m11:03:41  5 of 21 START test dbt_constraints_primary_key_dim_customers_sk_customer_id .... [RUN]
[0m11:03:41  5 of 21 PASS dbt_constraints_primary_key_dim_customers_sk_customer_id .......... [[32mPASS[0m in 0.13s]
[0m11:03:41  6 of 21 START test dbt_constraints_primary_key_dim_date_date_id ................ [RUN]
[0m11:03:41  6 of 21 PASS dbt_constraints_primary_key_dim_date_date_id ...................... [[32mPASS[0m in 0.16s]
[0m11:03:41  7 of 21 START test dbt_constraints_primary_key_fct_orders_sk_order_id .......... [RUN]
[0m11:03:41  7 of 21 PASS dbt_constraints_primary_key_fct_orders_sk_order_id ................ [[32mPASS[0m in 0.14s]
[0m11:03:41  8 of 21 START test not_null_dim_books_nk_book_id ............................... [RUN]
[0m11:03:42  8 of 21 PASS not_null_dim_books_nk_book_id ..................................... [[32mPASS[0m in 0.13s]
[0m11:03:42  9 of 21 START test not_null_dim_books_sk_book_id ............................... [RUN]
[0m11:03:42  9 of 21 PASS not_null_dim_books_sk_book_id ..................................... [[32mPASS[0m in 0.12s]
[0m11:03:42  10 of 21 START test not_null_dim_customers_nk_customer_id ...................... [RUN]
[0m11:03:42  10 of 21 PASS not_null_dim_customers_nk_customer_id ............................ [[32mPASS[0m in 0.10s]
[0m11:03:42  11 of 21 START test not_null_dim_customers_sk_customer_id ...................... [RUN]
[0m11:03:42  11 of 21 PASS not_null_dim_customers_sk_customer_id ............................ [[32mPASS[0m in 0.13s]
[0m11:03:42  12 of 21 START test not_null_dim_date_date_id .................................. [RUN]
[0m11:03:42  12 of 21 PASS not_null_dim_date_date_id ........................................ [[32mPASS[0m in 0.11s]
[0m11:03:42  13 of 21 START test not_null_fct_book_sales_dd_order_id ........................ [RUN]
[0m11:03:42  13 of 21 PASS not_null_fct_book_sales_dd_order_id .............................. [[32mPASS[0m in 0.11s]
[0m11:03:42  14 of 21 START test not_null_fct_book_sales_nk_book_id ......................... [RUN]
[0m11:03:42  14 of 21 PASS not_null_fct_book_sales_nk_book_id ............................... [[32mPASS[0m in 0.11s]
[0m11:03:42  15 of 21 START test not_null_fct_book_sales_order_date ......................... [RUN]
[0m11:03:42  15 of 21 PASS not_null_fct_book_sales_order_date ............................... [[32mPASS[0m in 0.11s]
[0m11:03:42  16 of 21 START test not_null_fct_orders_dd_order_id ............................ [RUN]
[0m11:03:43  16 of 21 PASS not_null_fct_orders_dd_order_id .................................. [[32mPASS[0m in 0.09s]
[0m11:03:43  17 of 21 START test not_null_fct_orders_nk_customer_id ......................... [RUN]
[0m11:03:43  17 of 21 PASS not_null_fct_orders_nk_customer_id ............................... [[32mPASS[0m in 0.06s]
[0m11:03:43  18 of 21 START test not_null_fct_orders_sk_order_id ............................ [RUN]
[0m11:03:43  18 of 21 PASS not_null_fct_orders_sk_order_id .................................. [[32mPASS[0m in 0.07s]
[0m11:03:43  19 of 21 START test unique_dim_books_sk_book_id ................................ [RUN]
[0m11:03:43  19 of 21 PASS unique_dim_books_sk_book_id ...................................... [[32mPASS[0m in 0.10s]
[0m11:03:43  20 of 21 START test unique_dim_customers_sk_customer_id ........................ [RUN]
[0m11:03:43  20 of 21 PASS unique_dim_customers_sk_customer_id .............................. [[32mPASS[0m in 0.09s]
[0m11:03:43  21 of 21 START test unique_fct_orders_sk_order_id .............................. [RUN]
[0m11:03:43  21 of 21 PASS unique_fct_orders_sk_order_id .................................... [[32mPASS[0m in 0.10s]
[0m11:03:43  
[0m11:03:43  Running dbt Constraints
[0m11:03:43  Creating not null constraint for: nk_book_id in "pacbook-dwh"."final"."dim_books"
[0m11:03:43  Creating not null constraint for: sk_book_id in "pacbook-dwh"."final"."dim_books"
[0m11:03:43  Creating not null constraint for: nk_customer_id in "pacbook-dwh"."final"."dim_customers"
[0m11:03:44  Creating not null constraint for: sk_customer_id in "pacbook-dwh"."final"."dim_customers"
[0m11:03:44  Creating not null constraint for: date_id in "pacbook-dwh"."final"."dim_date"
[0m11:03:44  Creating not null constraint for: dd_order_id in "pacbook-dwh"."final"."fct_book_sales"
[0m11:03:44  Creating not null constraint for: nk_book_id in "pacbook-dwh"."final"."fct_book_sales"
[0m11:03:44  Creating not null constraint for: order_date in "pacbook-dwh"."final"."fct_book_sales"
[0m11:03:44  Creating not null constraint for: dd_order_id in "pacbook-dwh"."final"."fct_orders"
[0m11:03:44  Creating not null constraint for: nk_customer_id in "pacbook-dwh"."final"."fct_orders"
[0m11:03:44  Creating not null constraint for: sk_order_id in "pacbook-dwh"."final"."fct_orders"
[0m11:03:44  Creating not null constraint for: sk_book_id in "pacbook-dwh"."final"."dim_books"
[0m11:03:44  Creating primary key: DIM_BOOKS_SK_BOOK_ID_PK
[0m11:03:44  Creating not null constraint for: sk_customer_id in "pacbook-dwh"."final"."dim_customers"
[0m11:03:44  Creating primary key: DIM_CUSTOMERS_SK_CUSTOMER_ID_PK
[0m11:03:44  Creating not null constraint for: date_id in "pacbook-dwh"."final"."dim_date"
[0m11:03:44  Creating primary key: DIM_DATE_DATE_ID_PK
[0m11:03:44  Creating not null constraint for: sk_order_id in "pacbook-dwh"."final"."fct_orders"
[0m11:03:45  Creating primary key: FCT_ORDERS_SK_ORDER_ID_PK
[0m11:03:45  Skipping FCT_BOOK_SALES_NK_BOOK_ID_FK because a PK/UK was not found on the PK table: "pacbook-dwh"."final"."dim_books" ['nk_book_id']
[0m11:03:45  Skipping FCT_BOOK_SALES_ORDER_DATE_FK because a PK/UK was not found on the PK table: "pacbook-dwh"."final"."dim_date" ['date_actual']
[0m11:03:45  Skipping FCT_ORDERS_NK_CUSTOMER_ID_FK because a PK/UK was not found on the PK table: "pacbook-dwh"."final"."dim_customers" ['nk_customer_id']
[0m11:03:45  Finished dbt Constraints
[0m11:03:45  1 of 1 START hook: dbt_constraints.on-run-end.0 ................................ [RUN]
[0m11:03:45  1 of 1 OK hook: dbt_constraints.on-run-end.0 ................................... [[32mOK[0m in 1.75s]
[0m11:03:45  
[0m11:03:45  Finished running 1 project hook, 21 data tests in 0 hours 0 minutes and 5.09 seconds (5.09s).
[0m11:03:45  
[0m11:03:45  [32mCompleted successfully[0m
[0m11:03:45  
[0m11:03:45  Done. PASS=22 WARN=0 ERROR=0 SKIP=0 TOTAL=22
2024-11-19 18:03:47,589 - INFO - Transform to All Dimensions and Fact Tables - SUCCESS!
2024-11-19 18:03:47,590 - INFO - ==================================ENDING TRANSFROM DATA=======================================
2024-11-19 18:03:47,591 - INFO - [pid 74316] Worker Worker(salt=816750656, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=74316) done      Transform()
2024-11-19 18:03:47,593 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-19 18:03:47,606 - INFO - Informed scheduler that task   Transform__99914b932b   has status   DONE
2024-11-19 18:03:47,607 - DEBUG - Asking scheduler for work...
2024-11-19 18:03:47,617 - DEBUG - Done
2024-11-19 18:03:47,618 - DEBUG - There are no more tasks to run at this time
2024-11-19 18:03:47,618 - INFO - Worker Worker(salt=816750656, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=74316) was stopped. Shutting down Keep-Alive thread
2024-11-19 18:03:47,628 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 3 ran successfully:
    - 1 Extract()
    - 1 Load()
    - 1 Transform()

This progress looks :) because there were no failed tasks or missing dependencies

===== Luigi Execution Summary =====

2024-11-19 18:05:45,409 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-19 18:05:45,464 - INFO - EXTRACT 'public.address' - SUCCESS.
2024-11-19 18:05:45,471 - INFO - EXTRACT 'public.address_status' - SUCCESS.
2024-11-19 18:05:45,511 - INFO - EXTRACT 'public.author' - SUCCESS.
2024-11-19 18:05:45,653 - INFO - EXTRACT 'public.book' - SUCCESS.
2024-11-19 18:05:45,767 - INFO - EXTRACT 'public.book_author' - SUCCESS.
2024-11-19 18:05:45,777 - INFO - EXTRACT 'public.book_language' - SUCCESS.
2024-11-19 18:05:45,787 - INFO - EXTRACT 'public.country' - SUCCESS.
2024-11-19 18:05:45,906 - INFO - EXTRACT 'public.cust_order' - SUCCESS.
2024-11-19 18:05:45,929 - INFO - EXTRACT 'public.customer' - SUCCESS.
2024-11-19 18:05:45,958 - INFO - EXTRACT 'public.customer_address' - SUCCESS.
2024-11-19 18:05:46,269 - INFO - EXTRACT 'public.order_history' - SUCCESS.
2024-11-19 18:05:46,441 - INFO - EXTRACT 'public.order_line' - SUCCESS.
2024-11-19 18:05:46,450 - INFO - EXTRACT 'public.order_status' - SUCCESS.
2024-11-19 18:05:46,470 - INFO - EXTRACT 'public.publisher' - SUCCESS.
2024-11-19 18:05:46,480 - INFO - EXTRACT 'public.shipping_method' - SUCCESS.
2024-11-19 18:05:46,480 - INFO - EXTRACT ALL TABLE FROM SOURCE DATABASE - SUCCESS!
2024-11-19 18:05:46,483 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-19 18:05:46,483 - INFO - [pid 78821] Worker Worker(salt=2714040240, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=78821) done      Extract()
2024-11-19 18:05:46,487 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-19 18:05:46,495 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-19 18:05:46,495 - DEBUG - Asking scheduler for work...
2024-11-19 18:05:46,502 - DEBUG - Pending tasks: 2
2024-11-19 18:05:46,502 - INFO - [pid 78821] Worker Worker(salt=2714040240, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=78821) running   Load()
2024-11-19 18:05:46,675 - INFO - Read Extracted Data - SUCCESS!
2024-11-19 18:05:46,676 - INFO - Connect to DWH - SUCCESS!
2024-11-19 18:05:47,193 - INFO - Truncate Staging Schema in DWH - SUCCESS!
2024-11-19 18:05:47,194 - INFO - ==================================STARTING LOAD DATA=======================================
2024-11-19 18:05:47,246 - INFO - Load country table - SUCCESS!
2024-11-19 18:05:47,391 - INFO - Load address table - SUCCESS!
2024-11-19 18:05:47,411 - INFO - Load address_status table - SUCCESS!
2024-11-19 18:05:47,430 - INFO - Load book_language table - SUCCESS!
2024-11-19 18:05:47,554 - INFO - Load customer table - SUCCESS!
2024-11-19 18:05:47,647 - INFO - Load publisher table - SUCCESS!
2024-11-19 18:05:47,666 - INFO - Load shipping_method table - SUCCESS!
2024-11-19 18:05:48,002 - INFO - Load author table - SUCCESS!
2024-11-19 18:05:49,483 - INFO - Load book table - SUCCESS!
2024-11-19 18:05:50,546 - INFO - Load cust_order table - SUCCESS!
2024-11-19 18:05:51,027 - INFO - Load customer_address table - SUCCESS!
2024-11-19 18:05:51,050 - INFO - Load order_status table - SUCCESS!
2024-11-19 18:05:52,322 - INFO - Load book_author table - SUCCESS!
2024-11-19 18:05:54,160 - INFO - Load order_history table - SUCCESS!
2024-11-19 18:05:55,501 - INFO - Load order_line table - SUCCESS!
2024-11-19 18:05:55,501 - INFO - LOAD All Tables To Pacbook DWH Staging Schema - SUCCESS!
2024-11-19 18:05:55,514 - INFO - ==================================ENDING LOAD DATA=======================================
2024-11-19 18:05:55,522 - INFO - [pid 78821] Worker Worker(salt=2714040240, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=78821) done      Load()
2024-11-19 18:05:55,524 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-19 18:05:55,539 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-11-19 18:05:55,541 - DEBUG - Asking scheduler for work...
2024-11-19 18:05:55,558 - DEBUG - Pending tasks: 1
2024-11-19 18:05:55,559 - INFO - [pid 78821] Worker Worker(salt=2714040240, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=78821) running   Transform()
2024-11-19 18:05:55,561 - INFO - ==================================STARTING TRANSFROM DATA=======================================
[0m11:05:58  Running with dbt=1.9.0-b4
[0m11:06:00  Installing dbt-labs/dbt_utils
[0m11:06:00  Installed from version 1.1.1
[0m11:06:00  Updated version available: 1.3.0
[0m11:06:00  Installing calogica/dbt_date
[0m11:06:00  Installed from version 0.10.0
[0m11:06:01  Updated version available: 0.10.1
[0m11:06:01  Installing Snowflake-Labs/dbt_constraints
[0m11:06:01  Installed from version 0.6.3
[0m11:06:01  Updated version available: 1.0.4
[0m11:06:01  
[0m11:06:01  Updates available for packages: ['dbt-labs/dbt_utils', 'calogica/dbt_date', 'Snowflake-Labs/dbt_constraints']                 
Update your versions in packages.yml, then run dbt deps
[0m11:06:05  Running with dbt=1.9.0-b4
[0m11:06:05  Registered adapter: postgres=1.8.2
[0m11:06:07  Found 19 models, 1 seed, 1 operation, 21 data tests, 2 snapshots, 15 sources, 751 macros
[0m11:06:07  
[0m11:06:07  Concurrency: 1 threads (target='dev')
[0m11:06:07  
[0m11:06:07  1 of 1 START seed file final.dim_date .......................................... [RUN]
[0m11:13:30  1 of 1 OK loaded seed file final.dim_date ...................................... [[32mINSERT 29220[0m in 442.47s]
[0m11:13:30  
[0m11:13:30  Running dbt Constraints
[0m11:13:30  Finished dbt Constraints
[0m11:13:30  1 of 1 START hook: dbt_constraints.on-run-end.0 ................................ [RUN]
[0m11:13:30  1 of 1 OK hook: dbt_constraints.on-run-end.0 ................................... [[32mOK[0m in 0.32s]
[0m11:13:30  
[0m11:13:30  Finished running 1 project hook, 1 seed in 0 hours 7 minutes and 23.36 seconds (443.36s).
[0m11:13:30  
[0m11:13:30  [32mCompleted successfully[0m
[0m11:13:30  
[0m11:13:30  Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m11:13:40  Running with dbt=1.9.0-b4
[0m11:13:41  Registered adapter: postgres=1.8.2
[0m11:13:44  Found 19 models, 1 seed, 1 operation, 21 data tests, 2 snapshots, 15 sources, 751 macros
[0m11:13:44  
[0m11:13:44  Concurrency: 1 threads (target='dev')
[0m11:13:44  
[0m11:13:45  1 of 19 START sql view model final.stg_pacbook__address ........................ [RUN]
[0m11:13:46  1 of 19 OK created sql view model final.stg_pacbook__address ................... [[32mCREATE VIEW[0m in 0.54s]
[0m11:13:46  2 of 19 START sql view model final.stg_pacbook__address_status ................. [RUN]
[0m11:13:46  2 of 19 OK created sql view model final.stg_pacbook__address_status ............ [[32mCREATE VIEW[0m in 0.19s]
[0m11:13:46  3 of 19 START sql view model final.stg_pacbook__author ......................... [RUN]
[0m11:13:46  3 of 19 OK created sql view model final.stg_pacbook__author .................... [[32mCREATE VIEW[0m in 0.21s]
[0m11:13:46  4 of 19 START sql view model final.stg_pacbook__book ........................... [RUN]
[0m11:13:47  4 of 19 OK created sql view model final.stg_pacbook__book ...................... [[32mCREATE VIEW[0m in 0.16s]
[0m11:13:47  5 of 19 START sql view model final.stg_pacbook__book_author .................... [RUN]
[0m11:13:47  5 of 19 OK created sql view model final.stg_pacbook__book_author ............... [[32mCREATE VIEW[0m in 0.22s]
[0m11:13:47  6 of 19 START sql view model final.stg_pacbook__book_language .................. [RUN]
[0m11:13:47  6 of 19 OK created sql view model final.stg_pacbook__book_language ............. [[32mCREATE VIEW[0m in 0.25s]
[0m11:13:47  7 of 19 START sql view model final.stg_pacbook__country ........................ [RUN]
[0m11:13:47  7 of 19 OK created sql view model final.stg_pacbook__country ................... [[32mCREATE VIEW[0m in 0.20s]
[0m11:13:47  8 of 19 START sql view model final.stg_pacbook__cust_order ..................... [RUN]
[0m11:13:48  8 of 19 OK created sql view model final.stg_pacbook__cust_order ................ [[32mCREATE VIEW[0m in 0.18s]
[0m11:13:48  9 of 19 START sql view model final.stg_pacbook__customer ....................... [RUN]
[0m11:13:48  9 of 19 OK created sql view model final.stg_pacbook__customer .................. [[32mCREATE VIEW[0m in 0.20s]
[0m11:13:48  10 of 19 START sql view model final.stg_pacbook__customer_address .............. [RUN]
[0m11:13:48  10 of 19 OK created sql view model final.stg_pacbook__customer_address ......... [[32mCREATE VIEW[0m in 0.13s]
[0m11:13:48  11 of 19 START sql view model final.stg_pacbook__order_history ................. [RUN]
[0m11:13:49  11 of 19 OK created sql view model final.stg_pacbook__order_history ............ [[32mCREATE VIEW[0m in 0.86s]
[0m11:13:49  12 of 19 START sql view model final.stg_pacbook__order_line .................... [RUN]
[0m11:13:49  12 of 19 OK created sql view model final.stg_pacbook__order_line ............... [[32mCREATE VIEW[0m in 0.22s]
[0m11:13:49  13 of 19 START sql view model final.stg_pacbook__order_status .................. [RUN]
[0m11:13:49  13 of 19 OK created sql view model final.stg_pacbook__order_status ............. [[32mCREATE VIEW[0m in 0.23s]
[0m11:13:49  14 of 19 START sql view model final.stg_pacbook__publisher ..................... [RUN]
[0m11:13:49  14 of 19 OK created sql view model final.stg_pacbook__publisher ................ [[32mCREATE VIEW[0m in 0.19s]
[0m11:13:50  15 of 19 START sql view model final.stg_pacbook__shipping_method ............... [RUN]
[0m11:13:50  15 of 19 OK created sql view model final.stg_pacbook__shipping_method .......... [[32mCREATE VIEW[0m in 0.20s]
[0m11:13:50  16 of 19 START sql table model final.dim_customers ............................. [RUN]
[0m11:13:50  16 of 19 OK created sql table model final.dim_customers ........................ [[32mSELECT 3350[0m in 0.58s]
[0m11:13:50  17 of 19 START sql table model final.dim_books ................................. [RUN]
[0m11:13:51  17 of 19 OK created sql table model final.dim_books ............................ [[32mSELECT 11127[0m in 0.60s]
[0m11:13:51  18 of 19 START sql table model final.fct_book_sales ............................ [RUN]
[0m11:13:52  18 of 19 OK created sql table model final.fct_book_sales ....................... [[32mSELECT 15399[0m in 0.62s]
[0m11:13:52  19 of 19 START sql table model final.fct_orders ................................ [RUN]
[0m11:13:52  19 of 19 OK created sql table model final.fct_orders ........................... [[32mSELECT 7550[0m in 0.40s]
[0m11:13:52  
[0m11:13:52  Running dbt Constraints
[0m11:13:52  Finished dbt Constraints
[0m11:13:52  1 of 1 START hook: dbt_constraints.on-run-end.0 ................................ [RUN]
[0m11:13:52  1 of 1 OK hook: dbt_constraints.on-run-end.0 ................................... [[32mOK[0m in 0.20s]
[0m11:13:52  
[0m11:13:52  Finished running 1 project hook, 4 table models, 15 view models in 0 hours 0 minutes and 8.04 seconds (8.04s).
[0m11:13:53  
[0m11:13:53  [32mCompleted successfully[0m
[0m11:13:53  
[0m11:13:53  Done. PASS=20 WARN=0 ERROR=0 SKIP=0 TOTAL=20
[0m11:13:59  Running with dbt=1.9.0-b4
[0m11:14:00  Registered adapter: postgres=1.8.2
[0m11:14:02  Found 19 models, 1 seed, 1 operation, 21 data tests, 2 snapshots, 15 sources, 751 macros
[0m11:14:02  
[0m11:14:02  Concurrency: 1 threads (target='dev')
[0m11:14:02  
[0m11:14:02  1 of 2 START snapshot snapshots.dim_books_snapshot ............................. [RUN]
[0m11:14:04  1 of 2 OK snapshotted snapshots.dim_books_snapshot ............................. [[32mINSERT 0 1[0m in 1.08s]
[0m11:14:04  2 of 2 START snapshot snapshots.dim_customers_snapshot ......................... [RUN]
[0m11:14:04  2 of 2 OK snapshotted snapshots.dim_customers_snapshot ......................... [[32mINSERT 0 0[0m in 0.44s]
[0m11:14:04  
[0m11:14:04  Running dbt Constraints
[0m11:14:04  Finished dbt Constraints
[0m11:14:04  1 of 1 START hook: dbt_constraints.on-run-end.0 ................................ [RUN]
[0m11:14:04  1 of 1 OK hook: dbt_constraints.on-run-end.0 ................................... [[32mOK[0m in 0.19s]
[0m11:14:04  
[0m11:14:04  Finished running 1 project hook, 2 snapshots in 0 hours 0 minutes and 2.27 seconds (2.27s).
[0m11:14:04  
[0m11:14:04  [32mCompleted successfully[0m
[0m11:14:04  
[0m11:14:04  Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m11:14:10  Running with dbt=1.9.0-b4
[0m11:14:10  Registered adapter: postgres=1.8.2
[0m11:14:12  Found 19 models, 1 seed, 1 operation, 21 data tests, 2 snapshots, 15 sources, 751 macros
[0m11:14:12  
[0m11:14:12  Concurrency: 1 threads (target='dev')
[0m11:14:12  
[0m11:14:13  1 of 21 START test dbt_constraints_foreign_key_fct_book_sales_nk_book_id__nk_book_id__ref_dim_books_  [RUN]
[0m11:14:13  1 of 21 PASS dbt_constraints_foreign_key_fct_book_sales_nk_book_id__nk_book_id__ref_dim_books_  [[32mPASS[0m in 0.22s]
[0m11:14:13  2 of 21 START test dbt_constraints_foreign_key_fct_book_sales_order_date__date_actual__ref_dim_date_  [RUN]
[0m11:14:13  2 of 21 PASS dbt_constraints_foreign_key_fct_book_sales_order_date__date_actual__ref_dim_date_  [[32mPASS[0m in 0.22s]
[0m11:14:13  3 of 21 START test dbt_constraints_foreign_key_fct_orders_nk_customer_id__nk_customer_id__ref_dim_customers_  [RUN]
[0m11:14:13  3 of 21 PASS dbt_constraints_foreign_key_fct_orders_nk_customer_id__nk_customer_id__ref_dim_customers_  [[32mPASS[0m in 0.18s]
[0m11:14:13  4 of 21 START test dbt_constraints_primary_key_dim_books_sk_book_id ............ [RUN]
[0m11:14:14  4 of 21 PASS dbt_constraints_primary_key_dim_books_sk_book_id .................. [[32mPASS[0m in 0.20s]
[0m11:14:14  5 of 21 START test dbt_constraints_primary_key_dim_customers_sk_customer_id .... [RUN]
[0m11:14:14  5 of 21 PASS dbt_constraints_primary_key_dim_customers_sk_customer_id .......... [[32mPASS[0m in 0.13s]
[0m11:14:14  6 of 21 START test dbt_constraints_primary_key_dim_date_date_id ................ [RUN]
[0m11:14:14  6 of 21 PASS dbt_constraints_primary_key_dim_date_date_id ...................... [[32mPASS[0m in 0.22s]
[0m11:14:14  7 of 21 START test dbt_constraints_primary_key_fct_orders_sk_order_id .......... [RUN]
[0m11:14:14  7 of 21 PASS dbt_constraints_primary_key_fct_orders_sk_order_id ................ [[32mPASS[0m in 0.19s]
[0m11:14:14  8 of 21 START test not_null_dim_books_nk_book_id ............................... [RUN]
[0m11:14:14  8 of 21 PASS not_null_dim_books_nk_book_id ..................................... [[32mPASS[0m in 0.07s]
[0m11:14:14  9 of 21 START test not_null_dim_books_sk_book_id ............................... [RUN]
[0m11:14:14  9 of 21 PASS not_null_dim_books_sk_book_id ..................................... [[32mPASS[0m in 0.06s]
[0m11:14:14  10 of 21 START test not_null_dim_customers_nk_customer_id ...................... [RUN]
[0m11:14:14  10 of 21 PASS not_null_dim_customers_nk_customer_id ............................ [[32mPASS[0m in 0.09s]
[0m11:14:14  11 of 21 START test not_null_dim_customers_sk_customer_id ...................... [RUN]
[0m11:14:15  11 of 21 PASS not_null_dim_customers_sk_customer_id ............................ [[32mPASS[0m in 0.13s]
[0m11:14:15  12 of 21 START test not_null_dim_date_date_id .................................. [RUN]
[0m11:14:15  12 of 21 PASS not_null_dim_date_date_id ........................................ [[32mPASS[0m in 0.15s]
[0m11:14:15  13 of 21 START test not_null_fct_book_sales_dd_order_id ........................ [RUN]
[0m11:14:15  13 of 21 PASS not_null_fct_book_sales_dd_order_id .............................. [[32mPASS[0m in 0.16s]
[0m11:14:15  14 of 21 START test not_null_fct_book_sales_nk_book_id ......................... [RUN]
[0m11:14:15  14 of 21 PASS not_null_fct_book_sales_nk_book_id ............................... [[32mPASS[0m in 0.17s]
[0m11:14:15  15 of 21 START test not_null_fct_book_sales_order_date ......................... [RUN]
[0m11:14:15  15 of 21 PASS not_null_fct_book_sales_order_date ............................... [[32mPASS[0m in 0.16s]
[0m11:14:15  16 of 21 START test not_null_fct_orders_dd_order_id ............................ [RUN]
[0m11:14:15  16 of 21 PASS not_null_fct_orders_dd_order_id .................................. [[32mPASS[0m in 0.15s]
[0m11:14:15  17 of 21 START test not_null_fct_orders_nk_customer_id ......................... [RUN]
[0m11:14:16  17 of 21 PASS not_null_fct_orders_nk_customer_id ............................... [[32mPASS[0m in 0.15s]
[0m11:14:16  18 of 21 START test not_null_fct_orders_sk_order_id ............................ [RUN]
[0m11:14:16  18 of 21 PASS not_null_fct_orders_sk_order_id .................................. [[32mPASS[0m in 0.15s]
[0m11:14:16  19 of 21 START test unique_dim_books_sk_book_id ................................ [RUN]
[0m11:14:16  19 of 21 PASS unique_dim_books_sk_book_id ...................................... [[32mPASS[0m in 0.16s]
[0m11:14:16  20 of 21 START test unique_dim_customers_sk_customer_id ........................ [RUN]
[0m11:14:16  20 of 21 PASS unique_dim_customers_sk_customer_id .............................. [[32mPASS[0m in 0.15s]
[0m11:14:16  21 of 21 START test unique_fct_orders_sk_order_id .............................. [RUN]
[0m11:14:16  21 of 21 PASS unique_fct_orders_sk_order_id .................................... [[32mPASS[0m in 0.17s]
[0m11:14:16  
[0m11:14:16  Running dbt Constraints
[0m11:14:17  Creating not null constraint for: nk_book_id in "pacbook-dwh"."final"."dim_books"
[0m11:14:17  Creating not null constraint for: sk_book_id in "pacbook-dwh"."final"."dim_books"
[0m11:14:17  Creating not null constraint for: nk_customer_id in "pacbook-dwh"."final"."dim_customers"
[0m11:14:17  Creating not null constraint for: sk_customer_id in "pacbook-dwh"."final"."dim_customers"
[0m11:14:17  Creating not null constraint for: date_id in "pacbook-dwh"."final"."dim_date"
[0m11:14:17  Creating not null constraint for: dd_order_id in "pacbook-dwh"."final"."fct_book_sales"
[0m11:14:17  Creating not null constraint for: nk_book_id in "pacbook-dwh"."final"."fct_book_sales"
[0m11:14:17  Creating not null constraint for: order_date in "pacbook-dwh"."final"."fct_book_sales"
[0m11:14:18  Creating not null constraint for: dd_order_id in "pacbook-dwh"."final"."fct_orders"
[0m11:14:18  Creating not null constraint for: nk_customer_id in "pacbook-dwh"."final"."fct_orders"
[0m11:14:18  Creating not null constraint for: sk_order_id in "pacbook-dwh"."final"."fct_orders"
[0m11:14:18  Creating not null constraint for: sk_book_id in "pacbook-dwh"."final"."dim_books"
[0m11:14:18  Creating primary key: DIM_BOOKS_SK_BOOK_ID_PK
[0m11:14:18  Creating not null constraint for: sk_customer_id in "pacbook-dwh"."final"."dim_customers"
[0m11:14:18  Creating primary key: DIM_CUSTOMERS_SK_CUSTOMER_ID_PK
[0m11:14:18  Creating not null constraint for: date_id in "pacbook-dwh"."final"."dim_date"
[0m11:14:18  Creating primary key: DIM_DATE_DATE_ID_PK
[0m11:14:18  Creating not null constraint for: sk_order_id in "pacbook-dwh"."final"."fct_orders"
[0m11:14:18  Creating primary key: FCT_ORDERS_SK_ORDER_ID_PK
[0m11:14:19  Skipping FCT_BOOK_SALES_NK_BOOK_ID_FK because a PK/UK was not found on the PK table: "pacbook-dwh"."final"."dim_books" ['nk_book_id']
[0m11:14:19  Skipping FCT_BOOK_SALES_ORDER_DATE_FK because a PK/UK was not found on the PK table: "pacbook-dwh"."final"."dim_date" ['date_actual']
[0m11:14:19  Skipping FCT_ORDERS_NK_CUSTOMER_ID_FK because a PK/UK was not found on the PK table: "pacbook-dwh"."final"."dim_customers" ['nk_customer_id']
[0m11:14:19  Finished dbt Constraints
[0m11:14:19  1 of 1 START hook: dbt_constraints.on-run-end.0 ................................ [RUN]
[0m11:14:19  1 of 1 OK hook: dbt_constraints.on-run-end.0 ................................... [[32mOK[0m in 2.24s]
[0m11:14:19  
[0m11:14:19  Finished running 1 project hook, 21 data tests in 0 hours 0 minutes and 6.31 seconds (6.31s).
[0m11:14:19  
[0m11:14:19  [32mCompleted successfully[0m
[0m11:14:19  
[0m11:14:19  Done. PASS=22 WARN=0 ERROR=0 SKIP=0 TOTAL=22
2024-11-19 18:14:21,680 - INFO - Transform to All Dimensions and Fact Tables - SUCCESS!
2024-11-19 18:14:21,685 - INFO - ==================================ENDING TRANSFROM DATA=======================================
2024-11-19 18:14:21,688 - INFO - [pid 78821] Worker Worker(salt=2714040240, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=78821) done      Transform()
2024-11-19 18:14:21,697 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-19 18:14:21,737 - INFO - Informed scheduler that task   Transform__99914b932b   has status   DONE
2024-11-19 18:14:21,741 - DEBUG - Asking scheduler for work...
2024-11-19 18:14:21,758 - DEBUG - Done
2024-11-19 18:14:21,760 - DEBUG - There are no more tasks to run at this time
2024-11-19 18:14:21,763 - INFO - Worker Worker(salt=2714040240, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=78821) was stopped. Shutting down Keep-Alive thread
2024-11-19 18:14:21,800 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 3 ran successfully:
    - 1 Extract()
    - 1 Load()
    - 1 Transform()

This progress looks :) because there were no failed tasks or missing dependencies

===== Luigi Execution Summary =====

2024-11-19 18:34:30,238 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-19 18:34:30,434 - INFO - EXTRACT 'public.address' - SUCCESS.
2024-11-19 18:34:30,451 - INFO - EXTRACT 'public.address_status' - SUCCESS.
2024-11-19 18:34:30,560 - INFO - EXTRACT 'public.author' - SUCCESS.
2024-11-19 18:34:30,888 - INFO - EXTRACT 'public.book' - SUCCESS.
2024-11-19 18:34:31,075 - INFO - EXTRACT 'public.book_author' - SUCCESS.
2024-11-19 18:34:31,089 - INFO - EXTRACT 'public.book_language' - SUCCESS.
2024-11-19 18:34:31,103 - INFO - EXTRACT 'public.country' - SUCCESS.
2024-11-19 18:34:31,238 - INFO - EXTRACT 'public.cust_order' - SUCCESS.
2024-11-19 18:34:31,266 - INFO - EXTRACT 'public.customer' - SUCCESS.
2024-11-19 18:34:31,300 - INFO - EXTRACT 'public.customer_address' - SUCCESS.
2024-11-19 18:34:31,665 - INFO - EXTRACT 'public.order_history' - SUCCESS.
2024-11-19 18:34:31,918 - INFO - EXTRACT 'public.order_line' - SUCCESS.
2024-11-19 18:34:31,934 - INFO - EXTRACT 'public.order_status' - SUCCESS.
2024-11-19 18:34:31,968 - INFO - EXTRACT 'public.publisher' - SUCCESS.
2024-11-19 18:34:31,985 - INFO - EXTRACT 'public.shipping_method' - SUCCESS.
2024-11-19 18:34:31,985 - INFO - EXTRACT ALL TABLE FROM SOURCE DATABASE - SUCCESS!
2024-11-19 18:34:31,990 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-19 18:34:31,991 - INFO - [pid 91525] Worker Worker(salt=898720430, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=91525) done      Extract()
2024-11-19 18:34:31,997 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-19 18:34:32,010 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-19 18:34:32,011 - DEBUG - Asking scheduler for work...
2024-11-19 18:34:32,022 - DEBUG - Pending tasks: 2
2024-11-19 18:34:32,024 - INFO - [pid 91525] Worker Worker(salt=898720430, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=91525) running   Load()
2024-11-19 18:34:32,345 - INFO - Read Extracted Data - SUCCESS!
2024-11-19 18:34:32,348 - INFO - Connect to DWH - SUCCESS!
2024-11-19 18:34:32,985 - INFO - Truncate Staging Schema in DWH - SUCCESS!
2024-11-19 18:34:32,985 - INFO - ==================================STARTING LOAD DATA=======================================
2024-11-19 18:34:33,039 - INFO - Load country table - SUCCESS!
2024-11-19 18:34:33,171 - INFO - Load address table - SUCCESS!
2024-11-19 18:34:33,186 - INFO - Load address_status table - SUCCESS!
2024-11-19 18:34:33,203 - INFO - Load book_language table - SUCCESS!
2024-11-19 18:34:33,376 - INFO - Load customer table - SUCCESS!
2024-11-19 18:34:33,583 - INFO - Load publisher table - SUCCESS!
2024-11-19 18:34:33,619 - INFO - Load shipping_method table - SUCCESS!
2024-11-19 18:34:34,128 - INFO - Load author table - SUCCESS!
2024-11-19 18:34:35,775 - INFO - Load book table - SUCCESS!
2024-11-19 18:34:36,629 - INFO - Load cust_order table - SUCCESS!
2024-11-19 18:34:37,001 - INFO - Load customer_address table - SUCCESS!
2024-11-19 18:34:37,020 - INFO - Load order_status table - SUCCESS!
2024-11-19 18:34:38,328 - INFO - Load book_author table - SUCCESS!
2024-11-19 18:34:40,863 - INFO - Load order_history table - SUCCESS!
2024-11-19 18:34:42,443 - INFO - Load order_line table - SUCCESS!
2024-11-19 18:34:42,444 - INFO - LOAD All Tables To Pacbook DWH Staging Schema - SUCCESS!
2024-11-19 18:34:42,450 - INFO - ==================================ENDING LOAD DATA=======================================
2024-11-19 18:34:42,453 - INFO - [pid 91525] Worker Worker(salt=898720430, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=91525) done      Load()
2024-11-19 18:34:42,454 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-19 18:34:42,464 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-11-19 18:34:42,465 - DEBUG - Asking scheduler for work...
2024-11-19 18:34:42,473 - DEBUG - Pending tasks: 1
2024-11-19 18:34:42,473 - INFO - [pid 91525] Worker Worker(salt=898720430, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=91525) running   Transform()
2024-11-19 18:34:42,475 - INFO - ==================================STARTING TRANSFROM DATA=======================================
[0m11:34:45  Running with dbt=1.9.0-b4
[0m11:34:47  Installing dbt-labs/dbt_utils
[0m11:34:48  Installed from version 1.1.1
[0m11:34:48  Updated version available: 1.3.0
[0m11:34:48  Installing calogica/dbt_date
[0m11:34:50  Installed from version 0.10.0
[0m11:34:50  Updated version available: 0.10.1
[0m11:34:50  Installing Snowflake-Labs/dbt_constraints
[0m11:34:51  Installed from version 0.6.3
[0m11:34:51  Updated version available: 1.0.4
[0m11:34:51  
[0m11:34:51  Updates available for packages: ['dbt-labs/dbt_utils', 'calogica/dbt_date', 'Snowflake-Labs/dbt_constraints']                 
Update your versions in packages.yml, then run dbt deps
[0m11:34:56  Running with dbt=1.9.0-b4
[0m11:34:56  Registered adapter: postgres=1.8.2
[0m11:34:58  Found 19 models, 1 seed, 1 operation, 21 data tests, 2 snapshots, 15 sources, 751 macros
[0m11:34:58  
[0m11:34:58  Concurrency: 1 threads (target='dev')
[0m11:34:58  
[0m11:34:59  1 of 1 START seed file final.dim_date .......................................... [RUN]
[0m11:39:42  1 of 1 OK loaded seed file final.dim_date ...................................... [[32mINSERT 29220[0m in 283.76s]
[0m11:39:42  
[0m11:39:43  Running dbt Constraints
[0m11:39:43  Finished dbt Constraints
[0m11:39:43  1 of 1 START hook: dbt_constraints.on-run-end.0 ................................ [RUN]
[0m11:39:43  1 of 1 OK hook: dbt_constraints.on-run-end.0 ................................... [[32mOK[0m in 0.10s]
[0m11:39:43  
[0m11:39:43  Finished running 1 project hook, 1 seed in 0 hours 4 minutes and 44.52 seconds (284.52s).
[0m11:39:43  
[0m11:39:43  [32mCompleted successfully[0m
[0m11:39:43  
[0m11:39:43  Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m11:39:47  Running with dbt=1.9.0-b4
[0m11:39:48  Registered adapter: postgres=1.8.2
[0m11:39:49  Found 19 models, 1 seed, 1 operation, 21 data tests, 2 snapshots, 15 sources, 751 macros
[0m11:39:49  
[0m11:39:49  Concurrency: 1 threads (target='dev')
[0m11:39:49  
[0m11:39:49  1 of 19 START sql view model final.stg_pacbook__address ........................ [RUN]
[0m11:39:50  1 of 19 OK created sql view model final.stg_pacbook__address ................... [[32mCREATE VIEW[0m in 0.37s]
[0m11:39:50  2 of 19 START sql view model final.stg_pacbook__address_status ................. [RUN]
[0m11:39:50  2 of 19 OK created sql view model final.stg_pacbook__address_status ............ [[32mCREATE VIEW[0m in 0.18s]
[0m11:39:50  3 of 19 START sql view model final.stg_pacbook__author ......................... [RUN]
[0m11:39:50  3 of 19 OK created sql view model final.stg_pacbook__author .................... [[32mCREATE VIEW[0m in 0.24s]
[0m11:39:50  4 of 19 START sql view model final.stg_pacbook__book ........................... [RUN]
[0m11:39:50  4 of 19 OK created sql view model final.stg_pacbook__book ...................... [[32mCREATE VIEW[0m in 0.20s]
[0m11:39:50  5 of 19 START sql view model final.stg_pacbook__book_author .................... [RUN]
[0m11:39:51  5 of 19 OK created sql view model final.stg_pacbook__book_author ............... [[32mCREATE VIEW[0m in 0.21s]
[0m11:39:51  6 of 19 START sql view model final.stg_pacbook__book_language .................. [RUN]
[0m11:39:51  6 of 19 OK created sql view model final.stg_pacbook__book_language ............. [[32mCREATE VIEW[0m in 0.22s]
[0m11:39:51  7 of 19 START sql view model final.stg_pacbook__country ........................ [RUN]
[0m11:39:51  7 of 19 OK created sql view model final.stg_pacbook__country ................... [[32mCREATE VIEW[0m in 0.20s]
[0m11:39:51  8 of 19 START sql view model final.stg_pacbook__cust_order ..................... [RUN]
[0m11:39:51  8 of 19 OK created sql view model final.stg_pacbook__cust_order ................ [[32mCREATE VIEW[0m in 0.21s]
[0m11:39:51  9 of 19 START sql view model final.stg_pacbook__customer ....................... [RUN]
[0m11:39:52  9 of 19 OK created sql view model final.stg_pacbook__customer .................. [[32mCREATE VIEW[0m in 0.20s]
[0m11:39:52  10 of 19 START sql view model final.stg_pacbook__customer_address .............. [RUN]
[0m11:39:52  10 of 19 OK created sql view model final.stg_pacbook__customer_address ......... [[32mCREATE VIEW[0m in 0.21s]
[0m11:39:52  11 of 19 START sql view model final.stg_pacbook__order_history ................. [RUN]
[0m11:39:52  11 of 19 OK created sql view model final.stg_pacbook__order_history ............ [[32mCREATE VIEW[0m in 0.31s]
[0m11:39:52  12 of 19 START sql view model final.stg_pacbook__order_line .................... [RUN]
[0m11:39:52  12 of 19 OK created sql view model final.stg_pacbook__order_line ............... [[32mCREATE VIEW[0m in 0.20s]
[0m11:39:52  13 of 19 START sql view model final.stg_pacbook__order_status .................. [RUN]
[0m11:39:53  13 of 19 OK created sql view model final.stg_pacbook__order_status ............. [[32mCREATE VIEW[0m in 0.22s]
[0m11:39:53  14 of 19 START sql view model final.stg_pacbook__publisher ..................... [RUN]
[0m11:39:53  14 of 19 OK created sql view model final.stg_pacbook__publisher ................ [[32mCREATE VIEW[0m in 0.21s]
[0m11:39:53  15 of 19 START sql view model final.stg_pacbook__shipping_method ............... [RUN]
[0m11:39:53  15 of 19 OK created sql view model final.stg_pacbook__shipping_method .......... [[32mCREATE VIEW[0m in 0.19s]
[0m11:39:53  16 of 19 START sql table model final.dim_customers ............................. [RUN]
[0m11:39:53  16 of 19 OK created sql table model final.dim_customers ........................ [[32mSELECT 3350[0m in 0.53s]
[0m11:39:53  17 of 19 START sql table model final.dim_books ................................. [RUN]
[0m11:39:54  17 of 19 OK created sql table model final.dim_books ............................ [[32mSELECT 11128[0m in 0.54s]
[0m11:39:54  18 of 19 START sql table model final.fct_book_sales ............................ [RUN]
[0m11:39:54  18 of 19 OK created sql table model final.fct_book_sales ....................... [[32mSELECT 15399[0m in 0.44s]
[0m11:39:55  19 of 19 START sql table model final.fct_orders ................................ [RUN]
[0m11:39:55  19 of 19 OK created sql table model final.fct_orders ........................... [[32mSELECT 7550[0m in 0.52s]
[0m11:39:55  
[0m11:39:55  Running dbt Constraints
[0m11:39:55  Finished dbt Constraints
[0m11:39:55  1 of 1 START hook: dbt_constraints.on-run-end.0 ................................ [RUN]
[0m11:39:55  1 of 1 OK hook: dbt_constraints.on-run-end.0 ................................... [[32mOK[0m in 0.13s]
[0m11:39:55  
[0m11:39:55  Finished running 1 project hook, 4 table models, 15 view models in 0 hours 0 minutes and 6.39 seconds (6.39s).
[0m11:39:55  
[0m11:39:55  [32mCompleted successfully[0m
[0m11:39:55  
[0m11:39:55  Done. PASS=20 WARN=0 ERROR=0 SKIP=0 TOTAL=20
[0m11:40:00  Running with dbt=1.9.0-b4
[0m11:40:01  Registered adapter: postgres=1.8.2
[0m11:40:02  Found 19 models, 1 seed, 1 operation, 21 data tests, 2 snapshots, 15 sources, 751 macros
[0m11:40:02  
[0m11:40:02  Concurrency: 1 threads (target='dev')
[0m11:40:02  
[0m11:40:02  1 of 2 START snapshot snapshots.dim_books_snapshot ............................. [RUN]
[0m11:40:03  1 of 2 OK snapshotted snapshots.dim_books_snapshot ............................. [[32mINSERT 0 1[0m in 0.90s]
[0m11:40:03  2 of 2 START snapshot snapshots.dim_customers_snapshot ......................... [RUN]
[0m11:40:04  2 of 2 OK snapshotted snapshots.dim_customers_snapshot ......................... [[32mINSERT 0 0[0m in 0.49s]
[0m11:40:04  
[0m11:40:04  Running dbt Constraints
[0m11:40:04  Finished dbt Constraints
[0m11:40:04  1 of 1 START hook: dbt_constraints.on-run-end.0 ................................ [RUN]
[0m11:40:04  1 of 1 OK hook: dbt_constraints.on-run-end.0 ................................... [[32mOK[0m in 0.19s]
[0m11:40:04  
[0m11:40:04  Finished running 1 project hook, 2 snapshots in 0 hours 0 minutes and 2.15 seconds (2.15s).
[0m11:40:04  
[0m11:40:04  [32mCompleted successfully[0m
[0m11:40:04  
[0m11:40:04  Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m11:40:09  Running with dbt=1.9.0-b4
[0m11:40:09  Registered adapter: postgres=1.8.2
[0m11:40:10  Found 19 models, 1 seed, 1 operation, 21 data tests, 2 snapshots, 15 sources, 751 macros
[0m11:40:10  
[0m11:40:10  Concurrency: 1 threads (target='dev')
[0m11:40:10  
[0m11:40:11  1 of 21 START test dbt_constraints_foreign_key_fct_book_sales_nk_book_id__nk_book_id__ref_dim_books_  [RUN]
[0m11:40:11  1 of 21 PASS dbt_constraints_foreign_key_fct_book_sales_nk_book_id__nk_book_id__ref_dim_books_  [[32mPASS[0m in 0.14s]
[0m11:40:11  2 of 21 START test dbt_constraints_foreign_key_fct_book_sales_order_date__date_actual__ref_dim_date_  [RUN]
[0m11:40:11  2 of 21 PASS dbt_constraints_foreign_key_fct_book_sales_order_date__date_actual__ref_dim_date_  [[32mPASS[0m in 0.06s]
[0m11:40:11  3 of 21 START test dbt_constraints_foreign_key_fct_orders_nk_customer_id__nk_customer_id__ref_dim_customers_  [RUN]
[0m11:40:11  3 of 21 PASS dbt_constraints_foreign_key_fct_orders_nk_customer_id__nk_customer_id__ref_dim_customers_  [[32mPASS[0m in 0.06s]
[0m11:40:11  4 of 21 START test dbt_constraints_primary_key_dim_books_sk_book_id ............ [RUN]
[0m11:40:11  4 of 21 PASS dbt_constraints_primary_key_dim_books_sk_book_id .................. [[32mPASS[0m in 0.09s]
[0m11:40:11  5 of 21 START test dbt_constraints_primary_key_dim_customers_sk_customer_id .... [RUN]
[0m11:40:11  5 of 21 PASS dbt_constraints_primary_key_dim_customers_sk_customer_id .......... [[32mPASS[0m in 0.07s]
[0m11:40:11  6 of 21 START test dbt_constraints_primary_key_dim_date_date_id ................ [RUN]
[0m11:40:11  6 of 21 PASS dbt_constraints_primary_key_dim_date_date_id ...................... [[32mPASS[0m in 0.14s]
[0m11:40:11  7 of 21 START test dbt_constraints_primary_key_fct_orders_sk_order_id .......... [RUN]
[0m11:40:11  7 of 21 PASS dbt_constraints_primary_key_fct_orders_sk_order_id ................ [[32mPASS[0m in 0.12s]
[0m11:40:11  8 of 21 START test not_null_dim_books_nk_book_id ............................... [RUN]
[0m11:40:11  8 of 21 PASS not_null_dim_books_nk_book_id ..................................... [[32mPASS[0m in 0.07s]
[0m11:40:11  9 of 21 START test not_null_dim_books_sk_book_id ............................... [RUN]
[0m11:40:11  9 of 21 PASS not_null_dim_books_sk_book_id ..................................... [[32mPASS[0m in 0.06s]
[0m11:40:11  10 of 21 START test not_null_dim_customers_nk_customer_id ...................... [RUN]
[0m11:40:12  10 of 21 PASS not_null_dim_customers_nk_customer_id ............................ [[32mPASS[0m in 0.07s]
[0m11:40:12  11 of 21 START test not_null_dim_customers_sk_customer_id ...................... [RUN]
[0m11:40:12  11 of 21 PASS not_null_dim_customers_sk_customer_id ............................ [[32mPASS[0m in 0.07s]
[0m11:40:12  12 of 21 START test not_null_dim_date_date_id .................................. [RUN]
[0m11:40:12  12 of 21 PASS not_null_dim_date_date_id ........................................ [[32mPASS[0m in 0.07s]
[0m11:40:12  13 of 21 START test not_null_fct_book_sales_dd_order_id ........................ [RUN]
[0m11:40:12  13 of 21 PASS not_null_fct_book_sales_dd_order_id .............................. [[32mPASS[0m in 0.09s]
[0m11:40:12  14 of 21 START test not_null_fct_book_sales_nk_book_id ......................... [RUN]
[0m11:40:12  14 of 21 PASS not_null_fct_book_sales_nk_book_id ............................... [[32mPASS[0m in 0.10s]
[0m11:40:12  15 of 21 START test not_null_fct_book_sales_order_date ......................... [RUN]
[0m11:40:12  15 of 21 PASS not_null_fct_book_sales_order_date ............................... [[32mPASS[0m in 0.09s]
[0m11:40:12  16 of 21 START test not_null_fct_orders_dd_order_id ............................ [RUN]
[0m11:40:12  16 of 21 PASS not_null_fct_orders_dd_order_id .................................. [[32mPASS[0m in 0.09s]
[0m11:40:12  17 of 21 START test not_null_fct_orders_nk_customer_id ......................... [RUN]
[0m11:40:12  17 of 21 PASS not_null_fct_orders_nk_customer_id ............................... [[32mPASS[0m in 0.08s]
[0m11:40:12  18 of 21 START test not_null_fct_orders_sk_order_id ............................ [RUN]
[0m11:40:12  18 of 21 PASS not_null_fct_orders_sk_order_id .................................. [[32mPASS[0m in 0.10s]
[0m11:40:12  19 of 21 START test unique_dim_books_sk_book_id ................................ [RUN]
[0m11:40:12  19 of 21 PASS unique_dim_books_sk_book_id ...................................... [[32mPASS[0m in 0.14s]
[0m11:40:12  20 of 21 START test unique_dim_customers_sk_customer_id ........................ [RUN]
[0m11:40:13  20 of 21 PASS unique_dim_customers_sk_customer_id .............................. [[32mPASS[0m in 0.09s]
[0m11:40:13  21 of 21 START test unique_fct_orders_sk_order_id .............................. [RUN]
[0m11:40:13  21 of 21 PASS unique_fct_orders_sk_order_id .................................... [[32mPASS[0m in 0.07s]
[0m11:40:13  
[0m11:40:13  Running dbt Constraints
[0m11:40:13  Creating not null constraint for: nk_book_id in "pacbook-dwh"."final"."dim_books"
[0m11:40:13  Creating not null constraint for: sk_book_id in "pacbook-dwh"."final"."dim_books"
[0m11:40:13  Creating not null constraint for: nk_customer_id in "pacbook-dwh"."final"."dim_customers"
[0m11:40:13  Creating not null constraint for: sk_customer_id in "pacbook-dwh"."final"."dim_customers"
[0m11:40:13  Creating not null constraint for: date_id in "pacbook-dwh"."final"."dim_date"
[0m11:40:13  Creating not null constraint for: dd_order_id in "pacbook-dwh"."final"."fct_book_sales"
[0m11:40:13  Creating not null constraint for: nk_book_id in "pacbook-dwh"."final"."fct_book_sales"
[0m11:40:13  Creating not null constraint for: order_date in "pacbook-dwh"."final"."fct_book_sales"
[0m11:40:13  Creating not null constraint for: dd_order_id in "pacbook-dwh"."final"."fct_orders"
[0m11:40:13  Creating not null constraint for: nk_customer_id in "pacbook-dwh"."final"."fct_orders"
[0m11:40:13  Creating not null constraint for: sk_order_id in "pacbook-dwh"."final"."fct_orders"
[0m11:40:13  Creating not null constraint for: sk_book_id in "pacbook-dwh"."final"."dim_books"
[0m11:40:13  Creating primary key: DIM_BOOKS_SK_BOOK_ID_PK
[0m11:40:14  Creating not null constraint for: sk_customer_id in "pacbook-dwh"."final"."dim_customers"
[0m11:40:14  Creating primary key: DIM_CUSTOMERS_SK_CUSTOMER_ID_PK
[0m11:40:14  Creating not null constraint for: date_id in "pacbook-dwh"."final"."dim_date"
[0m11:40:14  Creating primary key: DIM_DATE_DATE_ID_PK
[0m11:40:14  Creating not null constraint for: sk_order_id in "pacbook-dwh"."final"."fct_orders"
[0m11:40:14  Creating primary key: FCT_ORDERS_SK_ORDER_ID_PK
[0m11:40:14  Skipping FCT_BOOK_SALES_NK_BOOK_ID_FK because a PK/UK was not found on the PK table: "pacbook-dwh"."final"."dim_books" ['nk_book_id']
[0m11:40:14  Skipping FCT_BOOK_SALES_ORDER_DATE_FK because a PK/UK was not found on the PK table: "pacbook-dwh"."final"."dim_date" ['date_actual']
[0m11:40:14  Skipping FCT_ORDERS_NK_CUSTOMER_ID_FK because a PK/UK was not found on the PK table: "pacbook-dwh"."final"."dim_customers" ['nk_customer_id']
[0m11:40:14  Finished dbt Constraints
[0m11:40:14  1 of 1 START hook: dbt_constraints.on-run-end.0 ................................ [RUN]
[0m11:40:14  1 of 1 OK hook: dbt_constraints.on-run-end.0 ................................... [[32mOK[0m in 1.59s]
[0m11:40:14  
[0m11:40:14  Finished running 1 project hook, 21 data tests in 0 hours 0 minutes and 4.06 seconds (4.06s).
[0m11:40:15  
[0m11:40:15  [32mCompleted successfully[0m
[0m11:40:15  
[0m11:40:15  Done. PASS=22 WARN=0 ERROR=0 SKIP=0 TOTAL=22
2024-11-19 18:40:16,873 - INFO - Transform to All Dimensions and Fact Tables - SUCCESS!
2024-11-19 18:40:16,874 - INFO - ==================================ENDING TRANSFROM DATA=======================================
2024-11-19 18:40:16,874 - INFO - [pid 91525] Worker Worker(salt=898720430, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=91525) done      Transform()
2024-11-19 18:40:16,875 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-19 18:40:16,883 - INFO - Informed scheduler that task   Transform__99914b932b   has status   DONE
2024-11-19 18:40:16,884 - DEBUG - Asking scheduler for work...
2024-11-19 18:40:16,890 - DEBUG - Done
2024-11-19 18:40:16,890 - DEBUG - There are no more tasks to run at this time
2024-11-19 18:40:16,891 - INFO - Worker Worker(salt=898720430, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=91525) was stopped. Shutting down Keep-Alive thread
2024-11-19 18:40:16,894 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 3 ran successfully:
    - 1 Extract()
    - 1 Load()
    - 1 Transform()

This progress looks :) because there were no failed tasks or missing dependencies

===== Luigi Execution Summary =====

2024-11-19 20:00:58,990 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-19 20:00:59,044 - INFO - EXTRACT 'public.address' - SUCCESS.
2024-11-19 20:00:59,053 - INFO - EXTRACT 'public.address_status' - SUCCESS.
2024-11-19 20:00:59,095 - INFO - EXTRACT 'public.author' - SUCCESS.
2024-11-19 20:00:59,189 - INFO - EXTRACT 'public.book' - SUCCESS.
2024-11-19 20:00:59,262 - INFO - EXTRACT 'public.book_author' - SUCCESS.
2024-11-19 20:00:59,268 - INFO - EXTRACT 'public.book_language' - SUCCESS.
2024-11-19 20:00:59,272 - INFO - EXTRACT 'public.country' - SUCCESS.
2024-11-19 20:00:59,319 - INFO - EXTRACT 'public.cust_order' - SUCCESS.
2024-11-19 20:00:59,331 - INFO - EXTRACT 'public.customer' - SUCCESS.
2024-11-19 20:00:59,345 - INFO - EXTRACT 'public.customer_address' - SUCCESS.
2024-11-19 20:00:59,462 - INFO - EXTRACT 'public.order_history' - SUCCESS.
2024-11-19 20:00:59,555 - INFO - EXTRACT 'public.order_line' - SUCCESS.
2024-11-19 20:00:59,560 - INFO - EXTRACT 'public.order_status' - SUCCESS.
2024-11-19 20:00:59,570 - INFO - EXTRACT 'public.publisher' - SUCCESS.
2024-11-19 20:00:59,575 - INFO - EXTRACT 'public.shipping_method' - SUCCESS.
2024-11-19 20:00:59,575 - INFO - EXTRACT ALL TABLE FROM SOURCE DATABASE - SUCCESS!
2024-11-19 20:00:59,576 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-19 20:00:59,576 - INFO - [pid 123741] Worker Worker(salt=6470965867, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=123741) done      Extract()
2024-11-19 20:00:59,578 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-19 20:00:59,582 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-19 20:00:59,582 - DEBUG - Asking scheduler for work...
2024-11-19 20:00:59,586 - DEBUG - Pending tasks: 2
2024-11-19 20:00:59,586 - INFO - [pid 123741] Worker Worker(salt=6470965867, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=123741) running   Load()
2024-11-19 20:00:59,666 - INFO - Read Extracted Data - SUCCESS!
2024-11-19 20:00:59,667 - INFO - Connect to DWH - SUCCESS!
2024-11-19 20:00:59,931 - INFO - Truncate Staging Schema in DWH - SUCCESS!
2024-11-19 20:00:59,931 - INFO - ==================================STARTING LOAD DATA=======================================
2024-11-19 20:00:59,950 - INFO - Load country table - SUCCESS!
2024-11-19 20:01:00,026 - INFO - Load address table - SUCCESS!
2024-11-19 20:01:00,034 - INFO - Load address_status table - SUCCESS!
2024-11-19 20:01:00,042 - INFO - Load book_language table - SUCCESS!
2024-11-19 20:01:00,100 - INFO - Load customer table - SUCCESS!
2024-11-19 20:01:00,148 - INFO - Load publisher table - SUCCESS!
2024-11-19 20:01:00,159 - INFO - Load shipping_method table - SUCCESS!
2024-11-19 20:01:00,320 - INFO - Load author table - SUCCESS!
2024-11-19 20:01:00,848 - INFO - Load book table - SUCCESS!
2024-11-19 20:01:01,184 - INFO - Load cust_order table - SUCCESS!
2024-11-19 20:01:01,300 - INFO - Load customer_address table - SUCCESS!
2024-11-19 20:01:01,309 - INFO - Load order_status table - SUCCESS!
2024-11-19 20:01:01,848 - INFO - Load book_author table - SUCCESS!
2024-11-19 20:01:02,506 - INFO - Load order_history table - SUCCESS!
2024-11-19 20:01:02,971 - INFO - Load order_line table - SUCCESS!
2024-11-19 20:01:02,971 - INFO - LOAD All Tables To Pacbook DWH Staging Schema - SUCCESS!
2024-11-19 20:01:02,972 - INFO - ==================================ENDING LOAD DATA=======================================
2024-11-19 20:01:02,974 - INFO - [pid 123741] Worker Worker(salt=6470965867, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=123741) done      Load()
2024-11-19 20:01:02,974 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-19 20:01:02,977 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-11-19 20:01:02,977 - DEBUG - Asking scheduler for work...
2024-11-19 20:01:02,979 - DEBUG - Pending tasks: 1
2024-11-19 20:01:02,979 - INFO - [pid 123741] Worker Worker(salt=6470965867, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=123741) running   Transform()
2024-11-19 20:01:02,979 - INFO - ==================================STARTING TRANSFROM DATA=======================================
[0m13:01:04  Running with dbt=1.9.0-b4
[0m13:01:06  Installing dbt-labs/dbt_utils
[0m13:01:06  Installed from version 1.1.1
[0m13:01:06  Updated version available: 1.3.0
[0m13:01:06  Installing calogica/dbt_date
[0m13:01:07  Installed from version 0.10.0
[0m13:01:07  Updated version available: 0.10.1
[0m13:01:07  Installing Snowflake-Labs/dbt_constraints
[0m13:01:07  Installed from version 0.6.3
[0m13:01:07  Updated version available: 1.0.4
[0m13:01:07  
[0m13:01:07  Updates available for packages: ['dbt-labs/dbt_utils', 'calogica/dbt_date', 'Snowflake-Labs/dbt_constraints']                 
Update your versions in packages.yml, then run dbt deps
[0m13:01:10  Running with dbt=1.9.0-b4
[0m13:01:10  Registered adapter: postgres=1.8.2
[0m13:01:11  Found 19 models, 1 seed, 1 operation, 21 data tests, 2 snapshots, 15 sources, 751 macros
[0m13:01:11  
[0m13:01:11  Concurrency: 1 threads (target='dev')
[0m13:01:11  
[0m13:01:11  1 of 1 START seed file final.dim_date .......................................... [RUN]
[0m13:03:23  1 of 1 OK loaded seed file final.dim_date ...................................... [[32mINSERT 29220[0m in 132.34s]
[0m13:03:23  
[0m13:03:23  Running dbt Constraints
[0m13:03:23  Finished dbt Constraints
[0m13:03:23  1 of 1 START hook: dbt_constraints.on-run-end.0 ................................ [RUN]
[0m13:03:23  1 of 1 OK hook: dbt_constraints.on-run-end.0 ................................... [[32mOK[0m in 0.06s]
[0m13:03:23  
[0m13:03:23  Finished running 1 project hook, 1 seed in 0 hours 2 minutes and 12.62 seconds (132.62s).
[0m13:03:23  
[0m13:03:23  [32mCompleted successfully[0m
[0m13:03:23  
[0m13:03:23  Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m13:03:26  Running with dbt=1.9.0-b4
[0m13:03:26  Registered adapter: postgres=1.8.2
[0m13:03:27  Found 19 models, 1 seed, 1 operation, 21 data tests, 2 snapshots, 15 sources, 751 macros
[0m13:03:27  
[0m13:03:27  Concurrency: 1 threads (target='dev')
[0m13:03:27  
[0m13:03:27  1 of 19 START sql view model final.stg_pacbook__address ........................ [RUN]
[0m13:03:27  1 of 19 OK created sql view model final.stg_pacbook__address ................... [[32mCREATE VIEW[0m in 0.11s]
[0m13:03:27  2 of 19 START sql view model final.stg_pacbook__address_status ................. [RUN]
[0m13:03:27  2 of 19 OK created sql view model final.stg_pacbook__address_status ............ [[32mCREATE VIEW[0m in 0.05s]
[0m13:03:27  3 of 19 START sql view model final.stg_pacbook__author ......................... [RUN]
[0m13:03:27  3 of 19 OK created sql view model final.stg_pacbook__author .................... [[32mCREATE VIEW[0m in 0.05s]
[0m13:03:27  4 of 19 START sql view model final.stg_pacbook__book ........................... [RUN]
[0m13:03:27  4 of 19 OK created sql view model final.stg_pacbook__book ...................... [[32mCREATE VIEW[0m in 0.05s]
[0m13:03:27  5 of 19 START sql view model final.stg_pacbook__book_author .................... [RUN]
[0m13:03:27  5 of 19 OK created sql view model final.stg_pacbook__book_author ............... [[32mCREATE VIEW[0m in 0.05s]
[0m13:03:27  6 of 19 START sql view model final.stg_pacbook__book_language .................. [RUN]
[0m13:03:27  6 of 19 OK created sql view model final.stg_pacbook__book_language ............. [[32mCREATE VIEW[0m in 0.05s]
[0m13:03:27  7 of 19 START sql view model final.stg_pacbook__country ........................ [RUN]
[0m13:03:27  7 of 19 OK created sql view model final.stg_pacbook__country ................... [[32mCREATE VIEW[0m in 0.05s]
[0m13:03:27  8 of 19 START sql view model final.stg_pacbook__cust_order ..................... [RUN]
[0m13:03:27  8 of 19 OK created sql view model final.stg_pacbook__cust_order ................ [[32mCREATE VIEW[0m in 0.06s]
[0m13:03:27  9 of 19 START sql view model final.stg_pacbook__customer ....................... [RUN]
[0m13:03:27  9 of 19 OK created sql view model final.stg_pacbook__customer .................. [[32mCREATE VIEW[0m in 0.05s]
[0m13:03:27  10 of 19 START sql view model final.stg_pacbook__customer_address .............. [RUN]
[0m13:03:27  10 of 19 OK created sql view model final.stg_pacbook__customer_address ......... [[32mCREATE VIEW[0m in 0.05s]
[0m13:03:27  11 of 19 START sql view model final.stg_pacbook__order_history ................. [RUN]
[0m13:03:28  11 of 19 OK created sql view model final.stg_pacbook__order_history ............ [[32mCREATE VIEW[0m in 0.05s]
[0m13:03:28  12 of 19 START sql view model final.stg_pacbook__order_line .................... [RUN]
[0m13:03:28  12 of 19 OK created sql view model final.stg_pacbook__order_line ............... [[32mCREATE VIEW[0m in 0.05s]
[0m13:03:28  13 of 19 START sql view model final.stg_pacbook__order_status .................. [RUN]
[0m13:03:28  13 of 19 OK created sql view model final.stg_pacbook__order_status ............. [[32mCREATE VIEW[0m in 0.05s]
[0m13:03:28  14 of 19 START sql view model final.stg_pacbook__publisher ..................... [RUN]
[0m13:03:28  14 of 19 OK created sql view model final.stg_pacbook__publisher ................ [[32mCREATE VIEW[0m in 0.10s]
[0m13:03:28  15 of 19 START sql view model final.stg_pacbook__shipping_method ............... [RUN]
[0m13:03:28  15 of 19 OK created sql view model final.stg_pacbook__shipping_method .......... [[32mCREATE VIEW[0m in 0.05s]
[0m13:03:28  16 of 19 START sql table model final.dim_customers ............................. [RUN]
[0m13:03:28  16 of 19 OK created sql table model final.dim_customers ........................ [[32mSELECT 3350[0m in 0.15s]
[0m13:03:28  17 of 19 START sql table model final.dim_books ................................. [RUN]
[0m13:03:28  17 of 19 OK created sql table model final.dim_books ............................ [[32mSELECT 11127[0m in 0.19s]
[0m13:03:28  18 of 19 START sql table model final.fct_book_sales ............................ [RUN]
[0m13:03:29  18 of 19 OK created sql table model final.fct_book_sales ....................... [[32mSELECT 15399[0m in 0.63s]
[0m13:03:29  19 of 19 START sql table model final.fct_orders ................................ [RUN]
[0m13:03:30  19 of 19 OK created sql table model final.fct_orders ........................... [[32mSELECT 7550[0m in 0.87s]
[0m13:03:30  
[0m13:03:30  Running dbt Constraints
[0m13:03:30  Finished dbt Constraints
[0m13:03:30  1 of 1 START hook: dbt_constraints.on-run-end.0 ................................ [RUN]
[0m13:03:30  1 of 1 OK hook: dbt_constraints.on-run-end.0 ................................... [[32mOK[0m in 0.06s]
[0m13:03:30  
[0m13:03:30  Finished running 1 project hook, 4 table models, 15 view models in 0 hours 0 minutes and 3.07 seconds (3.07s).
[0m13:03:30  
[0m13:03:30  [32mCompleted successfully[0m
[0m13:03:30  
[0m13:03:30  Done. PASS=20 WARN=0 ERROR=0 SKIP=0 TOTAL=20
[0m13:03:33  Running with dbt=1.9.0-b4
[0m13:03:33  Registered adapter: postgres=1.8.2
[0m13:03:33  Found 19 models, 1 seed, 1 operation, 21 data tests, 2 snapshots, 15 sources, 751 macros
[0m13:03:33  
[0m13:03:33  Concurrency: 1 threads (target='dev')
[0m13:03:33  
[0m13:03:33  1 of 2 START snapshot snapshots.dim_books_snapshot ............................. [RUN]
[0m13:03:34  1 of 2 OK snapshotted snapshots.dim_books_snapshot ............................. [[32mSELECT 11127[0m in 0.22s]
[0m13:03:34  2 of 2 START snapshot snapshots.dim_customers_snapshot ......................... [RUN]
[0m13:03:34  2 of 2 OK snapshotted snapshots.dim_customers_snapshot ......................... [[32mSELECT 3350[0m in 0.06s]
[0m13:03:34  
[0m13:03:34  Running dbt Constraints
[0m13:03:34  Finished dbt Constraints
[0m13:03:34  1 of 1 START hook: dbt_constraints.on-run-end.0 ................................ [RUN]
[0m13:03:34  1 of 1 OK hook: dbt_constraints.on-run-end.0 ................................... [[32mOK[0m in 0.05s]
[0m13:03:34  
[0m13:03:34  Finished running 1 project hook, 2 snapshots in 0 hours 0 minutes and 0.55 seconds (0.55s).
[0m13:03:34  
[0m13:03:34  [32mCompleted successfully[0m
[0m13:03:34  
[0m13:03:34  Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m13:03:36  Running with dbt=1.9.0-b4
[0m13:03:36  Registered adapter: postgres=1.8.2
[0m13:03:37  Found 19 models, 1 seed, 1 operation, 21 data tests, 2 snapshots, 15 sources, 751 macros
[0m13:03:37  
[0m13:03:37  Concurrency: 1 threads (target='dev')
[0m13:03:37  
[0m13:03:37  1 of 21 START test dbt_constraints_foreign_key_fct_book_sales_nk_book_id__nk_book_id__ref_dim_books_  [RUN]
[0m13:03:37  1 of 21 PASS dbt_constraints_foreign_key_fct_book_sales_nk_book_id__nk_book_id__ref_dim_books_  [[32mPASS[0m in 0.07s]
[0m13:03:37  2 of 21 START test dbt_constraints_foreign_key_fct_book_sales_order_date__date_actual__ref_dim_date_  [RUN]
[0m13:03:37  2 of 21 PASS dbt_constraints_foreign_key_fct_book_sales_order_date__date_actual__ref_dim_date_  [[32mPASS[0m in 0.04s]
[0m13:03:37  3 of 21 START test dbt_constraints_foreign_key_fct_orders_nk_customer_id__nk_customer_id__ref_dim_customers_  [RUN]
[0m13:03:37  3 of 21 PASS dbt_constraints_foreign_key_fct_orders_nk_customer_id__nk_customer_id__ref_dim_customers_  [[32mPASS[0m in 0.03s]
[0m13:03:37  4 of 21 START test dbt_constraints_primary_key_dim_books_sk_book_id ............ [RUN]
[0m13:03:37  4 of 21 PASS dbt_constraints_primary_key_dim_books_sk_book_id .................. [[32mPASS[0m in 0.03s]
[0m13:03:37  5 of 21 START test dbt_constraints_primary_key_dim_customers_sk_customer_id .... [RUN]
[0m13:03:37  5 of 21 PASS dbt_constraints_primary_key_dim_customers_sk_customer_id .......... [[32mPASS[0m in 0.03s]
[0m13:03:37  6 of 21 START test dbt_constraints_primary_key_dim_date_date_id ................ [RUN]
[0m13:03:37  6 of 21 PASS dbt_constraints_primary_key_dim_date_date_id ...................... [[32mPASS[0m in 0.04s]
[0m13:03:37  7 of 21 START test dbt_constraints_primary_key_fct_orders_sk_order_id .......... [RUN]
[0m13:03:37  7 of 21 PASS dbt_constraints_primary_key_fct_orders_sk_order_id ................ [[32mPASS[0m in 0.03s]
[0m13:03:37  8 of 21 START test not_null_dim_books_nk_book_id ............................... [RUN]
[0m13:03:38  8 of 21 PASS not_null_dim_books_nk_book_id ..................................... [[32mPASS[0m in 0.03s]
[0m13:03:38  9 of 21 START test not_null_dim_books_sk_book_id ............................... [RUN]
[0m13:03:38  9 of 21 PASS not_null_dim_books_sk_book_id ..................................... [[32mPASS[0m in 0.03s]
[0m13:03:38  10 of 21 START test not_null_dim_customers_nk_customer_id ...................... [RUN]
[0m13:03:38  10 of 21 PASS not_null_dim_customers_nk_customer_id ............................ [[32mPASS[0m in 0.03s]
[0m13:03:38  11 of 21 START test not_null_dim_customers_sk_customer_id ...................... [RUN]
[0m13:03:38  11 of 21 PASS not_null_dim_customers_sk_customer_id ............................ [[32mPASS[0m in 0.03s]
[0m13:03:38  12 of 21 START test not_null_dim_date_date_id .................................. [RUN]
[0m13:03:38  12 of 21 PASS not_null_dim_date_date_id ........................................ [[32mPASS[0m in 0.03s]
[0m13:03:38  13 of 21 START test not_null_fct_book_sales_dd_order_id ........................ [RUN]
[0m13:03:38  13 of 21 PASS not_null_fct_book_sales_dd_order_id .............................. [[32mPASS[0m in 0.03s]
[0m13:03:38  14 of 21 START test not_null_fct_book_sales_nk_book_id ......................... [RUN]
[0m13:03:38  14 of 21 PASS not_null_fct_book_sales_nk_book_id ............................... [[32mPASS[0m in 0.03s]
[0m13:03:38  15 of 21 START test not_null_fct_book_sales_order_date ......................... [RUN]
[0m13:03:38  15 of 21 PASS not_null_fct_book_sales_order_date ............................... [[32mPASS[0m in 0.03s]
[0m13:03:38  16 of 21 START test not_null_fct_orders_dd_order_id ............................ [RUN]
[0m13:03:38  16 of 21 PASS not_null_fct_orders_dd_order_id .................................. [[32mPASS[0m in 0.03s]
[0m13:03:38  17 of 21 START test not_null_fct_orders_nk_customer_id ......................... [RUN]
[0m13:03:38  17 of 21 PASS not_null_fct_orders_nk_customer_id ............................... [[32mPASS[0m in 0.03s]
[0m13:03:38  18 of 21 START test not_null_fct_orders_sk_order_id ............................ [RUN]
[0m13:03:38  18 of 21 PASS not_null_fct_orders_sk_order_id .................................. [[32mPASS[0m in 0.03s]
[0m13:03:38  19 of 21 START test unique_dim_books_sk_book_id ................................ [RUN]
[0m13:03:38  19 of 21 PASS unique_dim_books_sk_book_id ...................................... [[32mPASS[0m in 0.03s]
[0m13:03:38  20 of 21 START test unique_dim_customers_sk_customer_id ........................ [RUN]
[0m13:03:38  20 of 21 PASS unique_dim_customers_sk_customer_id .............................. [[32mPASS[0m in 0.03s]
[0m13:03:38  21 of 21 START test unique_fct_orders_sk_order_id .............................. [RUN]
[0m13:03:38  21 of 21 PASS unique_fct_orders_sk_order_id .................................... [[32mPASS[0m in 0.03s]
[0m13:03:38  
[0m13:03:38  Running dbt Constraints
[0m13:03:38  Creating not null constraint for: nk_book_id in "pacbook-dwh"."final"."dim_books"
[0m13:03:38  Creating not null constraint for: sk_book_id in "pacbook-dwh"."final"."dim_books"
[0m13:03:38  Creating not null constraint for: nk_customer_id in "pacbook-dwh"."final"."dim_customers"
[0m13:03:38  Creating not null constraint for: sk_customer_id in "pacbook-dwh"."final"."dim_customers"
[0m13:03:38  Creating not null constraint for: date_id in "pacbook-dwh"."final"."dim_date"
[0m13:03:38  Creating not null constraint for: dd_order_id in "pacbook-dwh"."final"."fct_book_sales"
[0m13:03:38  Creating not null constraint for: nk_book_id in "pacbook-dwh"."final"."fct_book_sales"
[0m13:03:38  Creating not null constraint for: order_date in "pacbook-dwh"."final"."fct_book_sales"
[0m13:03:38  Creating not null constraint for: dd_order_id in "pacbook-dwh"."final"."fct_orders"
[0m13:03:38  Creating not null constraint for: nk_customer_id in "pacbook-dwh"."final"."fct_orders"
[0m13:03:38  Creating not null constraint for: sk_order_id in "pacbook-dwh"."final"."fct_orders"
[0m13:03:38  Creating not null constraint for: sk_book_id in "pacbook-dwh"."final"."dim_books"
[0m13:03:38  Creating primary key: DIM_BOOKS_SK_BOOK_ID_PK
[0m13:03:38  Creating not null constraint for: sk_customer_id in "pacbook-dwh"."final"."dim_customers"
[0m13:03:38  Creating primary key: DIM_CUSTOMERS_SK_CUSTOMER_ID_PK
[0m13:03:38  Creating not null constraint for: date_id in "pacbook-dwh"."final"."dim_date"
[0m13:03:38  Creating primary key: DIM_DATE_DATE_ID_PK
[0m13:03:38  Creating not null constraint for: sk_order_id in "pacbook-dwh"."final"."fct_orders"
[0m13:03:38  Creating primary key: FCT_ORDERS_SK_ORDER_ID_PK
[0m13:03:38  Skipping FCT_BOOK_SALES_NK_BOOK_ID_FK because a PK/UK was not found on the PK table: "pacbook-dwh"."final"."dim_books" ['nk_book_id']
[0m13:03:38  Skipping FCT_BOOK_SALES_ORDER_DATE_FK because a PK/UK was not found on the PK table: "pacbook-dwh"."final"."dim_date" ['date_actual']
[0m13:03:38  Skipping FCT_ORDERS_NK_CUSTOMER_ID_FK because a PK/UK was not found on the PK table: "pacbook-dwh"."final"."dim_customers" ['nk_customer_id']
[0m13:03:38  Finished dbt Constraints
[0m13:03:38  1 of 1 START hook: dbt_constraints.on-run-end.0 ................................ [RUN]
[0m13:03:38  1 of 1 OK hook: dbt_constraints.on-run-end.0 ................................... [[32mOK[0m in 0.51s]
[0m13:03:38  
[0m13:03:38  Finished running 1 project hook, 21 data tests in 0 hours 0 minutes and 1.41 seconds (1.41s).
[0m13:03:39  
[0m13:03:39  [32mCompleted successfully[0m
[0m13:03:39  
[0m13:03:39  Done. PASS=22 WARN=0 ERROR=0 SKIP=0 TOTAL=22
2024-11-19 20:03:40,303 - INFO - Transform to All Dimensions and Fact Tables - SUCCESS!
2024-11-19 20:03:40,303 - INFO - ==================================ENDING TRANSFROM DATA=======================================
2024-11-19 20:03:40,303 - INFO - [pid 123741] Worker Worker(salt=6470965867, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=123741) done      Transform()
2024-11-19 20:03:40,304 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-19 20:03:40,307 - INFO - Informed scheduler that task   Transform__99914b932b   has status   DONE
2024-11-19 20:03:40,308 - DEBUG - Asking scheduler for work...
2024-11-19 20:03:40,310 - DEBUG - Done
2024-11-19 20:03:40,310 - DEBUG - There are no more tasks to run at this time
2024-11-19 20:03:40,310 - INFO - Worker Worker(salt=6470965867, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=123741) was stopped. Shutting down Keep-Alive thread
2024-11-19 20:03:40,312 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 3 ran successfully:
    - 1 Extract()
    - 1 Load()
    - 1 Transform()

This progress looks :) because there were no failed tasks or missing dependencies

===== Luigi Execution Summary =====

2024-11-20 01:10:09,853 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-20 01:10:10,015 - INFO - EXTRACT 'public.address' - SUCCESS.
2024-11-20 01:10:10,020 - INFO - EXTRACT 'public.address_status' - SUCCESS.
2024-11-20 01:10:10,054 - INFO - EXTRACT 'public.author' - SUCCESS.
2024-11-20 01:10:10,150 - INFO - EXTRACT 'public.book' - SUCCESS.
2024-11-20 01:10:10,245 - INFO - EXTRACT 'public.book_author' - SUCCESS.
2024-11-20 01:10:10,252 - INFO - EXTRACT 'public.book_language' - SUCCESS.
2024-11-20 01:10:10,260 - INFO - EXTRACT 'public.country' - SUCCESS.
2024-11-20 01:10:10,325 - INFO - EXTRACT 'public.cust_order' - SUCCESS.
2024-11-20 01:10:10,340 - INFO - EXTRACT 'public.customer' - SUCCESS.
2024-11-20 01:10:10,354 - INFO - EXTRACT 'public.customer_address' - SUCCESS.
2024-11-20 01:10:10,500 - INFO - EXTRACT 'public.order_history' - SUCCESS.
2024-11-20 01:10:10,619 - INFO - EXTRACT 'public.order_line' - SUCCESS.
2024-11-20 01:10:10,624 - INFO - EXTRACT 'public.order_status' - SUCCESS.
2024-11-20 01:10:10,637 - INFO - EXTRACT 'public.publisher' - SUCCESS.
2024-11-20 01:10:10,643 - INFO - EXTRACT 'public.shipping_method' - SUCCESS.
2024-11-20 01:10:10,644 - INFO - EXTRACT ALL TABLE FROM SOURCE DATABASE - SUCCESS!
2024-11-20 01:10:10,645 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-20 01:10:10,645 - INFO - [pid 226623] Worker Worker(salt=6547784601, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=226623) done      Extract()
2024-11-20 01:10:10,647 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-20 01:10:10,652 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-20 01:10:10,652 - DEBUG - Asking scheduler for work...
2024-11-20 01:10:10,655 - DEBUG - Pending tasks: 2
2024-11-20 01:10:10,655 - INFO - [pid 226623] Worker Worker(salt=6547784601, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=226623) running   Load()
2024-11-20 01:10:10,754 - INFO - Read Extracted Data - SUCCESS!
2024-11-20 01:10:10,763 - INFO - Connect to DWH - SUCCESS!
2024-11-20 01:10:11,205 - INFO - Truncate Staging Schema in DWH - SUCCESS!
2024-11-20 01:10:11,205 - INFO - ==================================STARTING LOAD DATA=======================================
2024-11-20 01:10:11,239 - INFO - Load country table - SUCCESS!
2024-11-20 01:10:11,296 - INFO - Load address table - SUCCESS!
2024-11-20 01:10:11,308 - INFO - Load address_status table - SUCCESS!
2024-11-20 01:10:11,318 - INFO - Load book_language table - SUCCESS!
2024-11-20 01:10:11,391 - INFO - Load customer table - SUCCESS!
2024-11-20 01:10:11,453 - INFO - Load publisher table - SUCCESS!
2024-11-20 01:10:11,463 - INFO - Load shipping_method table - SUCCESS!
2024-11-20 01:10:11,646 - INFO - Load author table - SUCCESS!
2024-11-20 01:10:12,238 - INFO - Load book table - SUCCESS!
2024-11-20 01:10:12,550 - INFO - Load cust_order table - SUCCESS!
2024-11-20 01:10:12,700 - INFO - Load customer_address table - SUCCESS!
2024-11-20 01:10:12,709 - INFO - Load order_status table - SUCCESS!
2024-11-20 01:10:13,177 - INFO - Load book_author table - SUCCESS!
2024-11-20 01:10:13,940 - INFO - Load order_history table - SUCCESS!
2024-11-20 01:10:14,443 - INFO - Load order_line table - SUCCESS!
2024-11-20 01:10:14,443 - INFO - LOAD All Tables To Pacbook DWH Staging Schema - SUCCESS!
2024-11-20 01:10:14,444 - INFO - ==================================ENDING LOAD DATA=======================================
2024-11-20 01:10:14,445 - INFO - [pid 226623] Worker Worker(salt=6547784601, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=226623) done      Load()
2024-11-20 01:10:14,446 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-20 01:10:14,450 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-11-20 01:10:14,450 - DEBUG - Asking scheduler for work...
2024-11-20 01:10:14,452 - DEBUG - Pending tasks: 1
2024-11-20 01:10:14,452 - INFO - [pid 226623] Worker Worker(salt=6547784601, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=226623) running   Transform()
2024-11-20 01:10:14,453 - INFO - ==================================STARTING TRANSFROM DATA=======================================
[0m18:10:16  Running with dbt=1.9.0-b4
[0m18:10:17  Installing dbt-labs/dbt_utils
[0m18:10:18  Installed from version 1.1.1
[0m18:10:18  Updated version available: 1.3.0
[0m18:10:18  Installing calogica/dbt_date
[0m18:10:19  Installed from version 0.10.0
[0m18:10:19  Updated version available: 0.10.1
[0m18:10:19  Installing Snowflake-Labs/dbt_constraints
[0m18:10:20  Installed from version 0.6.3
[0m18:10:20  Updated version available: 1.0.4
[0m18:10:20  
[0m18:10:20  Updates available for packages: ['dbt-labs/dbt_utils', 'calogica/dbt_date', 'Snowflake-Labs/dbt_constraints']                 
Update your versions in packages.yml, then run dbt deps
[0m18:10:23  Running with dbt=1.9.0-b4
[0m18:10:23  Registered adapter: postgres=1.8.2
[0m18:10:23  Found 19 models, 1 seed, 1 operation, 21 data tests, 2 snapshots, 15 sources, 751 macros
[0m18:10:23  
[0m18:10:23  Concurrency: 1 threads (target='dev')
[0m18:10:23  
[0m18:10:24  1 of 1 START seed file final.dim_date .......................................... [RUN]
[0m18:12:42  1 of 1 OK loaded seed file final.dim_date ...................................... [[32mINSERT 29220[0m in 138.43s]
[0m18:12:42  
[0m18:12:42  Running dbt Constraints
[0m18:12:42  Finished dbt Constraints
[0m18:12:42  1 of 1 START hook: dbt_constraints.on-run-end.0 ................................ [RUN]
[0m18:12:42  1 of 1 OK hook: dbt_constraints.on-run-end.0 ................................... [[32mOK[0m in 0.09s]
[0m18:12:42  
[0m18:12:42  Finished running 1 project hook, 1 seed in 0 hours 2 minutes and 18.83 seconds (138.83s).
[0m18:12:42  
[0m18:12:42  [32mCompleted successfully[0m
[0m18:12:42  
[0m18:12:42  Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m18:12:45  Running with dbt=1.9.0-b4
[0m18:12:45  Registered adapter: postgres=1.8.2
[0m18:12:46  Found 19 models, 1 seed, 1 operation, 21 data tests, 2 snapshots, 15 sources, 751 macros
[0m18:12:46  
[0m18:12:46  Concurrency: 1 threads (target='dev')
[0m18:12:46  
[0m18:12:46  1 of 19 START sql view model final.stg_pacbook__address ........................ [RUN]
[0m18:12:46  1 of 19 OK created sql view model final.stg_pacbook__address ................... [[32mCREATE VIEW[0m in 0.19s]
[0m18:12:46  2 of 19 START sql view model final.stg_pacbook__address_status ................. [RUN]
[0m18:12:46  2 of 19 OK created sql view model final.stg_pacbook__address_status ............ [[32mCREATE VIEW[0m in 0.07s]
[0m18:12:46  3 of 19 START sql view model final.stg_pacbook__author ......................... [RUN]
[0m18:12:46  3 of 19 OK created sql view model final.stg_pacbook__author .................... [[32mCREATE VIEW[0m in 0.06s]
[0m18:12:46  4 of 19 START sql view model final.stg_pacbook__book ........................... [RUN]
[0m18:12:46  4 of 19 OK created sql view model final.stg_pacbook__book ...................... [[32mCREATE VIEW[0m in 0.06s]
[0m18:12:46  5 of 19 START sql view model final.stg_pacbook__book_author .................... [RUN]
[0m18:12:46  5 of 19 OK created sql view model final.stg_pacbook__book_author ............... [[32mCREATE VIEW[0m in 0.07s]
[0m18:12:46  6 of 19 START sql view model final.stg_pacbook__book_language .................. [RUN]
[0m18:12:46  6 of 19 OK created sql view model final.stg_pacbook__book_language ............. [[32mCREATE VIEW[0m in 0.06s]
[0m18:12:46  7 of 19 START sql view model final.stg_pacbook__country ........................ [RUN]
[0m18:12:46  7 of 19 OK created sql view model final.stg_pacbook__country ................... [[32mCREATE VIEW[0m in 0.06s]
[0m18:12:46  8 of 19 START sql view model final.stg_pacbook__cust_order ..................... [RUN]
[0m18:12:47  8 of 19 OK created sql view model final.stg_pacbook__cust_order ................ [[32mCREATE VIEW[0m in 0.06s]
[0m18:12:47  9 of 19 START sql view model final.stg_pacbook__customer ....................... [RUN]
[0m18:12:47  9 of 19 OK created sql view model final.stg_pacbook__customer .................. [[32mCREATE VIEW[0m in 0.06s]
[0m18:12:47  10 of 19 START sql view model final.stg_pacbook__customer_address .............. [RUN]
[0m18:12:47  10 of 19 OK created sql view model final.stg_pacbook__customer_address ......... [[32mCREATE VIEW[0m in 0.06s]
[0m18:12:47  11 of 19 START sql view model final.stg_pacbook__order_history ................. [RUN]
[0m18:12:47  11 of 19 OK created sql view model final.stg_pacbook__order_history ............ [[32mCREATE VIEW[0m in 0.11s]
[0m18:12:47  12 of 19 START sql view model final.stg_pacbook__order_line .................... [RUN]
[0m18:12:47  12 of 19 OK created sql view model final.stg_pacbook__order_line ............... [[32mCREATE VIEW[0m in 0.06s]
[0m18:12:47  13 of 19 START sql view model final.stg_pacbook__order_status .................. [RUN]
[0m18:12:47  13 of 19 OK created sql view model final.stg_pacbook__order_status ............. [[32mCREATE VIEW[0m in 0.06s]
[0m18:12:47  14 of 19 START sql view model final.stg_pacbook__publisher ..................... [RUN]
[0m18:12:47  14 of 19 OK created sql view model final.stg_pacbook__publisher ................ [[32mCREATE VIEW[0m in 0.08s]
[0m18:12:47  15 of 19 START sql view model final.stg_pacbook__shipping_method ............... [RUN]
[0m18:12:47  15 of 19 OK created sql view model final.stg_pacbook__shipping_method .......... [[32mCREATE VIEW[0m in 0.06s]
[0m18:12:47  16 of 19 START sql table model final.dim_customers ............................. [RUN]
[0m18:12:47  16 of 19 OK created sql table model final.dim_customers ........................ [[32mSELECT 3350[0m in 0.22s]
[0m18:12:47  17 of 19 START sql table model final.dim_books ................................. [RUN]
[0m18:12:48  17 of 19 OK created sql table model final.dim_books ............................ [[32mSELECT 11127[0m in 0.21s]
[0m18:12:48  18 of 19 START sql table model final.fct_book_sales ............................ [RUN]
[0m18:12:48  18 of 19 OK created sql table model final.fct_book_sales ....................... [[32mSELECT 15399[0m in 0.21s]
[0m18:12:48  19 of 19 START sql table model final.fct_orders ................................ [RUN]
[0m18:12:48  19 of 19 OK created sql table model final.fct_orders ........................... [[32mSELECT 7550[0m in 0.25s]
[0m18:12:48  
[0m18:12:48  Running dbt Constraints
[0m18:12:48  Finished dbt Constraints
[0m18:12:48  1 of 1 START hook: dbt_constraints.on-run-end.0 ................................ [RUN]
[0m18:12:48  1 of 1 OK hook: dbt_constraints.on-run-end.0 ................................... [[32mOK[0m in 0.05s]
[0m18:12:48  
[0m18:12:48  Finished running 1 project hook, 4 table models, 15 view models in 0 hours 0 minutes and 2.37 seconds (2.37s).
[0m18:12:48  
[0m18:12:48  [32mCompleted successfully[0m
[0m18:12:48  
[0m18:12:48  Done. PASS=20 WARN=0 ERROR=0 SKIP=0 TOTAL=20
[0m18:12:51  Running with dbt=1.9.0-b4
[0m18:12:51  Registered adapter: postgres=1.8.2
[0m18:12:52  Found 19 models, 1 seed, 1 operation, 21 data tests, 2 snapshots, 15 sources, 751 macros
[0m18:12:52  
[0m18:12:52  Concurrency: 1 threads (target='dev')
[0m18:12:52  
[0m18:12:52  1 of 2 START snapshot snapshots.dim_books_snapshot ............................. [RUN]
[0m18:12:53  1 of 2 OK snapshotted snapshots.dim_books_snapshot ............................. [[32mINSERT 0 0[0m in 0.43s]
[0m18:12:53  2 of 2 START snapshot snapshots.dim_customers_snapshot ......................... [RUN]
[0m18:12:53  2 of 2 OK snapshotted snapshots.dim_customers_snapshot ......................... [[32mINSERT 0 0[0m in 0.16s]
[0m18:12:53  
[0m18:12:53  Running dbt Constraints
[0m18:12:53  Finished dbt Constraints
[0m18:12:53  1 of 1 START hook: dbt_constraints.on-run-end.0 ................................ [RUN]
[0m18:12:53  1 of 1 OK hook: dbt_constraints.on-run-end.0 ................................... [[32mOK[0m in 0.07s]
[0m18:12:53  
[0m18:12:53  Finished running 1 project hook, 2 snapshots in 0 hours 0 minutes and 0.89 seconds (0.89s).
[0m18:12:53  
[0m18:12:53  [32mCompleted successfully[0m
[0m18:12:53  
[0m18:12:53  Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m18:12:55  Running with dbt=1.9.0-b4
[0m18:12:56  Registered adapter: postgres=1.8.2
[0m18:12:56  Found 19 models, 1 seed, 1 operation, 21 data tests, 2 snapshots, 15 sources, 751 macros
[0m18:12:56  
[0m18:12:56  Concurrency: 1 threads (target='dev')
[0m18:12:56  
[0m18:12:56  1 of 21 START test dbt_constraints_foreign_key_fct_book_sales_nk_book_id__nk_book_id__ref_dim_books_  [RUN]
[0m18:12:56  1 of 21 PASS dbt_constraints_foreign_key_fct_book_sales_nk_book_id__nk_book_id__ref_dim_books_  [[32mPASS[0m in 0.07s]
[0m18:12:56  2 of 21 START test dbt_constraints_foreign_key_fct_book_sales_order_date__date_actual__ref_dim_date_  [RUN]
[0m18:12:57  2 of 21 PASS dbt_constraints_foreign_key_fct_book_sales_order_date__date_actual__ref_dim_date_  [[32mPASS[0m in 0.04s]
[0m18:12:57  3 of 21 START test dbt_constraints_foreign_key_fct_orders_nk_customer_id__nk_customer_id__ref_dim_customers_  [RUN]
[0m18:12:57  3 of 21 PASS dbt_constraints_foreign_key_fct_orders_nk_customer_id__nk_customer_id__ref_dim_customers_  [[32mPASS[0m in 0.03s]
[0m18:12:57  4 of 21 START test dbt_constraints_primary_key_dim_books_sk_book_id ............ [RUN]
[0m18:12:57  4 of 21 PASS dbt_constraints_primary_key_dim_books_sk_book_id .................. [[32mPASS[0m in 0.03s]
[0m18:12:57  5 of 21 START test dbt_constraints_primary_key_dim_customers_sk_customer_id .... [RUN]
[0m18:12:57  5 of 21 PASS dbt_constraints_primary_key_dim_customers_sk_customer_id .......... [[32mPASS[0m in 0.03s]
[0m18:12:57  6 of 21 START test dbt_constraints_primary_key_dim_date_date_id ................ [RUN]
[0m18:12:57  6 of 21 PASS dbt_constraints_primary_key_dim_date_date_id ...................... [[32mPASS[0m in 0.04s]
[0m18:12:57  7 of 21 START test dbt_constraints_primary_key_fct_orders_sk_order_id .......... [RUN]
[0m18:12:57  7 of 21 PASS dbt_constraints_primary_key_fct_orders_sk_order_id ................ [[32mPASS[0m in 0.03s]
[0m18:12:57  8 of 21 START test not_null_dim_books_nk_book_id ............................... [RUN]
[0m18:12:57  8 of 21 PASS not_null_dim_books_nk_book_id ..................................... [[32mPASS[0m in 0.03s]
[0m18:12:57  9 of 21 START test not_null_dim_books_sk_book_id ............................... [RUN]
[0m18:12:57  9 of 21 PASS not_null_dim_books_sk_book_id ..................................... [[32mPASS[0m in 0.03s]
[0m18:12:57  10 of 21 START test not_null_dim_customers_nk_customer_id ...................... [RUN]
[0m18:12:57  10 of 21 PASS not_null_dim_customers_nk_customer_id ............................ [[32mPASS[0m in 0.03s]
[0m18:12:57  11 of 21 START test not_null_dim_customers_sk_customer_id ...................... [RUN]
[0m18:12:57  11 of 21 PASS not_null_dim_customers_sk_customer_id ............................ [[32mPASS[0m in 0.03s]
[0m18:12:57  12 of 21 START test not_null_dim_date_date_id .................................. [RUN]
[0m18:12:57  12 of 21 PASS not_null_dim_date_date_id ........................................ [[32mPASS[0m in 0.03s]
[0m18:12:57  13 of 21 START test not_null_fct_book_sales_dd_order_id ........................ [RUN]
[0m18:12:57  13 of 21 PASS not_null_fct_book_sales_dd_order_id .............................. [[32mPASS[0m in 0.03s]
[0m18:12:57  14 of 21 START test not_null_fct_book_sales_nk_book_id ......................... [RUN]
[0m18:12:57  14 of 21 PASS not_null_fct_book_sales_nk_book_id ............................... [[32mPASS[0m in 0.03s]
[0m18:12:57  15 of 21 START test not_null_fct_book_sales_order_date ......................... [RUN]
[0m18:12:57  15 of 21 PASS not_null_fct_book_sales_order_date ............................... [[32mPASS[0m in 0.03s]
[0m18:12:57  16 of 21 START test not_null_fct_orders_dd_order_id ............................ [RUN]
[0m18:12:57  16 of 21 PASS not_null_fct_orders_dd_order_id .................................. [[32mPASS[0m in 0.03s]
[0m18:12:57  17 of 21 START test not_null_fct_orders_nk_customer_id ......................... [RUN]
[0m18:12:57  17 of 21 PASS not_null_fct_orders_nk_customer_id ............................... [[32mPASS[0m in 0.03s]
[0m18:12:57  18 of 21 START test not_null_fct_orders_sk_order_id ............................ [RUN]
[0m18:12:57  18 of 21 PASS not_null_fct_orders_sk_order_id .................................. [[32mPASS[0m in 0.03s]
[0m18:12:57  19 of 21 START test unique_dim_books_sk_book_id ................................ [RUN]
[0m18:12:57  19 of 21 PASS unique_dim_books_sk_book_id ...................................... [[32mPASS[0m in 0.03s]
[0m18:12:57  20 of 21 START test unique_dim_customers_sk_customer_id ........................ [RUN]
[0m18:12:57  20 of 21 PASS unique_dim_customers_sk_customer_id .............................. [[32mPASS[0m in 0.03s]
[0m18:12:57  21 of 21 START test unique_fct_orders_sk_order_id .............................. [RUN]
[0m18:12:57  21 of 21 PASS unique_fct_orders_sk_order_id .................................... [[32mPASS[0m in 0.03s]
[0m18:12:57  
[0m18:12:57  Running dbt Constraints
[0m18:12:57  Creating not null constraint for: nk_book_id in "pacbook-dwh"."final"."dim_books"
[0m18:12:57  Creating not null constraint for: sk_book_id in "pacbook-dwh"."final"."dim_books"
[0m18:12:57  Creating not null constraint for: nk_customer_id in "pacbook-dwh"."final"."dim_customers"
[0m18:12:57  Creating not null constraint for: sk_customer_id in "pacbook-dwh"."final"."dim_customers"
[0m18:12:57  Creating not null constraint for: date_id in "pacbook-dwh"."final"."dim_date"
[0m18:12:57  Creating not null constraint for: dd_order_id in "pacbook-dwh"."final"."fct_book_sales"
[0m18:12:57  Creating not null constraint for: nk_book_id in "pacbook-dwh"."final"."fct_book_sales"
[0m18:12:57  Creating not null constraint for: order_date in "pacbook-dwh"."final"."fct_book_sales"
[0m18:12:57  Creating not null constraint for: dd_order_id in "pacbook-dwh"."final"."fct_orders"
[0m18:12:57  Creating not null constraint for: nk_customer_id in "pacbook-dwh"."final"."fct_orders"
[0m18:12:57  Creating not null constraint for: sk_order_id in "pacbook-dwh"."final"."fct_orders"
[0m18:12:57  Creating not null constraint for: sk_book_id in "pacbook-dwh"."final"."dim_books"
[0m18:12:57  Creating primary key: DIM_BOOKS_SK_BOOK_ID_PK
[0m18:12:57  Creating not null constraint for: sk_customer_id in "pacbook-dwh"."final"."dim_customers"
[0m18:12:57  Creating primary key: DIM_CUSTOMERS_SK_CUSTOMER_ID_PK
[0m18:12:57  Creating not null constraint for: date_id in "pacbook-dwh"."final"."dim_date"
[0m18:12:58  Creating primary key: DIM_DATE_DATE_ID_PK
[0m18:12:58  Creating not null constraint for: sk_order_id in "pacbook-dwh"."final"."fct_orders"
[0m18:12:58  Creating primary key: FCT_ORDERS_SK_ORDER_ID_PK
[0m18:12:58  Skipping FCT_BOOK_SALES_NK_BOOK_ID_FK because a PK/UK was not found on the PK table: "pacbook-dwh"."final"."dim_books" ['nk_book_id']
[0m18:12:58  Skipping FCT_BOOK_SALES_ORDER_DATE_FK because a PK/UK was not found on the PK table: "pacbook-dwh"."final"."dim_date" ['date_actual']
[0m18:12:58  Skipping FCT_ORDERS_NK_CUSTOMER_ID_FK because a PK/UK was not found on the PK table: "pacbook-dwh"."final"."dim_customers" ['nk_customer_id']
[0m18:12:58  Finished dbt Constraints
[0m18:12:58  1 of 1 START hook: dbt_constraints.on-run-end.0 ................................ [RUN]
[0m18:12:58  1 of 1 OK hook: dbt_constraints.on-run-end.0 ................................... [[32mOK[0m in 0.52s]
[0m18:12:58  
[0m18:12:58  Finished running 1 project hook, 21 data tests in 0 hours 0 minutes and 1.43 seconds (1.43s).
[0m18:12:58  
[0m18:12:58  [32mCompleted successfully[0m
[0m18:12:58  
[0m18:12:58  Done. PASS=22 WARN=0 ERROR=0 SKIP=0 TOTAL=22
2024-11-20 01:12:59,663 - INFO - Transform to All Dimensions and Fact Tables - SUCCESS!
2024-11-20 01:12:59,664 - INFO - ==================================ENDING TRANSFROM DATA=======================================
2024-11-20 01:12:59,664 - INFO - [pid 226623] Worker Worker(salt=6547784601, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=226623) done      Transform()
2024-11-20 01:12:59,665 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-20 01:12:59,669 - INFO - Informed scheduler that task   Transform__99914b932b   has status   DONE
2024-11-20 01:12:59,669 - DEBUG - Asking scheduler for work...
2024-11-20 01:12:59,671 - DEBUG - Done
2024-11-20 01:12:59,671 - DEBUG - There are no more tasks to run at this time
2024-11-20 01:12:59,671 - INFO - Worker Worker(salt=6547784601, workers=1, host=LAPTOP-E1BGNT67, username=ricofebrian, pid=226623) was stopped. Shutting down Keep-Alive thread
2024-11-20 01:12:59,673 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 3 ran successfully:
    - 1 Extract()
    - 1 Load()
    - 1 Transform()

This progress looks :) because there were no failed tasks or missing dependencies

===== Luigi Execution Summary =====

